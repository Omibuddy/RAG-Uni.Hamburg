[
  {
    "page_content": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 06 – Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 1,
      "chunk_id": "p1c1",
      "title": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 06 – Replication and Consensus",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Replication ▪Consensus DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 2,
      "chunk_id": "p2c1",
      "title": "Agenda ▪Replication ▪Consensus DSM06Replication and Consensus",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Replication ▪Keeping a copy of the same data on multiple nodes ▪Databases, filesystems, caches, … ▪A node that has a copy of the data is called replica ▪If some replicas are faulty, others are still accessible ▪Idea: Spread load across many replicas ▪Easy if data does not change: just copy it ▪We will focus on data changes ▪Compare to RAID (Redundant Array of Independent Disks): DSM06Replication",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 3,
      "chunk_id": "p3c1",
      "title": "Replication ▪Keeping a copy of the same data on multiple nodes ▪Databases, filesystems, caches, … ▪A",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "focus on data changes ▪Compare to RAID (Redundant Array of Independent Disks): DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 3,
      "chunk_id": "p3c2",
      "title": "Replication ▪Keeping a copy of the same data on multiple nodes ▪Databases, filesystems, caches, … ▪A",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Replication ▪Keeping a copy of the same data on multiple nodes ▪Databases, filesystems, caches, … ▪A node that has a copy of the data is called replica ▪If some replicas are faulty, others are still accessible ▪Idea: Spread load across many replicas ▪Easy if data does not change: just copy it ▪We will focus on data changes ▪Compare to RAID (Redundant Array of Independent Disks): replication within",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 4,
      "chunk_id": "p4c1",
      "title": "Replication ▪Keeping a copy of the same data on multiple nodes ▪Databases, filesystems, caches, … ▪A",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "focus on data changes ▪Compare to RAID (Redundant Array of Independent Disks): replication within a single computer ▪RAID has a single controller; in distributed system, each node acts independently ▪Replicas can be distributed around the world, near users DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 4,
      "chunk_id": "p4c2",
      "title": "Replication ▪Keeping a copy of the same data on multiple nodes ▪Databases, filesystems, caches, … ▪A",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Why Replication? 1) Performance enhancement ▪Distributed systems have to scale in numbers and geographical scope ▪Multiple servers with replicated data giving diverse processes access to data ▪Access time may be much shorter 2) Faulttolerant service ▪Guarantees correct behavior in spite of certain faults ▪If f of f+1 servers crash then 1 remains to supply the service ▪If f of 2f+1 servers have",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 5,
      "chunk_id": "p5c1",
      "title": "Why Replication? 1) Performance enhancement ▪Distributed systems have to scale in numbers and geogra",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "faults ▪If f of f+1 servers crash then 1 remains to supply the service ▪If f of 2f+1 servers have byzantine faults then the system can supply a correct service DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 5,
      "chunk_id": "p5c2",
      "title": "Why Replication? 1) Performance enhancement ▪Distributed systems have to scale in numbers and geogra",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Why Replication? 3) Increased Availability ▪= Proportion of time for which a service is accessible ▪Despite of server failures and disconnected operations ▪If each of n servers has an independent probability p of of failing DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 6,
      "chunk_id": "p6c1",
      "title": "Why Replication? 3) Increased Availability ▪= Proportion of time for which a service is accessible ▪",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Why Replication? 3) Increased Availability ▪= Proportion of time for which a service is accessible ▪Despite of server failures and disconnected operations ▪If each of n servers has an independent probability p of of failing ▪availability = 1 – probability(all servers failed) = 1 – pn ▪1 – 0.052 = 1 – 0.0025 = 99,75% (for p = 0.05 and n = 2) ▪1 – 0.053 = 1 – 0.000125 = 99,9875% (for p = 0.05 and n",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 7,
      "chunk_id": "p7c1",
      "title": "Why Replication? 3) Increased Availability ▪= Proportion of time for which a service is accessible ▪",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "– 0.0025 = 99,75% (for p = 0.05 and n = 2) ▪1 – 0.053 = 1 – 0.000125 = 99,9875% (for p = 0.05 and n = 3) ▪for p = 0.01: DSM06Replication and Consensus replicas n P( ≥ 1 faulty) P(≥ 𝒏+𝟏 𝟐) faulty P(all n faulty) 0.01 0.01 0.01 0.03 3 × 104 106 0.049 1 × 105 1010 0.63 6 × 1074 10200",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 7,
      "chunk_id": "p7c2",
      "title": "Why Replication? 3) Increased Availability ▪= Proportion of time for which a service is accessible ▪",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Requirements for Replicated Data Replication transparency ▪Clients see logical objects (not several physical copies) ▪They access one logical item and receive a single result Consistency ▪All replicas should have “the same” state ▪E.g",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 8,
      "chunk_id": "p8c1",
      "title": "Requirements for Replicated Data Replication transparency ▪Clients see logical objects (not several ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". when a user of a calendar disconnects, the local copy may be inconsistent with the others and will need to be reconciled when they connect again ▪Connected clients using different copies should get consistent results ▪These issues are addressed in every distributed database DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 8,
      "chunk_id": "p8c2",
      "title": "Requirements for Replicated Data Replication transparency ▪Clients see logical objects (not several ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Implementing Replication ▪A collection of Replicat Managers (RMs) provides a service to clients",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 9,
      "chunk_id": "p9c1",
      "title": "Implementing Replication ▪A collection of Replicat Managers (RMs) provides a service to clients. ▪Cl",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Clients see a service that gives them access to logical objects, which are in fact replicated at the RMs ▪Clients request operations: ▪Those without updates are called readonly requests ▪The others are called update requests (they may include reads) ▪Clients requests are handled by front ends ▪A front end (FE) makes replication transparent DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 9,
      "chunk_id": "p9c2",
      "title": "Implementing Replication ▪A collection of Replicat Managers (RMs) provides a service to clients. ▪Cl",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Requests Processing: 5 Phases DSM06Replication and Consensus 1) Issue request ▪The FE either ▪Sends the request to a single RM that passes it on to the others ▪Multicasts the request to all of the RMs 2) Coordination ▪The RMs decide whether to apply the request 3) Execution ▪RMs execute the request 4) Agreement ▪RMs reach consensus on the effect of the request 5) Response ▪One or more RMs respond",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 10,
      "chunk_id": "p10c1",
      "title": "Requests Processing: 5 Phases DSM06Replication and Consensus 1) Issue request ▪The FE either ▪Sends ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "4) Agreement ▪RMs reach consensus on the effect of the request 5) Response ▪One or more RMs respond to the FE, e.g",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 10,
      "chunk_id": "p10c2",
      "title": "Requests Processing: 5 Phases DSM06Replication and Consensus 1) Issue request ▪The FE either ▪Sends ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪For high availability give first response to client. ▪To tolerate byzantine faults: Take a vote",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 10,
      "chunk_id": "p10c3",
      "title": "Requests Processing: 5 Phases DSM06Replication and Consensus 1) Issue request ▪The FE either ▪Sends ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Passive (Primary/Backup) Replication ▪There is at any time a single primary RM and one or more secondary (backup, slave) RMs ▪FEs communicate with the primary ▪Primary executes the operation and sends copies of the updated data to the result to backups ▪If the primary fails, one of the backups is promoted to act as the primary DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 11,
      "chunk_id": "p11c1",
      "title": "Passive (Primary/Backup) Replication ▪There is at any time a single primary RM and one or more secon",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Passive (Primary/Backup) Replication ▪Request: FE issues request with unique identifier to the primary RM ▪Coordination: Primary takes requests in FIFO order, if request already executed – resend the response ▪Execution: Primary executes the request and saves the response ▪Agreement: If request is an update, primary sends update with identifier to all backups ▪Response: Primary responds to FE",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 12,
      "chunk_id": "p12c1",
      "title": "Passive (Primary/Backup) Replication ▪Request: FE issues request with unique identifier to the prima",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "is an update, primary sends update with identifier to all backups ▪Response: Primary responds to FE DSM06Replication and Consensus If the primary fails, one of the backups is promoted to act as the primary",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 12,
      "chunk_id": "p12c2",
      "title": "Passive (Primary/Backup) Replication ▪Request: FE issues request with unique identifier to the prima",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Active Replication ▪The RMs are state machines all playing the same role and organized as a group ▪All start in the same state and perform the same operations in the same order so that their state remains identical ▪Underlying multicast is totally ordered and reliable ▪If an RM crashes it has no effect on performance of the service because the others continue as normal ▪It can tolerate byzantine",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 13,
      "chunk_id": "p13c1",
      "title": "Active Replication ▪The RMs are state machines all playing the same role and organized as a group ▪A",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "on performance of the service because the others continue as normal ▪It can tolerate byzantine failures because the FE can collect and compare the replies it receives DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 13,
      "chunk_id": "p13c2",
      "title": "Active Replication ▪The RMs are state machines all playing the same role and organized as a group ▪A",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Active Replication ▪Request: FE multicast request with unique identifier to a group of RMs ▪Coordination: The communication system delivers the request to every correct replica manager in the same (total) order ▪Execution: Every RM executes the request – correct RMs process request identically ▪Agreement: No agreement is needed, because of the multicast delivery semantics ▪Response: Each RM sends",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 14,
      "chunk_id": "p14c1",
      "title": "Active Replication ▪Request: FE multicast request with unique identifier to a group of RMs ▪Coordina",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "No agreement is needed, because of the multicast delivery semantics ▪Response: Each RM sends its response to the FE",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 14,
      "chunk_id": "p14c2",
      "title": "Active Replication ▪Request: FE multicast request with unique identifier to a group of RMs ▪Coordina",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". The number of replies that the FE collects depends upon the failure assumption and on the multicast algorithm. DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 14,
      "chunk_id": "p14c3",
      "title": "Active Replication ▪Request: FE multicast request with unique identifier to a group of RMs ▪Coordina",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Retrying state updates DSM06Replication and Consensus DB Client 2,106",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 15,
      "chunk_id": "p15c1",
      "title": "Retrying state updates DSM06Replication and Consensus DB Client 2,106",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Retrying state updates DSM06Replication and Consensus DB Client 2,106 2,107 Deduplicating requests requires that the database tracks which requests it has already seen (in stable storage)",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 16,
      "chunk_id": "p16c1",
      "title": "Retrying state updates DSM06Replication and Consensus DB Client 2,106 2,107 Deduplicating requests r",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Idempotence A function f is idempotent if f(x) = f(f(x)). ▪Not idempotent: f(likeCount) = likeCount +1 ▪Idempotent: f(likeSet) = likeSet ⋃{userID} Idempotent requests can be retried without deduplication. DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 17,
      "chunk_id": "p17c1",
      "title": "Idempotence A function f is idempotent if f(x) = f(f(x)). ▪Not idempotent: f(likeCount) = likeCount ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Idempotence A function f is idempotent if f(x) = f(f(x)). ▪Not idempotent: f(likeCount) = likeCount +1 ▪Idempotent: f(likeSet) = likeSet ⋃{userID} Idempotent requests can be retried without deduplication",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 18,
      "chunk_id": "p18c1",
      "title": "Idempotence A function f is idempotent if f(x) = f(f(x)). ▪Not idempotent: f(likeCount) = likeCount ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Choice of retry semantics: ▪Atmostonce: ▪send request, don’t retry, update may not happen ▪Atleastonce: ▪retry request until acknowledged, may repeat update ▪Exactlyonce: ▪retry + idempotence or deduplication DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 18,
      "chunk_id": "p18c2",
      "title": "Idempotence A function f is idempotent if f(x) = f(f(x)). ▪Not idempotent: f(likeCount) = likeCount ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Adding and then removing DSM06Replication and Consensus DB Client 1 f(likes) = likes ⋃{userID} g(likes) = likes \\ {userID} Client 2",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 19,
      "chunk_id": "p19c1",
      "title": "Adding and then removing DSM06Replication and Consensus DB Client 1 f(likes) = likes ⋃{userID} g(lik",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Adding and then removing DSM06Replication and Consensus DB Client 1 f(likes) = likes ⋃{userID} g(likes) = likes \\ {userID} Idempotent? f(f(x)) = f(x) but f(g(f(x)) ≠ g(f(x)) Client 2",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 20,
      "chunk_id": "p20c1",
      "title": "Adding and then removing DSM06Replication and Consensus DB Client 1 f(likes) = likes ⋃{userID} g(lik",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Adding and then removing DSM06Replication and Consensus A Client B",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 21,
      "chunk_id": "p21c1",
      "title": "Adding and then removing DSM06Replication and Consensus A Client B",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Adding and then removing DSM06Replication and Consensus A Client B A Client B Final state (x ∉ A, x ∈ B) is the same in both cases. However, what did the user want?",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 22,
      "chunk_id": "p22c1",
      "title": "Adding and then removing DSM06Replication and Consensus A Client B A Client B Final state (x ∉ A, x ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Timestamps and tombstones DSM06Replication and Consensus A Client B {x ↦ (t1 , true)} {x ↦ (t1, true)} {x ↦ (t2, false)} remove(x) does not actually remove x. It labels x with false to indicate it is invisible (a tombstone)",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 23,
      "chunk_id": "p23c1",
      "title": "Timestamps and tombstones DSM06Replication and Consensus A Client B {x ↦ (t1 , true)} {x ↦ (t1, true",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Reconciling Replicas DSM06Replication and Consensus A B {x ↦ (t1 , true)} {x ↦ (t2 , false)} {x ↦ (t2 , false)} Replicas periodically communicate among themselves to check for any inconsistencies. Propagate the record with the latest timestamp, discard the records with earlier timestamps (for a given key). {x ↦ (t2 , false)} t1 < t2 reconcile state (antientropy)",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 24,
      "chunk_id": "p24c1",
      "title": "Reconciling Replicas DSM06Replication and Consensus A B {x ↦ (t1 , true)} {x ↦ (t2 , false)} {x ↦ (t",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Concurrent writes by different clients DSM06Replication and Consensus A Client B Client t1 t2 Two common approaches: ▪Last writer wins (LLW): ▪Use timestamps with total order (e.g. Lamport clock). Keep v2 and discard v1 if t2 > t1. ▪Data loss!",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 25,
      "chunk_id": "p25c1",
      "title": "Concurrent writes by different clients DSM06Replication and Consensus A Client B Client t1 t2 Two co",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Concurrent writes by different clients DSM06Replication and Consensus A Client B Client t1 t2 Two common approaches: ▪Last writer wins (LLW): ▪Use timestamps with total order (e.g. Lamport clock). Keep v2 and discard v1 if t2 > t1. ▪Data loss! ▪Multivalue register: ▪Use timestamps with partial order (e.g. vector clock). ▪v2 replaces v1 if t2 > t1. ▪Preserves both {v1, v2} if t2 || t1",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 26,
      "chunk_id": "p26c1",
      "title": "Concurrent writes by different clients DSM06Replication and Consensus A Client B Client t1 t2 Two co",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Readafterwrite consistency DSM06Replication and Consensus A Client B t1 ▪The client updates a value in A and B, however, the update to A fails.",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 27,
      "chunk_id": "p27c1",
      "title": "Readafterwrite consistency DSM06Replication and Consensus A Client B t1 ▪The client updates a value ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Readafterwrite consistency DSM06Replication and Consensus A Client B t1 ▪The client updates a value in A and B, however, the update to A fails. ▪The client reads from A and B but this time the read from B fails. ▪The client cannot see its own update. ▪Requires writing to/reading from both replicas ▪not faulttolerant ▪Cannot write/read if one replica is unavailable",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 28,
      "chunk_id": "p28c1",
      "title": "Readafterwrite consistency DSM06Replication and Consensus A Client B t1 ▪The client updates a value ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Quroum (2 out of 3) DSM06Replication and Consensus A Client B t1 C ▪Write succeeds on B and C",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 29,
      "chunk_id": "p29c1",
      "title": "Quroum (2 out of 3) DSM06Replication and Consensus A Client B t1 C ▪Write succeeds on B and C",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Quroum (2 out of 3) DSM06Replication and Consensus A Client B t1 C ▪Write succeeds on B and C ▪Read succeeds on A and B",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 30,
      "chunk_id": "p30c1",
      "title": "Quroum (2 out of 3) DSM06Replication and Consensus A Client B t1 C ▪Write succeeds on B and C ▪Read ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Quroum (2 out of 3) DSM06Replication and Consensus A Client B t1 C ▪Write succeeds on B and C ▪Read succeeds on A and B ▪Choose between (t0 , v0) and (t1 , v1) based on timestamp",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 31,
      "chunk_id": "p31c1",
      "title": "Quroum (2 out of 3) DSM06Replication and Consensus A Client B t1 C ▪Write succeeds on B and C ▪Read ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Read and write quorums DSM06Replication and Consensus ▪In a system with n replicas: ▪If a write is acknowledged by w replicas (write quorum) ▪and we subsequently read from r replicas (read quorum) ▪and r + w > n, ▪… then the read will see the previously written value (or a value that subsequently overwrote it) ▪Read quroum and write quorum share ≥ 1 replica.",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 32,
      "chunk_id": "p32c1",
      "title": "Read and write quorums DSM06Replication and Consensus ▪In a system with n replicas: ▪If a write is a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Read and write quorums DSM06Replication and Consensus ▪In a system with n replicas: ▪If a write is acknowledged by w replicas (write quorum) ▪and we subsequently read from r replicas (read quorum) ▪and r + w > n, ▪… then the read will see the previously written value (or a value that subsequently overwrote it) ▪Read quroum and write quorum share ≥ 1 replica. A B C D E read quorum write quorum",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 33,
      "chunk_id": "p33c1",
      "title": "Read and write quorums DSM06Replication and Consensus ▪In a system with n replicas: ▪If a write is a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Read and write quorums DSM06Replication and Consensus ▪In a system with n replicas: ▪If a write is acknowledged by w replicas (write quorum) ▪and we subsequently read from r replicas (read quorum) ▪and r + w > n, ▪… then the read will see the previously written value (or a value that subsequently overwrote it) ▪Read quroum and write quorum share ≥ 1 replica",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 34,
      "chunk_id": "p34c1",
      "title": "Read and write quorums DSM06Replication and Consensus ▪In a system with n replicas: ▪If a write is a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Typical: r = w = 𝒏+𝟏 𝟐for n = 3, 5, 7, …. (majority) ▪Reads can tolerate nr unavailable replicas, writes nw A B C D E read quorum write quorum",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 34,
      "chunk_id": "p34c2",
      "title": "Read and write quorums DSM06Replication and Consensus ▪In a system with n replicas: ▪If a write is a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Read repair DSM06Replication and Consensus A Client B t1 C ▪Update (t1 , v1) is more recent than (t0 , v0) since t0 < t1.",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 35,
      "chunk_id": "p35c1",
      "title": "Read repair DSM06Replication and Consensus A Client B t1 C ▪Update (t1 , v1) is more recent than (t0",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Read repair DSM06Replication and Consensus A Client B t1 C ▪Update (t1 , v1) is more recent than (t0 , v0) since t0 < t1. ▪Client helps to propagate (t1 , v1) to other replicas.",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 36,
      "chunk_id": "p36c1",
      "title": "Read repair DSM06Replication and Consensus A Client B t1 C ▪Update (t1 , v1) is more recent than (t0",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "State Machine Replication DSM06Replication and Consensus ▪So far we have used besteffort broadcast for replication",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 37,
      "chunk_id": "p37c1",
      "title": "State Machine Replication DSM06Replication and Consensus ▪So far we have used besteffort broadcast f",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪What about stronger broadcast models? ▪Total order broadcast: every node delivers the same message in the same order ▪State machine replication (SRM): ▪Total order broadcast every update to all replicas ▪Replica delivers update message: apply it to own state ▪Applying an update is deterministic ▪Replica is a state machine: starts in fixed initial state, goes through same sequence of state",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 37,
      "chunk_id": "p37c2",
      "title": "State Machine Replication DSM06Replication and Consensus ▪So far we have used besteffort broadcast f",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "▪Replica is a state machine: starts in fixed initial state, goes through same sequence of state transitions in the same order ⇒ all replicas end up in the same state",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 37,
      "chunk_id": "p37c3",
      "title": "State Machine Replication DSM06Replication and Consensus ▪So far we have used besteffort broadcast f",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "State Machine Replication Algorithm DSM06Replication and Consensus ▪Closely related ideas: ▪Serializable transactions (execute in delivery order) ▪Blockchains, distributed ledgers, smart contracts ▪Limitations; ▪Cannot update state immediately, has to wait for delivery through broadcast ▪Needs faulttolerant total order broadcast on request to perform update u do send u via total order broadcast",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 38,
      "chunk_id": "p38c1",
      "title": "State Machine Replication Algorithm DSM06Replication and Consensus ▪Closely related ideas: ▪Serializ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "total order broadcast on request to perform update u do send u via total order broadcast end on on delivering u through total order broadcast do update state using arbitrary deterministic logic end on",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 38,
      "chunk_id": "p38c2",
      "title": "State Machine Replication Algorithm DSM06Replication and Consensus ▪Closely related ideas: ▪Serializ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Database Leader Replica DSM06Replication and Consensus Client 1 L F Client 2 T1 T2 ▪Leader database replica L ensures total order broadcast ▪Follower F applies transaction log in commit order",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 39,
      "chunk_id": "p39c1",
      "title": "Database Leader Replica DSM06Replication and Consensus Client 1 L F Client 2 T1 T2 ▪Leader database ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Replication using causal (and weaker) broadcast DSM06Replication and Consensus ▪State machine replication uses total order broadcast. ▪Can we use weaker forms of broadcast too? ▪If replica state updates are commutative, replicas can process updates in differents orders and still end up in the same state",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 40,
      "chunk_id": "p40c1",
      "title": "Replication using causal (and weaker) broadcast DSM06Replication and Consensus ▪State machine replic",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Update f and g are commutative if f(g(x)) = g(f(x)) broadcast assumptions about state update function total order deterministic (SMR) causal Deterministic, concurrent updates commute reliable Deterministic, all updates commute besteffort Deterministic, commutative, idempotent, tolerates message loss",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 40,
      "chunk_id": "p40c2",
      "title": "Replication using causal (and weaker) broadcast DSM06Replication and Consensus ▪State machine replic",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Replication ▪Consensus DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 41,
      "chunk_id": "p41c1",
      "title": "Agenda ▪Replication ▪Consensus DSM06Replication and Consensus",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Properties of Consensus Algorithms DSM06Replication and Consensus ▪Termination: ▪Each correct process eventually decides on a value ▪Agreement: ▪All correct processes decide on the same value ▪Validity/Integrity: ▪The agreedupon value must be one of the proposed values",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 42,
      "chunk_id": "p42c1",
      "title": "Properties of Consensus Algorithms DSM06Replication and Consensus ▪Termination: ▪Each correct proces",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Faulttolerant Total Order Broadcast DSM06Replication and Consensus ▪Total order broadcast is very useful for state machine replication. ▪Can implement total order broadcast by sending all messages via a single leader",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 43,
      "chunk_id": "p43c1",
      "title": "Faulttolerant Total Order Broadcast DSM06Replication and Consensus ▪Total order broadcast is very us",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Can implement total order broadcast by sending all messages via a single leader. ▪Problem: What if leader crashes/becomes unavailable? ▪Manual failover: a human operator chooses a new leader, and reconfigures each node to use new leader ▪Used in many databases! Fine for planned maintenance. ▪Unplanned outage? Humans are slow, may take a long time until system recovers. .",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 43,
      "chunk_id": "p43c2",
      "title": "Faulttolerant Total Order Broadcast DSM06Replication and Consensus ▪Total order broadcast is very us",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Unplanned outage? Humans are slow, may take a long time until system recovers. . . ▪Can we automatically choose a new leader?",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 43,
      "chunk_id": "p43c3",
      "title": "Faulttolerant Total Order Broadcast DSM06Replication and Consensus ▪Total order broadcast is very us",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Consensus and Total Order Broadcast DSM06Replication and Consensus ▪Traditional formulation of consensus: several nodes want to come to agreement about a single value ▪In context of total order broadcast: This value is the next message to deliver ▪Once one node decides on a certain message order, all nodes will decide the same order ▪Consensus and total order broadcast are formally equivalent",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 44,
      "chunk_id": "p44c1",
      "title": "Consensus and Total Order Broadcast DSM06Replication and Consensus ▪Traditional formulation of conse",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "all nodes will decide the same order ▪Consensus and total order broadcast are formally equivalent ▪Common consensus algorithms: ▪Paxos: singlevalue consensus ▪MultiPaxos: generalisation to total order broadcast (more efficient for multiple rounds) ▪Raft: Total order broadcast by default",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 44,
      "chunk_id": "p44c2",
      "title": "Consensus and Total Order Broadcast DSM06Replication and Consensus ▪Traditional formulation of conse",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Consensus System Model DSM06Replication and Consensus ▪Paxos, Raft, and other assume a partially synchronous, crashrecovery system model",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 45,
      "chunk_id": "p45c1",
      "title": "Consensus System Model DSM06Replication and Consensus ▪Paxos, Raft, and other assume a partially syn",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Why not asynchronous? ▪FLP (Fischer, Lynch, Paterson) result: There is no deterministic consensus algorithm that is guaranteed to terminate in an asynchronous crashstop system model ▪Paxos, Raft, and others use clocks only for timeouts/failure detection to ensure progress. Safety (correctness) does not depend on timing.",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 45,
      "chunk_id": "p45c2",
      "title": "Consensus System Model DSM06Replication and Consensus ▪Paxos, Raft, and other assume a partially syn",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "System model: Node Behaviour DSM06Replication and Consensus Each node executes a specified algorithm, assuming one of the following: ▪Crashstop (failstop): ▪A node is faulty if it crashes (at any moment). ▪After crashing, it stops executing forever. ▪Crashrecovery (failrecovery): ▪A node may crash at any moment, losing its inmemory state. It may resume executing sometime later",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 46,
      "chunk_id": "p46c1",
      "title": "System model: Node Behaviour DSM06Replication and Consensus Each node executes a specified algorithm",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". It may resume executing sometime later. ▪Data stored on disk survives the crash. ▪Byzantine (failarbitrary): ▪A node is faulty if it deviates from the algorithm. ▪Faulty nodes may do anything, including crashing or malicious behaviour. A node that is not faulty is called \"correct\"",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 46,
      "chunk_id": "p46c2",
      "title": "System model: Node Behaviour DSM06Replication and Consensus Each node executes a specified algorithm",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "System model: Synchrony (Timing) Assumptions DSM06Replication and Consensus Assume one of the following for network and nodes: ▪Synchronous: ▪Message latency no greater than a known upper bound. ▪Nodes execute algorithm at a known speed. ▪Partially synchronous: ▪The system is asynchronous for some finite (but unknown) periods of time, synchronous otherwise",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 47,
      "chunk_id": "p47c1",
      "title": "System model: Synchrony (Timing) Assumptions DSM06Replication and Consensus Assume one of the follow",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Asynchronous: ▪Messages can be delayed arbitrarily. ▪Nodes can pause execution arbitrarily. ▪No timing guarantees at all.",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 47,
      "chunk_id": "p47c2",
      "title": "System model: Synchrony (Timing) Assumptions DSM06Replication and Consensus Assume one of the follow",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Homework: DSM06Replication and Consensus",
    "metadata": {
      "source": "Lecture_06.pdf",
      "page": 48,
      "chunk_id": "p48c1",
      "title": "Homework: DSM06Replication and Consensus",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 07 – Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 1,
      "chunk_id": "p1c1",
      "title": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 07 – Consistency",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪TwoPhase Commit ▪Consistency Models DSM07Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 2,
      "chunk_id": "p2c1",
      "title": "Agenda ▪TwoPhase Commit ▪Consistency Models DSM07Consistency",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Requirements for Replicated Data Replication transparency ▪Clients see logical objects (not several physical copies) ▪They access one logical item and receive a single result Consistency ▪All replicas should have “the same” state ▪E.g",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 3,
      "chunk_id": "p3c1",
      "title": "Requirements for Replicated Data Replication transparency ▪Clients see logical objects (not several ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". when a user of a calendar disconnects, the local copy may be inconsistent with the others and will need to be reconciled when they connect again ▪Connected clients using different copies should get consistent results ▪These issues are addressed in every distributed database DSM07Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 3,
      "chunk_id": "p3c2",
      "title": "Requirements for Replicated Data Replication transparency ▪Clients see logical objects (not several ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Requirements for Replicated Data Replication transparency ▪Clients see logical objects (not several physical copies) ▪They access one logical item and receive a single result Consistency ▪All replicas should have “the same” state ▪E.g",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 4,
      "chunk_id": "p4c1",
      "title": "Requirements for Replicated Data Replication transparency ▪Clients see logical objects (not several ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". when a user of a calendar disconnects, the local copy may be inconsistent with the others and will need to be reconciled when they connect again ▪Connected clients using different copies should get consistent results ▪These issues are addressed in every distributed database DSM07Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 4,
      "chunk_id": "p4c2",
      "title": "Requirements for Replicated Data Replication transparency ▪Clients see logical objects (not several ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Twophase commit (2PC) DSM07Consistency State machine for coordinator State machine for participant The client who initiated the computation acts as coordinator; processes required to commit are the participants. ▪Phase 1a: Coordinator sends VOTEREQUEST to participants (also called a prewrite) ▪Phase 1b: When participant receives VOTEREQUEST it returns either VOTECOMMIT or VOTEABORT to coordinator",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 5,
      "chunk_id": "p5c1",
      "title": "Twophase commit (2PC) DSM07Consistency State machine for coordinator State machine for participant T",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". If it sends VOTEABORT, it aborts its local computation ▪Phase 2a: Coordinator collects all votes; if all are VOTECOMMIT, it sends GLOBALCOMMIT to all participants, otherwise it sends GLOBALABORT ▪Phase 2b: Each participant waits for GLOBALCOMMIT or GLOBALABORT and handles accordingly.",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 5,
      "chunk_id": "p5c2",
      "title": "Twophase commit (2PC) DSM07Consistency State machine for coordinator State machine for participant T",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Twophase commit (2PC) DSM07Consistency The client who initiated the computation acts as coordinator; processes required to commit are the participants. ▪Phase 1a: Coordinator sends VOTEREQUEST to participants (also called a prewrite) ▪Phase 1b: When participant receives VOTEREQUEST it returns either VOTECOMMIT or VOTEABORT to coordinator",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 6,
      "chunk_id": "p6c1",
      "title": "Twophase commit (2PC) DSM07Consistency The client who initiated the computation acts as coordinator;",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". If it sends VOTEABORT, it aborts its local computation ▪Phase 2a: Coordinator collects all votes; if all are VOTECOMMIT, it sends GLOBALCOMMIT to all participants, otherwise it sends GLOBALABORT ▪Phase 2b: Each participant waits for GLOBALCOMMIT or GLOBALABORT and handles accordingly.",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 6,
      "chunk_id": "p6c2",
      "title": "Twophase commit (2PC) DSM07Consistency The client who initiated the computation acts as coordinator;",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Consistency …means many different things in different contexts: ▪ACID: a transaction transforms the database from one \"consistent\" state to another ▪Readafterwrite consistency: A client should see its own write in the next read ▪Replication: replica should be \"consistent\" with other replicas ▪\"consistent\" = in the same state? (when exactly?) ▪\"consistent\" = read operations return same result? →We",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 7,
      "chunk_id": "p7c1",
      "title": "Consistency …means many different things in different contexts: ▪ACID: a transaction transforms the ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "= in the same state? (when exactly?) ▪\"consistent\" = read operations return same result? →We need to choose a consistency model DSM07Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 7,
      "chunk_id": "p7c2",
      "title": "Consistency …means many different things in different contexts: ▪ACID: a transaction transforms the ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Datacentric consistency models Read and write operations ▪Wi(x)a: Process Pi writes value a to x ▪Ri(x)b: Process Pi reads value b from x ▪All data items initially have value NIL ▪Example DSM07Consistency P1 writes a to x. Then P2 reads x which not updated yet. Thus, it it still NIL. In the second read, x is updated and P2 reads a. *If obvious, the index is ommited. *",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 8,
      "chunk_id": "p8c1",
      "title": "Datacentric consistency models Read and write operations ▪Wi(x)a: Process Pi writes value a to x ▪Ri",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Definition: The result of any execution is the same as if the operations of all processes were executed in some sequential order, and the operations of each individual process appear in this sequence in the order specified by its program",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 9,
      "chunk_id": "p9c1",
      "title": "Definition: The result of any execution is the same as if the operations of all processes were execu",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". →all processes see the same interleaving of operations Sequential Consistency DSM07Consistency A sequentially consistent data store A data store that is not sequentially consistent",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 9,
      "chunk_id": "p9c2",
      "title": "Definition: The result of any execution is the same as if the operations of all processes were execu",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Three concurrent processes (initial values: 0) Possible execution sequences (not exhaustive) Sequential Consistency DSM07Consistency Signature: print output from P1, P2, and P3 concatenated in this order",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 10,
      "chunk_id": "p10c1",
      "title": "Three concurrent processes (initial values: 0) Possible execution sequences (not exhaustive) Sequent",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Sequential Consistency – Another Example DSM07Consistency ▪Is it okay that P1 reads a? ▪Is it okay that P2 reads b? ▪Is it okay that P1 reads a and P2 reads b?",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 11,
      "chunk_id": "p11c1",
      "title": "Sequential Consistency – Another Example DSM07Consistency ▪Is it okay that P1 reads a? ▪Is it okay t",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Sequential Consistency – Another Example DSM07Consistency ▪Is it okay that P1 reads a? ▪Yes ▪Is it okay that P2 reads b? ▪Yes ▪Is it okay that P1 reads a and P2 reads b? ▪No!",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 12,
      "chunk_id": "p12c1",
      "title": "Sequential Consistency – Another Example DSM07Consistency ▪Is it okay that P1 reads a? ▪Yes ▪Is it o",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Why? ▪For P1 to read a, W1(x)a must have happened after W2(x)b. ▪For P2 to read b, W2(y)b must have happened after W1(y)a. Sequential Consistency – Another Example DSM07Consistency ▪Is it okay that P1 reads a? ▪Yes ▪Is it okay that P2 reads b? ▪Yes ▪Is it okay that P1 reads a and P2 reads b? ▪No!",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 13,
      "chunk_id": "p13c1",
      "title": "Why? ▪For P1 to read a, W1(x)a must have happened after W2(x)b. ▪For P2 to read b, W2(y)b must have ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "▪Multiple interleavings of statements are possible. ▪A program needs to accept all valid combinations and work correctly for each of them. ▪Sequential consistency is not compositional Sequential Consistency DSM07Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 14,
      "chunk_id": "p14c1",
      "title": "▪Multiple interleavings of statements are possible. ▪A program needs to accept all valid combination",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "▪Multiple interleavings of statements are possible. ▪A program needs to accept all valid combinations and work correctly for each of them",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 15,
      "chunk_id": "p15c1",
      "title": "▪Multiple interleavings of statements are possible. ▪A program needs to accept all valid combination",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪A program needs to accept all valid combinations and work correctly for each of them. ▪Sequential consistency is not compositional ▪What we want: All operations behave as if executed on a single copy of the data (even if there are in fact multiple replicas) ▪Each operation should appear to take effect instantaneously at some moment between its start and completion",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 15,
      "chunk_id": "p15c2",
      "title": "▪Multiple interleavings of statements are possible. ▪A program needs to accept all valid combination",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". →Linearizability (aka atomic, strong, immediate, or external consistency) Sequential Consistency DSM07Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 15,
      "chunk_id": "p15c3",
      "title": "▪Multiple interleavings of statements are possible. ▪A program needs to accept all valid combination",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Linearizability ▪Is the system linearizable? ▪Does the system appear like there is only a single copy of the data? No! ▪Is this, in general, an acceptable user experience? ▪In which case, this would have been acceptable? DSM07Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 16,
      "chunk_id": "p16c1",
      "title": "Linearizability ▪Is the system linearizable? ▪Does the system appear like there is only a single cop",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Linearizability read(x) ⇒ v and write(x,1) correspond to Ri(x)v and Wi(x)a DSM07Consistency ▪Is the system linearizable?",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 17,
      "chunk_id": "p17c1",
      "title": "Linearizability read(x) ⇒ v and write(x,1) correspond to Ri(x)v and Wi(x)a DSM07Consistency ▪Is the ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Linearizability read(x) ⇒ v and write(x,1) correspond to Ri(x)v and Wi(x)a DSM07Consistency ▪Is the system linearizable? ▪First read happens before write. Returns 0. Fine. ▪Last read happens after the write. Returns 1. Fine. ▪But what about the other reads?",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 18,
      "chunk_id": "p18c1",
      "title": "Linearizability read(x) ⇒ v and write(x,1) correspond to Ri(x)v and Wi(x)a DSM07Consistency ▪Is the ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Linearizability ▪In a linearizable system we imagine that there must be some point in time (between the start and end of the write operation) at which the value of x atomically flips from 0 to 1. DSM07Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 19,
      "chunk_id": "p19c1",
      "title": "Linearizability ▪In a linearizable system we imagine that there must be some point in time (between ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Background: CompareandSwap (CAS) DSM07Consistency ▪cas(x, vold, vnew) ⇒ r means the client requested an atomic compareandswap operation. ▪If the current value of the register/data x equals vold, it should be atomically set vnew. The operation then returns ok. ▪Otherwise the operation leaves the register/data unchanged and returns error.",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 20,
      "chunk_id": "p20c1",
      "title": "Background: CompareandSwap (CAS) DSM07Consistency ▪cas(x, vold, vnew) ⇒ r means the client requested",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Linearizability DSM07Consistency To check whether operations are linearizable, we visualize when these operations take effect. If these effects monotonically increase in time, the operations are linearizable.",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 21,
      "chunk_id": "p21c1",
      "title": "Linearizability DSM07Consistency To check whether operations are linearizable, we visualize when the",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Implementing Linearizability (1/2) DSM07Consistency 1. Lock Mechanisms: To ensure operations are atomic, lock mechanisms can be used to centrally control access to a resource or data point. For example, distributed locking systems ensure that only one operation can be performed on a data point at any given time. 2",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 22,
      "chunk_id": "p22c1",
      "title": "Implementing Linearizability (1/2) DSM07Consistency 1. Lock Mechanisms: To ensure operations are ato",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". 2. Consensus Protocols: Protocols like Paxos or Raft ensure that a group of nodes agrees on the next state of a system before it is committed. This helps maintain a consistent view of the operation order across all nodes. 3. Quorum Reads and Writes: Operations are considered complete only after being confirmed by a majority (quorum) of nodes in the system",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 22,
      "chunk_id": "p22c2",
      "title": "Implementing Linearizability (1/2) DSM07Consistency 1. Lock Mechanisms: To ensure operations are ato",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". This ensures that read operations will encounter at least one node with the latest data after a write operation.",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 22,
      "chunk_id": "p22c3",
      "title": "Implementing Linearizability (1/2) DSM07Consistency 1. Lock Mechanisms: To ensure operations are ato",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Implementing Linearizability (2/2) DSM07Consistency 4. Atomic Broadcasts: These techniques ensure that all nodes receive and execute operations in the same consistent order, maintaining synchronized views across the system. 5. Transactional Mechanisms: Many systems use transactional storage and mechanisms, e.g., TwoPhase Commit (2PC), to treat sequences of operations as indivisible, atomic units",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 23,
      "chunk_id": "p23c1",
      "title": "Implementing Linearizability (2/2) DSM07Consistency 4. Atomic Broadcasts: These techniques ensure th",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". 6. Timestamp Ordering: Systems use timestamps to assign each operation a unique global timestamp, which dictates the order in which updates are applied across different nodes.",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 23,
      "chunk_id": "p23c2",
      "title": "Implementing Linearizability (2/2) DSM07Consistency 4. Atomic Broadcasts: These techniques ensure th",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Causal Consistency DSM07Consistency Definition: Writes that are potentially causally related must be seen by all processes in the same order. Concurrent writes may be seen in a different order on different machines. Is the sequence on the left … ▪… sequentially … ▪… causally … … consistent?",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 24,
      "chunk_id": "p24c1",
      "title": "Causal Consistency DSM07Consistency Definition: Writes that are potentially causally related must be",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Causal Consistency DSM07Consistency Definition: Writes that are potentially causally related must be seen by all processes in the same order. Concurrent writes may be seen in a different order on different machines.",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 25,
      "chunk_id": "p25c1",
      "title": "Causal Consistency DSM07Consistency Definition: Writes that are potentially causally related must be",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Causal Consistency DSM07Consistency Definition: Writes that are potentially causally related must be seen by all processes in the same order. Concurrent writes may be seen in a different order on different machines. A violation of a causallyconsistent store A correct sequence of events in a causallyconsistent store",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 26,
      "chunk_id": "p26c1",
      "title": "Causal Consistency DSM07Consistency Definition: Writes that are potentially causally related must be",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Causal ConsistencyExercise DSM07Consistency What will be the results of R3(x) and R4(y)?",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 27,
      "chunk_id": "p27c1",
      "title": "Causal ConsistencyExercise DSM07Consistency What will be the results of R3(x) and R4(y)?",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Causal ConsistencyExercise DSM07Consistency What will be the results of R3(x) and R4(y)? R3(x) – a, because: W1(x)a → R2(x)a → W2(y)b → R3(y)b → R3(x)?",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 28,
      "chunk_id": "p28c1",
      "title": "Causal ConsistencyExercise DSM07Consistency What will be the results of R3(x) and R4(y)? R3(x) – a, ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Causal ConsistencyExercise DSM07Consistency What will be the results of R3(x) and R4(y)? R3(x) – a, because: W1(x)a → R2(x)a → W2(y)b → R3(y)b → R3(x)? R4(y) – NIL or b, because there is no causal relationship between W2(y)b and R4(y)",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 29,
      "chunk_id": "p29c1",
      "title": "Causal ConsistencyExercise DSM07Consistency What will be the results of R3(x) and R4(y)? R3(x) – a, ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Eventual Consistency ▪Linearizability advantages: ▪Makes a distributed system behave as if it were nondistributed ▪Simple for applications to use ▪Downsides: ▪Performance cost: lots of messages and waiting for responses ▪Scalability limits: leader can be a bottleneck ▪Availability problems: if you can't contact a quorum of nodes, you can't process any operations ▪Eventual consistency: a weaker",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 30,
      "chunk_id": "p30c1",
      "title": "Eventual Consistency ▪Linearizability advantages: ▪Makes a distributed system behave as if it were n",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "can't contact a quorum of nodes, you can't process any operations ▪Eventual consistency: a weaker model than linearizability",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 30,
      "chunk_id": "p30c2",
      "title": "Eventual Consistency ▪Linearizability advantages: ▪Makes a distributed system behave as if it were n",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". DSM07Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 30,
      "chunk_id": "p30c3",
      "title": "Eventual Consistency ▪Linearizability advantages: ▪Makes a distributed system behave as if it were n",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Eventual Consistency ▪Weakest form of consistency ▪All replicas converge toward identical copies, given the absence of writewrite conflicts. ▪Requirement: Updates guaranteed to propagate to all replicas. ▪WriteWrite Conflicts: Resolvable, especially with a small group of processes performing updates",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 31,
      "chunk_id": "p31c1",
      "title": "Eventual Consistency ▪Weakest form of consistency ▪All replicas converge toward identical copies, gi",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪WriteWrite Conflicts: Resolvable, especially with a small group of processes performing updates. ▪Conflict Resolution: In conflicts, one write operation is globally declared as the \"winner,\" overwriting conflicting operations, manual resolution (merge, conflicting copies) ▪Implementation Cost: Eventual consistency is often cheap to implement in practice. DSM07Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 31,
      "chunk_id": "p31c2",
      "title": "Eventual Consistency ▪Weakest form of consistency ▪All replicas converge toward identical copies, gi",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Consisteny Models DSM07Consistency Consistency Model Guarantee Strict Consistency Every read operation returns the most recent write based on a global timeline. Requires total global knowledge. Linearizability Operations appear instantaneously and globally in the order they were executed. Each operation seems to occur at a single point in time",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 32,
      "chunk_id": "p32c1",
      "title": "Consisteny Models DSM07Consistency Consistency Model Guarantee Strict Consistency Every read operati",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Each operation seems to occur at a single point in time. Sequential Consistency Operations appear in a single, consistent order that is the same for all processes, but not necessarily in realtime order. Causal Consistency Causally related operations appear in the correct order. Unrelated operations may appear in any order",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 32,
      "chunk_id": "p32c2",
      "title": "Consisteny Models DSM07Consistency Consistency Model Guarantee Strict Consistency Every read operati",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Unrelated operations may appear in any order. Eventual Consistency Guarantees that all copies will converge to the same value eventually if no new updates are made allowing temporary inconsistencies. Weak Consistency Provides no guarantees on the order or visibility of operations often prioritizing responsiveness and availability.",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 32,
      "chunk_id": "p32c3",
      "title": "Consisteny Models DSM07Consistency Consistency Model Guarantee Strict Consistency Every read operati",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "The CAP theorem Any networked system providing shared data can provide only two of the following three properties: ▪Consistency, by which a shared and replicated data item appears as a single, uptodate copy ▪Availability, by which updates will always be eventually executed ▪Partitioning: Tolerant to the partitioning of a process group. DSM07Consistency",
    "metadata": {
      "source": "Lecture_07.pdf",
      "page": 33,
      "chunk_id": "p33c1",
      "title": "The CAP theorem Any networked system providing shared data can provide only two of the following thr",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 1,
      "chunk_id": "p1c1",
      "title": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 03 – P2P & Naming",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Naming • A name in a distributed system is a string of bits or characters that is used to refer to an entity. • Addresses are a special kind of names and refer to an access point of an entity. • Access points are used to contact entities • Identifiers are special types of addresses: 1. An identifier refers to at most one entity 2. Each entity is referred to by at most one identifier 3",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 2,
      "chunk_id": "p2c1",
      "title": "Naming • A name in a distributed system is a string of bits or characters that is used to refer to a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Each entity is referred to by at most one identifier 3. An identifier always refers to the same entity DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 2,
      "chunk_id": "p2c2",
      "title": "Naming • A name in a distributed system is a string of bits or characters that is used to refer to a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "PeertoPeer Systems peer Etymology: Middle English, from Middle French per, from per, adjective, equal, from Latin par 1 : one that is of equal standing with another : EQUAL; especially : one belonging to the same societal group especially based on age, grade, or status DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 3,
      "chunk_id": "p3c1",
      "title": "PeertoPeer Systems peer Etymology: Middle English, from Middle French per, from per, adjective, equa",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Definitions Various definitions, for example: PeertoPeer is a class of applications that takes advantage of resources [...] available at the edges of the Internet. ... peertopeer nodes must operate outside the DNS and have [...] autonomy from central servers. Clay Shirky DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 4,
      "chunk_id": "p4c1",
      "title": "Definitions Various definitions, for example: PeertoPeer is a class of applications that takes advan",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Definitions Another one: Peertopeer systems are distributed systems consisting of interconnected nodes able to selforganize into network topologies with the purpose of sharing resources […], capable of adapting to failures and accommodating transient populations of nodes while maintaining acceptable connectivity and performance, without requiring the intermediation or support of a global",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 5,
      "chunk_id": "p5c1",
      "title": "Definitions Another one: Peertopeer systems are distributed systems consisting of interconnected nod",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "connectivity and performance, without requiring the intermediation or support of a global centralized server or authority",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 5,
      "chunk_id": "p5c2",
      "title": "Definitions Another one: Peertopeer systems are distributed systems consisting of interconnected nod",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". AndroutsellisTheotokis and Spinellis DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 5,
      "chunk_id": "p5c3",
      "title": "Definitions Another one: Peertopeer systems are distributed systems consisting of interconnected nod",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts • Periodically using socalled newsfeeds • News server are organized in an overlay network • Forwarding of messages to all interested neighbours • Prevention of forwarding loops: messages contain a history of visited news servers • The Usenet is an early (and current) example of a P2P system DSM03 –",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 6,
      "chunk_id": "p6c1",
      "title": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "of visited news servers • The Usenet is an early (and current) example of a P2P system DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 6,
      "chunk_id": "p6c2",
      "title": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts • Periodically using socalled newsfeeds • News server are organized in an overlay network • Forwarding of messages to all interested neighbours • Prevention of forwarding loops: messages contain a history of visited news servers • The Usenet is an early (and current) example of a P2P system DSM03 –",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 7,
      "chunk_id": "p7c1",
      "title": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "of visited news servers • The Usenet is an early (and current) example of a P2P system DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 7,
      "chunk_id": "p7c2",
      "title": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Application Classes using P2P • Communication and collaboration between users • Goal: Applications that enable direct communication between peers • For example, chat systems based on Jabber, VoIP systems like Skype • Distributed Computing • Goal: Sharing of processing power between peers • Example: Seti@home, genome@home • Internet Service Support • Goal: Support of Internet services based on P2P",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 8,
      "chunk_id": "p8c1",
      "title": "Application Classes using P2P • Communication and collaboration between users • Goal: Applications t",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Seti@home, genome@home • Internet Service Support • Goal: Support of Internet services based on P2P • Example: P2P multicast systems DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 8,
      "chunk_id": "p8c2",
      "title": "Application Classes using P2P • Communication and collaboration between users • Goal: Applications t",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Application Classes using P2P • Database systems • Goal: couple multiple independent databases • Examples: database replication, distributed query processing, e.g., Bayou • Content Distribution • Goal: make content available to users • Examples: file sharing (Gnutella, Kazaa, etc.), distributed content storage and lookup (Chord, CAN, etc.) • Main focus of this chapter DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 9,
      "chunk_id": "p9c1",
      "title": "Application Classes using P2P • Database systems • Goal: couple multiple independent databases • Exa",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Discussion • Why not use servers? • Communication: SMTP, Videoconference Systems • Computation: Elastic Cloud Computing • Databases: pick one out of thousand • Content distribution: iTunes/AppStore sells everything... • Is there a benefit in using P2P technology? DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 10,
      "chunk_id": "p10c1",
      "title": "Discussion • Why not use servers? • Communication: SMTP, Videoconference Systems • Computation: Elas",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Organizing Servers on the Internet • The Internet assume(s|d) computers to • Be 24/7 online • Have a fixed IP address • Thus, they can be managed in registers, such as DNS • However, this is no longer true • Mobility: computers roam through different networks • IPAddress shortage: multiplex IP Adresses (NAT) • Security: block distinct services DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 11,
      "chunk_id": "p11c1",
      "title": "Organizing Servers on the Internet • The Internet assume(s|d) computers to • Be 24/7 online • Have a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Main objective of P2P Systems • Provide an overlay network on top of the Internet • Overlay: nodes are processes that are connected to each other using the underlying network • Overlay addresses and management services are provided • Aim at integration of nodes that join sporadically DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 12,
      "chunk_id": "p12c1",
      "title": "Main objective of P2P Systems • Provide an overlay network on top of the Internet • Overlay: nodes a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Overlay Networks DSM03 – P2P & Naming Overlay Underlay",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 13,
      "chunk_id": "p13c1",
      "title": "Overlay Networks DSM03 – P2P & Naming Overlay Underlay",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Overlay Networks DSM03 – P2P & Naming Overlay Underlay",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 14,
      "chunk_id": "p14c1",
      "title": "Overlay Networks DSM03 – P2P & Naming Overlay Underlay",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Overlay Networks DSM03 – P2P & Naming Overlay Underlay",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 15,
      "chunk_id": "p15c1",
      "title": "Overlay Networks DSM03 – P2P & Naming Overlay Underlay",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Functionality of P2P System • Join the network • Connecting nodes need to know at least one other node of the network • Exchange neighbor information • Often contains an Overlay address and an Underlay address • Route messages to a target / neighbor • Repair for disconnecting nodes • Disconnect gracefully from network DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 16,
      "chunk_id": "p16c1",
      "title": "Functionality of P2P System • Join the network • Connecting nodes need to know at least one other no",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Functionality of P2P Content Distribution Systems DSM03 – P2P & Naming Minimal functionality required • Insert new content • Locate (search for) content • Retrieve content Optional functionality (often harder to achieve) • Deletion: remove an object (and its copies!) • Update: apply changes to an existing object • Expiration: remove objects after a specified time • Versioning: • each object is",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 17,
      "chunk_id": "p17c1",
      "title": "Functionality of P2P Content Distribution Systems DSM03 – P2P & Naming Minimal functionality require",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "existing object • Expiration: remove objects after a specified time • Versioning: • each object is readonly (new versions) • Replace all existing copies",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 17,
      "chunk_id": "p17c2",
      "title": "Functionality of P2P Content Distribution Systems DSM03 – P2P & Naming Minimal functionality require",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Architectural properties: Degree of Centralization • Centralization in this context: →Are there any centralized components necessary to run a given system? • Various degrees of centralization can be found in systems • Purely decentralized architectures • Partially centralized architectures • Hybrid decentralized architectures DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 18,
      "chunk_id": "p18c1",
      "title": "Architectural properties: Degree of Centralization • Centralization in this context: →Are there any ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Purely Decentralized Architectures • All nodes perform the same task • May hinder scalability • All nodes are in the role of SERVer and cliENT (SERVENT) • Example: Gnutella 0.4, Chord DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 19,
      "chunk_id": "p19c1",
      "title": "Purely Decentralized Architectures • All nodes perform the same task • May hinder scalability • All ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Partially Centralized Architectures • Similar to purely decentralized • However, some nodes are more important • Notion of socalled supernodes (or superpeers) • Supernodes: • Often act as local index • Provide information about the content stored at local peers • Are dynamically elected • Do not constitute a single point of failure DSM03 – P2P & Naming „normal“ peers supernodes",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 20,
      "chunk_id": "p20c1",
      "title": "Partially Centralized Architectures • Similar to purely decentralized • However, some nodes are more",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Hybrid Decentralized Architectures • Centralized servers exist for some tasks, e.g. • Maintain user data (access control) • Maintain directories of metadata about available files • Exchange of data directly between peers • Sometimes called „peerthroughpeer“ or „broker mediated“ systems • Central components constitute single points of failure! DSM03 – P2P & Naming Download of content Server lookup",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 21,
      "chunk_id": "p21c1",
      "title": "Hybrid Decentralized Architectures • Centralized servers exist for some tasks, e.g. • Maintain user ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Network Structure • Overlay network: • network which is built “on top” of another network • Overlay networks may be created and maintained as: • Unstructured overlay networks • Structured overlay networks DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 22,
      "chunk_id": "p22c1",
      "title": "Network Structure • Overlay network: • network which is built “on top” of another network • Overlay ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Unstructured Overlays • Creation of overlay: nondeterministic as nodes and content are added/removed • Search methods (examples): • Brute force: query flooding (breadth/depthfirst) →High message overhead • Random walk →May not find all items that match • Usually cope very well with transient node populations • Insertion and removal of peers is easy • Examples: Gnutella, Kazaa, FreeHaven DSM03 –",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 23,
      "chunk_id": "p23c1",
      "title": "Unstructured Overlays • Creation of overlay: nondeterministic as nodes and content are added/removed",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "populations • Insertion and removal of peers is easy • Examples: Gnutella, Kazaa, FreeHaven DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 23,
      "chunk_id": "p23c2",
      "title": "Unstructured Overlays • Creation of overlay: nondeterministic as nodes and content are added/removed",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Structured Overlays • Content placed at precisely specified locations • Insertion and removal of peers is more complex • Structure is tightly controlled →must be maintained • Files may have to be migrated on insertion/removal of peers • Search methods depend on structure (examples): • Binary search along a ring, e.g., Chord • Alphanumeric search over multiple rings, e.g., SkipNet, SkABNet •",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 24,
      "chunk_id": "p24c1",
      "title": "Structured Overlays • Content placed at precisely specified locations • Insertion and removal of pee",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "along a ring, e.g., Chord • Alphanumeric search over multiple rings, e.g., SkipNet, SkABNet • Routing between regions in a Cartesian space, e.g., CAN (Content addressable network) DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 24,
      "chunk_id": "p24c2",
      "title": "Structured Overlays • Content placed at precisely specified locations • Insertion and removal of pee",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Unstructured Overlays: Gnutella ▪Structured Overlays: Chord DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 25,
      "chunk_id": "p25c1",
      "title": "Agenda ▪Unstructured Overlays: Gnutella ▪Structured Overlays: Chord DSM03 – P2P & Naming",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Unstructured Example: Gnutella • Application: file sharing – mainly MP3s... but • Objective: distributed search! • Gnutella is a protocol – not a product/implementation • Dates back to March 2000 by Frankel/Pepper • Initial version stopped • Open Source „conquered“ the development process DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 26,
      "chunk_id": "p26c1",
      "title": "Unstructured Example: Gnutella • Application: file sharing – mainly MP3s... but • Objective: distrib",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Gnutella System Model • P2P • No explicit client/server roles • Purely decentralized coordination model • Unstructured overlay • Gnutella nodes form a network on top of the Internet (overlay) • Servents first have to discover a servent part of the Gnutella network (not part of the protocol!) • Basic operations in the Gnutella network: • Discovery of further nodes • Queries DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 27,
      "chunk_id": "p27c1",
      "title": "Gnutella System Model • P2P • No explicit client/server roles • Purely decentralized coordination mo",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Gnutella Protocol: Descriptors • Ping: discover other hosts; Servents respond with 1 or more Pongs • Pong: response to Ping; includes address and #files shared • Query: issued to search the network • QueryHit: if query is matched in the local data set, servents issue QueryHitmessages with „enough information to acquire the data“ →Data access is not part of the protocol! • Push: servents behind",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 28,
      "chunk_id": "p28c1",
      "title": "Gnutella Protocol: Descriptors • Ping: discover other hosts; Servents respond with 1 or more Pongs •",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "information to acquire the data“ →Data access is not part of the protocol! • Push: servents behind firewalls likely restrict access to their Gnutella port →the requesting servant issues a Push in order to get the Query result send",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 28,
      "chunk_id": "p28c2",
      "title": "Gnutella Protocol: Descriptors • Ping: discover other hosts; Servents respond with 1 or more Pongs •",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". (cf. active vs. passive FTP) DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 28,
      "chunk_id": "p28c3",
      "title": "Gnutella Protocol: Descriptors • Ping: discover other hosts; Servents respond with 1 or more Pongs •",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Descriptor Routing • Descriptors are associated with a TTL (typically: 7) • Servents send Ping descriptors to others to discover new hosts • Each servent receiving a Ping • forwards Ping to servents it knows – as long as TTL > 0 and not to the neighbour issuing the Ping • returns one or more Pong DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 29,
      "chunk_id": "p29c1",
      "title": "Descriptor Routing • Descriptors are associated with a TTL (typically: 7) • Servents send Ping descr",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Descriptor Routing • Pong returns information about node • Port and IPAddress • Number of files shared • Number of KB shared • Routed along the Path of corresponding Ping (reverse path) • Query • Minimum speed (kb/sec) • Search criteria – free! not limited to files • Routing – similar to Pings DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 30,
      "chunk_id": "p30c1",
      "title": "Descriptor Routing • Pong returns information about node • Port and IPAddress • Number of files shar",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Descriptor Routing • QueryHit • Response to Query • Information about the query result and how to access it (IPAddr, Port#, ...) • Routing – like Pongs • Push • Sent along the QueryHit path • Contains servent’s address (IP, Port) where files should be „pushed to“ DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 31,
      "chunk_id": "p31c1",
      "title": "Descriptor Routing • QueryHit • Response to Query • Information about the query result and how to ac",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Issues Not Solved by the Protocol • Discovery of Gnutella network • How to find the first node to discover the network? 1. manually configure (the old days... Rumours, IRC) 2. host caches – many enter the network at the same place → performance? • Accessing result • File sharing: use http DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 32,
      "chunk_id": "p32c1",
      "title": "Issues Not Solved by the Protocol • Discovery of Gnutella network • How to find the first node to di",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Performance Issues • Gnutella protocol is based on flooding • Gnutella network topology does not reflect • structure of content providers wrt. content • structure of content providers wrt. to bandwidth • Ideally: • Nodes with high bandwidth/high data volume in the „center“ • But: • Clients tend to access the network from the same entry points (host caches) DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 33,
      "chunk_id": "p33c1",
      "title": "Performance Issues • Gnutella protocol is based on flooding • Gnutella network topology does not ref",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Some Numbers I Percentage of messages (4.9 Millions of messages over 48h): • Query: 54.80% • Pong: 26.90% • Ping: 14.80% • QueryHit: 2.80% • Push: 0.70% DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 34,
      "chunk_id": "p34c1",
      "title": "Some Numbers I Percentage of messages (4.9 Millions of messages over 48h): • Query: 54.80% • Pong: 2",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Some Numbers II DSM03 – P2P & Naming Average bandwidth usage (kBit/s) per node for Search (S) and Discovery (D) depending on TTL (number of nodes) and frequency: Rate ~500 nodes (TTL=2) ~4000 nodes (TTL=3) ~8000 nodes (TTL=4) 1/h S: 0.04 D: 0.08 S: 0.61 D: 1.10 S: 2.10 D: 3.20 1/min S: 2.50 D: 4.80 S: 36.80 D: 68.20 S: 127.00 D: 194.90 1/s S: 151.00 D: 288.00 S: 2,211.00 D: 4,099.40 S: 7,617.30 D:",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 35,
      "chunk_id": "p35c1",
      "title": "Some Numbers II DSM03 – P2P & Naming Average bandwidth usage (kBit/s) per node for Search (S) and Di",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "36.80 D: 68.20 S: 127.00 D: 194.90 1/s S: 151.00 D: 288.00 S: 2,211.00 D: 4,099.40 S: 7,617.30 D: 11,694.50 Note: default TTL=7! Only costs for Gnutella protocol; not file transfer",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 35,
      "chunk_id": "p35c2",
      "title": "Some Numbers II DSM03 – P2P & Naming Average bandwidth usage (kBit/s) per node for Search (S) and Di",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Freeriding Gnutella • P2P File sharing based on contribution of all peers • But: • 70 % of all users do not share files! • 50 % of all requests are answered by 1% of hosts • Freeriders are equally distributed DSM03 – P2P & Naming • Solutions? • Caching of files →implicit replication • Incentives: upload/download ratio (in a P2P system?)",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 36,
      "chunk_id": "p36c1",
      "title": "Freeriding Gnutella • P2P File sharing based on contribution of all peers • But: • 70 % of all users",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Gnutella Summary • Decentralized coordination model • Unstructured overlay • Not limited to file transfer • Flooding based discovery/search imposes scalability problems • Freeriders dominate • Organization of network does not reflect sharing/downloading DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 37,
      "chunk_id": "p37c1",
      "title": "Gnutella Summary • Decentralized coordination model • Unstructured overlay • Not limited to file tra",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Peer to Peer Lookup Services • Gnutella‘s discovery/search creates heavy load • General problem: efficient lookup of host which stores a data item • Dynamics of network changes • Hosts enter/leave systems • Decentralized control avoids single points of failures • Chord • Protocol for efficient lookup in dynamic peer2peer systems DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 38,
      "chunk_id": "p38c1",
      "title": "Peer to Peer Lookup Services • Gnutella‘s discovery/search creates heavy load • General problem: eff",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Unstructured Overlays: Gnutella ▪Structured Overlays: Chord DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 39,
      "chunk_id": "p39c1",
      "title": "Agenda ▪Unstructured Overlays: Gnutella ▪Structured Overlays: Chord DSM03 – P2P & Naming",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Chord Basics • Basic notations: • k: key • n: node from n1...nN • lookup(k) →n : map key to node responsible • Every node can associate data with a key • Problems: • Assignment of keys to nodes • Distributed knowledge: do all nodes need to know all mappings? DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 40,
      "chunk_id": "p40c1",
      "title": "Chord Basics • Basic notations: • k: key • n: node from n1...nN • lookup(k) →n : map key to node res",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Chord Organisation • Each key is assigned an id of length m bits →hash function • Hash function ensures equal distribution of keys among N nodes • Chord ring build from identifier circle modulo 2m: 0..2m1 • Nodes are integrated into Chord ring by hashing the host IP Address • Node with nearest id to key (clockwise) maintains it DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 41,
      "chunk_id": "p41c1",
      "title": "Chord Organisation • Each key is assigned an id of length m bits →hash function • Hash function ensu",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Chord Ring DSM03 – P2P & Naming 10 nodes storing 5 keys Next node clockwise to 10 is 14 N1 N56 N51 N48 N42 N38 N32 N21 N14 N8 K10 K30 K38 K54 K24",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 42,
      "chunk_id": "p42c1",
      "title": "Chord Ring DSM03 – P2P & Naming 10 nodes storing 5 keys Next node clockwise to 10 is 14 N1 N56 N51 N",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Query for identifier ID forwarded until two nodes straddle ID • Second of these two nodes maintains the information of the ID DSM03 – P2P & Naming n.find_successor(id): //executed on node n if (n < id) && (id <= successor) //(n, successor] straddle id return successor //clockwise node responsible",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 43,
      "chunk_id": "p43c1",
      "title": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Q",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "id) && (id <= successor) //(n, successor] straddle id return successor //clockwise node responsible else return successor.find_successor(id) //go ahead...",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 43,
      "chunk_id": "p43c2",
      "title": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Q",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Query for identifier ID forwarded until two nodes straddle ID • Second of these two nodes maintains the information of the ID DSM03 – P2P & Naming n.find_successor(id): //executed on node n if (n < id) && (id <= successor) //(n, successor] straddle id return successor //clockwise node responsible",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 44,
      "chunk_id": "p44c1",
      "title": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Q",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "id) && (id <= successor) //(n, successor] straddle id return successor //clockwise node responsible else return successor.find_successor(id) //go ahead...",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 44,
      "chunk_id": "p44c2",
      "title": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Q",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Query for identifier ID forwarded until two nodes straddle ID • Second of these two nodes maintains the information of the ID DSM03 – P2P & Naming n.find_successor(id): //executed on node n if id ∈ (n, successor] //(n, successor] straddle id return successor //clockwise node responsible else return",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 45,
      "chunk_id": "p45c1",
      "title": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Q",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "successor] //(n, successor] straddle id return successor //clockwise node responsible else return successor.find_successor(id) //go ahead...",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 45,
      "chunk_id": "p45c2",
      "title": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Q",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Chord Ring DSM03 – P2P & Naming (n < id) && (id <= successor) K46",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 46,
      "chunk_id": "p46c1",
      "title": "Chord Ring DSM03 – P2P & Naming (n < id) && (id <= successor) K46",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Chord Ring DSM03 – P2P & Naming (n < id) && (id <= successor) K58 (successor < n) && (n <= id) K46",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 47,
      "chunk_id": "p47c1",
      "title": "Chord Ring DSM03 – P2P & Naming (n < id) && (id <= successor) K58 (successor < n) && (n <= id) K46",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Chord Ring DSM03 – P2P & Naming (n < id) && (id <= successor) K58 (successor < n) && (n <= id) K46 K4 (successor < n) && (id <= successor)",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 48,
      "chunk_id": "p48c1",
      "title": "Chord Ring DSM03 – P2P & Naming (n < id) && (id <= successor) K58 (successor < n) && (n <= id) K46 K",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Query for identifier ID forwarded until two nodes straddle ID • Second of these two nodes maintains the information of the ID DSM03 – P2P & Naming n.find_successor(id): //executed on node n (n < id) && (id <= successor) || (successor < n) && (n <= id) || (successor < n) && (id <= successor) return",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 49,
      "chunk_id": "p49c1",
      "title": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Q",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "&& (id <= successor) || (successor < n) && (n <= id) || (successor < n) && (id <= successor) return successor //clockwise node responsible else return successor.find_successor(id) //go ahead...",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 49,
      "chunk_id": "p49c2",
      "title": "Simple Key Location • Minimal state information on nodes: each node „knows“ its direct successor • Q",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Chord Ring DSM03 – P2P & Naming Search for K38 starting on node N8 N1 N56 N51 N48 N42 N38 N32 N21 N14 N8 K10 K30 K38 K54 K24 32 < 38 <= 38 → Node 38 is responsible",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 50,
      "chunk_id": "p50c1",
      "title": "Chord Ring DSM03 – P2P & Naming Search for K38 starting on node N8 N1 N56 N51 N48 N42 N38 N32 N21 N1",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Scalable Key Location • Simple variant: • has linear search effort O(N) • Minimal state – only successor O(1) • Improvement: • Increase local state DSM03 – P2P & Naming • Question: • Search effort when all N nodes are stored at each node? • Effort when nodes enter/leave network? • Simple variant • Variant with N nodes stored locally • Any compromise? →Finger table",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 51,
      "chunk_id": "p51c1",
      "title": "Scalable Key Location • Simple variant: • has linear search effort O(N) • Minimal state – only succe",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Finger Table • Key length m bits • Each node maintains a finger table of length m • ith entry in finger table of node n: • first node s that succeeds n by (at least) 2i1 on the ring • s is ith finger of n • successor of n: 1st finger of n DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 52,
      "chunk_id": "p52c1",
      "title": "Finger Table • Key length m bits • Each node maintains a finger table of length m • ith entry in fin",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Finger TableExample DSM03 – P2P & Naming N1 N56 N51 N48 N42 N38 N32 N21 N8 +1 +2 +4 +8 +16 N14 Finger Table of N8 start node N8 + 1 = N9 N14 N8 + 2 = N10 N14 N8 + 4 = N12 N14 N8 + 8 = N16 N21 N8 + 16 = N24 N32 6 N8 + 32 = N40 N42",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 53,
      "chunk_id": "p53c1",
      "title": "Finger TableExample DSM03 – P2P & Naming N1 N56 N51 N48 N42 N38 N32 N21 N8 +1 +2 +4 +8 +16 N14 Finge",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Improved Search DSM03 – P2P & Naming n.find_successor(id): //executed on node n if id ∈ (n, successor] //(n, successor] straddle id return successor //clockwise node responsible else return successor.find_successor(id) //go ahead...",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 54,
      "chunk_id": "p54c1",
      "title": "Improved Search DSM03 – P2P & Naming n.find_successor(id): //executed on node n if id ∈ (n, successo",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Improved Search DSM03 – P2P & Naming n.find_successor(id): //executed on node n if id ∈ (n, successor] //(n, successor] straddle id return successor //clockwise node responsible else return find_predecessor(id).find_successor(id)",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 55,
      "chunk_id": "p55c1",
      "title": "Improved Search DSM03 – P2P & Naming n.find_successor(id): //executed on node n if id ∈ (n, successo",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Improved Search DSM03 – P2P & Naming n.find_successor(id): //executed on node n if id ∈ (n, successor] //(n, successor] straddle id return successor //clockwise node responsible else return find_predecessor(id).find_successor(id) n.find_predecessor(id): for i = m downto 1 if finger[i] ∈ (n, id) return finger[i] return n",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 56,
      "chunk_id": "p56c1",
      "title": "Improved Search DSM03 – P2P & Naming n.find_successor(id): //executed on node n if id ∈ (n, successo",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Finger TableExample DSM03 – P2P & Naming N1 N56 N51 N48 N42 N38 N32 N21 N8 Finger Table of N8 K54 N14 start node N8 + 1 = N9 N14 N8 + 2 = N10 N14 N8 + 4 = N12 N14 N8 + 8 = N16 N21 N8 + 16 = N24 N32 6 N8 + 32 = N40 N42",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 57,
      "chunk_id": "p57c1",
      "title": "Finger TableExample DSM03 – P2P & Naming N1 N56 N51 N48 N42 N38 N32 N21 N8 Finger Table of N8 K54 N1",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Search costs • Finger table • (n+2i1) mod 2m; 1<=i<=m • Each node has next half of the chord ring in finger table • Higher density of nodes with „nearer“ ids • Search • Each step cuts down search interval by half →Search costs? DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 58,
      "chunk_id": "p58c1",
      "title": "Search costs • Finger table • (n+2i1) mod 2m; 1<=i<=m • Each node has next half of the chord ring in",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Node Joins • Nodes may join (and leave) the Chord ring at any time • Each node additionally maintains predecessor node • Task to be done for node join: 1. Initialize predecessor and finger table of new node 2. Update fingers and predecessors of existing nodes 3. Transferring of keys necessary DSM03 – P2P & Naming n.join(n’): n.init_finger_table(n‘) update_others()",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 59,
      "chunk_id": "p59c1",
      "title": "Node Joins • Nodes may join (and leave) the Chord ring at any time • Each node additionally maintain",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Initializing Fingers and Predecessor DSM03 – P2P & Naming n.init_finger_table(n’): finger[1].node = n’.find_successor(finger[1].start) successor = finger[1].node predecessor = successor.predecessor successor.predecessor = n predecessor.successor = n for i = 1 to m1 if( finger[i+1].start ϵ [n, finger[i].node) ) finger[i+1].node = finger[i].node else finger[i+1].node =",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 60,
      "chunk_id": "p60c1",
      "title": "Initializing Fingers and Predecessor DSM03 – P2P & Naming n.init_finger_table(n’): finger[1].node = ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "finger[i+1].start ϵ [n, finger[i].node) ) finger[i+1].node = finger[i].node else finger[i+1].node = n’.find_successor(finger[i+1].start) start node N8 + 1 = N9 N14 N8 + 2 = N10 N14 N8 + 4 = N12 N14 N8 + 8 = N16 N21 N8 + 16 = N24 N32 6 N8 + 32 = N40 N42 „start“ can be easily computed",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 60,
      "chunk_id": "p60c2",
      "title": "Initializing Fingers and Predecessor DSM03 – P2P & Naming n.init_finger_table(n’): finger[1].node = ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Updating Fingers of Existing Nodes I • New node n may replace finger table entry on other node(s) • Naïve approach: announce n to all nodes →O(N) • More efficient: • Node n must be the ith finger of node p, if • p precedes n by at least 2i1 and • the ith finger of p succeeds n DSM03 – P2P & Naming start node N421 = N41 N38 N422 = N40 N38 N424 = N38 N38 N428 = N34 N32 N4216 = N26 N21 N4232 = N10 N8",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 61,
      "chunk_id": "p61c1",
      "title": "Updating Fingers of Existing Nodes I • New node n may replace finger table entry on other node(s) • ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "node N421 = N41 N38 N422 = N40 N38 N424 = N38 N38 N428 = N34 N32 N4216 = N26 N21 N4232 = N10 N8 „reversed“ finger table to better understand which node to update",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 61,
      "chunk_id": "p61c2",
      "title": "Updating Fingers of Existing Nodes I • New node n may replace finger table entry on other node(s) • ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Updating Fingers of Existing Nodes II DSM03 – P2P & Naming n.update_others(): //update all nodes that point to n for i = 1 to m p = find_predecessor(n – 2i1) //find last node p whose ith finger might be n p.update_finger_table(n, i) n.update_finger_table(s, i): //s is now the ith finger of node n if( s ϵ [n, finger[i].node) ) finger[i].node = s p = predecessor //maybe predecessor also needs to be",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 62,
      "chunk_id": "p62c1",
      "title": "Updating Fingers of Existing Nodes II DSM03 – P2P & Naming n.update_others(): //update all nodes tha",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "s ϵ [n, finger[i].node) ) finger[i].node = s p = predecessor //maybe predecessor also needs to be updated p.update_finger_table(s,i)",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 62,
      "chunk_id": "p62c2",
      "title": "Updating Fingers of Existing Nodes II DSM03 – P2P & Naming n.update_others(): //update all nodes tha",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Updating Fingers of Existing Nodes II DSM03 – P2P & Naming n.update_others(): //update all nodes that point to n for i = 1 to m p = find_predecessor(n – 2i1) //find last node p whose ith finger might be n p.update_finger_table(n, i) n.update_finger_table(s, i): //s is now the ith finger of node n if( s ϵ [n, finger[i].node) ) finger[i].node = s p = predecessor //maybe predecessor also needs to be",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 63,
      "chunk_id": "p63c1",
      "title": "Updating Fingers of Existing Nodes II DSM03 – P2P & Naming n.update_others(): //update all nodes tha",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "s ϵ [n, finger[i].node) ) finger[i].node = s p = predecessor //maybe predecessor also needs to be updated p.update_finger_table(s,i) start node N421 = N41 N38 N422 = N40 N38 N424 = N38 N38 N428 = N34 N32 N4216 = N26 N21 N4232 = N10 N8",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 63,
      "chunk_id": "p63c2",
      "title": "Updating Fingers of Existing Nodes II DSM03 – P2P & Naming n.update_others(): //update all nodes tha",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Leaving Nodes • Assumption: node n leaves the system • Set n.predecessor.successor = n.successor • Set n.successor.predecessor = n.predecessor • Fix finger tables of nodes • Transfer keys • Controlled exit – what if errors are happening? DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 64,
      "chunk_id": "p64c1",
      "title": "Leaving Nodes • Assumption: node n leaves the system • Set n.predecessor.successor = n.successor • S",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Chord Summary • Structured P2P • Requires global hash function • Efficient lookup • Single points of failure (as we learned it) • how to cope with that → see paper DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 65,
      "chunk_id": "p65c1",
      "title": "Chord Summary • Structured P2P • Requires global hash function • Efficient lookup • Single points of",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Peer to Peer Lookup Services I • Gnutella‘s discovery/search creates heavy load • General problem: efficient lookup of host which stores a data item • Dynamics of network changes • hosts enter/leave systems • decentralized control avoids single points of failures • Chord • Protocol for efficient lookup in dynamic peer2peer systems DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 66,
      "chunk_id": "p66c1",
      "title": "Peer to Peer Lookup Services I • Gnutella‘s discovery/search creates heavy load • General problem: e",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Peer to Peer Lookup Services II • Chord finds keys efficiently →What happens if we don’t know the correct key? • Chord keys are hashed • How can we find similar data? • How can I decide where my data is stored? • Chord has no replication →How can we account for peers dropping out? DSM03 – P2P & Naming",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 67,
      "chunk_id": "p67c1",
      "title": "Peer to Peer Lookup Services II • Chord finds keys efficiently →What happens if we don’t know the co",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Peer to Peer Lookup Services II • Chord finds keys efficiently →What happens if we don’t know the correct key? • Chord keys are hashed • How can we find similar data? • How can I decide where my data is stored? • Chord has no replication →How can we account for peers dropping out? DSM03 – P2P & Naming A Glimpse into Science Background: Locate relevant data streams in a decentralized sensor network",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 68,
      "chunk_id": "p68c1",
      "title": "Peer to Peer Lookup Services II • Chord finds keys efficiently →What happens if we don’t know the co",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Problem: 1. Sensor data is short lived and can not be evenly distributed using hash functions. 2. Data is owned by someone who wants to keep control. 3. Similar data streams should be located close to each other. Solution: Organize peers based on a selfselected attributevaluebased identifier, while keeping log(n) discovery and support ranges, selections and wildcards within the identifier.",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 68,
      "chunk_id": "p68c2",
      "title": "Peer to Peer Lookup Services II • Chord finds keys efficiently →What happens if we don’t know the co",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Name spaces • Flat names are good for machines, but not very convenient for humans to use. • Structured names that are composed from simple, humanreadable names. DSM03 – P2P & Naming • Naming graph: • A graph in which a leaf node represents a (named) entity. A directory node is an entity that refers to other nodes. • A directory node contains a table of (node identifier, edge label) pairs",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 69,
      "chunk_id": "p69c1",
      "title": "Name spaces • Flat names are good for machines, but not very convenient for humans to use. • Structu",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". • A directory node contains a table of (node identifier, edge label) pairs. A general naming graph with a single root node",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 69,
      "chunk_id": "p69c2",
      "title": "Name spaces • Flat names are good for machines, but not very convenient for humans to use. • Structu",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Naming Graphs DSM03 – P2P & Naming • Root node: no incoming, only outgoing edges. Entry point. Mostly only one. • Path: N:[label1, label2, label3, …, labeln] • absolute: starting from the root N: • relative: otherwise • Global name: same entity in all contexts • Local name: depends on the location • Example: Most file systems A general naming graph with a single root node",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 70,
      "chunk_id": "p70c1",
      "title": "Naming Graphs DSM03 – P2P & Naming • Root node: no incoming, only outgoing edges. Entry point. Mostl",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Name Resolution DSM03 – P2P & Naming To resolve a name, we need a directory node",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 71,
      "chunk_id": "p71c1",
      "title": "Name Resolution DSM03 – P2P & Naming To resolve a name, we need a directory node. How do we find tha",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". How do we find that (initial) node? Closure mechanism: The mechanism to select the implicit context from which to start name resolution • www.distributedsystems.net start at a DNS name server • /home/maarten/mbox start at the local file server • 0031 20 598 7784 dial a phone number • 77.167.55.6 route message to a specific IP address",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 71,
      "chunk_id": "p71c2",
      "title": "Name Resolution DSM03 – P2P & Naming To resolve a name, we need a directory node. How do we find tha",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Name Linking DSM03 – P2P & Naming • Hard link/path name: a name that is resolved by following a specific path in a naming graph from one node to another",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 72,
      "chunk_id": "p72c1",
      "title": "Name Linking DSM03 – P2P & Naming • Hard link/path name: a name that is resolved by following a spec",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". • Soft link: Allow a node N to contain a name of another node • First resolve N’s name (leading to N) • Read the content of N, yielding name • Name resolution continues with name One way or the other, we know where and how to start name resolution given name",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 72,
      "chunk_id": "p72c2",
      "title": "Name Linking DSM03 – P2P & Naming • Hard link/path name: a name that is resolved by following a spec",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mounting DSM03 – P2P & Naming • Name resolution can also be used to merge different name spaces transparently through mounting • Foreign name space: the name space that needs to be accessed • Mount point: the node in the current name space containing the node identifier of the foreign name space • Mounting point: the node in the foreign name space where to continue name resolution 1) Protocol 2)",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 73,
      "chunk_id": "p73c1",
      "title": "Mounting DSM03 – P2P & Naming • Name resolution can also be used to merge different name spaces tran",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mounting point: the node in the foreign name space where to continue name resolution 1) Protocol 2) Server 3) Mounting point",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 73,
      "chunk_id": "p73c2",
      "title": "Mounting DSM03 – P2P & Naming • Name resolution can also be used to merge different name spaces tran",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mounting DSM03 – P2P & Naming • Name resolution can also be used to merge different name spaces transparently through mounting • Foreign name space: the name space that needs to be accessed • Mount point: the node in the current name space containing the node identifier of the foreign name space • Mounting point: the node in the foreign name space where to continue name resolution 1) Protocol 2)",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 74,
      "chunk_id": "p74c1",
      "title": "Mounting DSM03 – P2P & Naming • Name resolution can also be used to merge different name spaces tran",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mounting point: the node in the foreign name space where to continue name resolution 1) Protocol 2) Server 3) Mounting point",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 74,
      "chunk_id": "p74c2",
      "title": "Mounting DSM03 – P2P & Naming • Name resolution can also be used to merge different name spaces tran",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Name Space Implementation DSM03 – P2P & Naming Goal: Distribute the name resolution process as well as name space management across multiple machines, by distributing nodes of the naming graph. Distinguish three levels • Global level: Consists of the highlevel directory nodes",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 75,
      "chunk_id": "p75c1",
      "title": "Name Space Implementation DSM03 – P2P & Naming Goal: Distribute the name resolution process as well ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Distinguish three levels • Global level: Consists of the highlevel directory nodes. Main aspect is that these directory nodes have to be jointly managed by different administrations • Administrational level: Contains midlevel directory nodes that can be grouped in such a way that each group can be assigned to a separate administration",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 75,
      "chunk_id": "p75c2",
      "title": "Name Space Implementation DSM03 – P2P & Naming Goal: Distribute the name resolution process as well ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". • Managerial level: Consists of lowlevel directory nodes within a single administration. Main issue is effectively mapping directory nodes to local name servers.",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 75,
      "chunk_id": "p75c3",
      "title": "Name Space Implementation DSM03 – P2P & Naming Goal: Distribute the name resolution process as well ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Name Space Implementation DSM03 – P2P & Naming Item Global Administrational Managerial Worldwide Organization Department Few Many Vast numbers Seconds Milliseconds Immediate Lazy Immediate Immediate Many None or few None Yes Yes Sometimes 1: Geographical scale 2: # Nodes 3: Responsiveness 4: Update propagation 5: # Replicas 6: Clientside caching?",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 76,
      "chunk_id": "p76c1",
      "title": "Name Space Implementation DSM03 – P2P & Naming Item Global Administrational Managerial Worldwide Org",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Iterative Name Resolution DSM03 – P2P & Naming 1. resolve(dir, [name1,..., nameK ]) sent to Server0 responsible for dir 2. Server0 resolves resolve(dir, name1) → dir1, returning the identification (address) of Server1, which stores dir1. 3. Client sends resolve(dir1, [name2 , ..., nameK ]) to Server1, etc.",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 77,
      "chunk_id": "p77c1",
      "title": "Iterative Name Resolution DSM03 – P2P & Naming 1. resolve(dir, [name1,..., nameK ]) sent to Server0 ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Recursive Name Resolution DSM03 – P2P & Naming 1. resolve(dir, [name1,..., nameK ]) sent to Server0 responsible for dir 2. Server0 resolves resolve(dir, name1) → dir1, and sends 3. resolve(dir1, [name2 , ..., nameK ]) to Server1, which stores dir1. 4. Server0 waits for result from Server1, and returns it to client.",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 78,
      "chunk_id": "p78c1",
      "title": "Recursive Name Resolution DSM03 – P2P & Naming 1. resolve(dir, [name1,..., nameK ]) sent to Server0 ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Example: The Domain Name System (DNS) DSM03 – P2P & Naming • Hierarchically organized name space with each node having exactly one incoming edge • edge label = node label. • domain: a subtree • domain name: a path name to a domain’s root node.",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 79,
      "chunk_id": "p79c1",
      "title": "Example: The Domain Name System (DNS) DSM03 – P2P & Naming • Hierarchically organized name space wit",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Modern DNS DSM03 – P2P & Naming The traditional organization of the implementation of DNS The modern organization of DNS 1. Organizations use external DNS resolvers 2. Client applications (browsers) bypass organizational settings and use a DNS of their choice 3. DNShosting is outsourced to thirdparties",
    "metadata": {
      "source": "Lecture_03.pdf",
      "page": 80,
      "chunk_id": "p80c1",
      "title": "Modern DNS DSM03 – P2P & Naming The traditional organization of the implementation of DNS The modern",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 1,
      "chunk_id": "p1c1",
      "title": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 01Introduction",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Who are we? DSM01Introduction Philipp Kisters philipp.kisters@uni... Janick Edinger janick.edinger@uni...",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 2,
      "chunk_id": "p2c1",
      "title": "Who are we? DSM01Introduction Philipp Kisters philipp.kisters@uni... Janick Edinger janick.edinger@u",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Organizational DSM01Introduction ▪The module consists of two parts ▪Lecture (Tuesday, 12:15 – 13:45, room D220) ▪Exercise (Tuesday, 14:15 – 15:45, room F009) ▪Materials, submissions, communication: Git and Mattermost https://git.informatik.unihamburg.de/dos/teaching/dsm_24 ▪Recommended Literature: ▪Distributed Systems, Maarten van Steen, Andrew S",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 3,
      "chunk_id": "p3c1",
      "title": "Organizational DSM01Introduction ▪The module consists of two parts ▪Lecture (Tuesday, 12:15 – 13:45,",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Tanenbaum, 4th Edition, 2023 ▪Distributed Systems – Concept and Design, George Coulouris, Jean Dollimore, Tim Kindberg, Gordon Blair, 5th Edition, 2012",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 3,
      "chunk_id": "p3c2",
      "title": "Organizational DSM01Introduction ▪The module consists of two parts ▪Lecture (Tuesday, 12:15 – 13:45,",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "DSM01Introduction Week Session Date Lecture Exercise Comment 15. Oct. 24 D220 F009 22. Oct. 24 D220 F009 29. Oct. 24 D220 D220 05. Nov. 24 D220 F009 12. Nov. 24 D220 F009 19. Nov. 24 D220 F009 26. Nov. 24 D220 F009 03. Dec. 24 no class (F009) Exercise on demand 10. Dec. 24 D220 F009 17. Dec. 24 D220 F009 07. Jan. 25 D220 F009 14. Jan. 25 D220 F009 21. Jan. 25 D220 F009 28. Jan. 25 D220 F009 04",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 4,
      "chunk_id": "p4c1",
      "title": "DSM01Introduction Week Session Date Lecture Exercise Comment 15. Oct. 24 D220 F009 22. Oct. 24 D220 ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Jan. 25 D220 F009 14. Jan. 25 D220 F009 21. Jan. 25 D220 F009 28. Jan. 25 D220 F009 04. Feb 25 First Exam ESA B Friday, 09:30 – 11:30 04. Mar 25 Second Exam ESA C Tuesday, 09:30 – 11:30",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 4,
      "chunk_id": "p4c2",
      "title": "DSM01Introduction Week Session Date Lecture Exercise Comment 15. Oct. 24 D220 F009 22. Oct. 24 D220 ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Goal of this course Gain an understanding of the analysis, development, and evaluation of distributed systems. DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 5,
      "chunk_id": "p5c1",
      "title": "Goal of this course Gain an understanding of the analysis, development, and evaluation of distribute",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Introduction to Distributed Systems ▪Categorization of Distributed Systems ▪Recap: Layered Architectures DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 6,
      "chunk_id": "p6c1",
      "title": "Agenda ▪Introduction to Distributed Systems ▪Categorization of Distributed Systems ▪Recap: Layered A",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Introduction to Distributed Systems ▪Categorization of Distributed Systems ▪Recap: Layered Architectures DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 7,
      "chunk_id": "p7c1",
      "title": "Agenda ▪Introduction to Distributed Systems ▪Categorization of Distributed Systems ▪Recap: Layered A",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 8,
      "chunk_id": "p8c1",
      "title": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction logically? physically? DNS is locally centralized but physically highly distributed.",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 9,
      "chunk_id": "p9c1",
      "title": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction logically? ph",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction logically? physically? DNS is locally centralized but physically highly distributed. • harder to implement • harder maintain • harder to make robust",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 10,
      "chunk_id": "p10c1",
      "title": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction logically? ph",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction logically? physically? DNS is locally centralized but physically highly distributed. • harder to implement • harder maintain • harder to make robust concurrency no global clock failures everywhere",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 11,
      "chunk_id": "p11c1",
      "title": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction logically? ph",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction logically? physically? DNS is locally centralized but physically highly distributed",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 12,
      "chunk_id": "p12c1",
      "title": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction logically? ph",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". • harder to implement • harder maintain • harder to make robust concurrency no global clock failures everywhere A Glimpse into Science Situation: In online games, dead reckoning is used to predict the path of a person or item between two updates. Problem: It might happen that between these two updates something important happens",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 12,
      "chunk_id": "p12c2",
      "title": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction logically? ph",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Problem: It might happen that between these two updates something important happens. Solution: Every player creates a log of all events and sends these logs as snapshots to all other player. Eventually, everybody has the same information and can agree on a correct state.",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 12,
      "chunk_id": "p12c3",
      "title": "Centralized Systems == Distributed Systems? Why Distributed Systems? DSM01Introduction logically? ph",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Why Distributed Systems? Distributed Systems == Decentralized Systems? DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 13,
      "chunk_id": "p13c1",
      "title": "Why Distributed Systems? Distributed Systems == Decentralized Systems? DSM01Introduction",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Why Distributed Systems? Distributed Systems == Decentralized Systems? DSM01Introduction A distributed system is a networked computer system in which processes and resources are sufficiently spread across multiple computers. A decentralized system is a networked computer system in which processes and resources are necessarily spread across multiple computers.",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 14,
      "chunk_id": "p14c1",
      "title": "Why Distributed Systems? Distributed Systems == Decentralized Systems? DSM01Introduction A distribut",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Perspectives on distributed systems ▪Architecture: How do components interact and depend on each other? ▪Process: What software (server, client, …) is running in the system? ▪Communication: How is data exchanged in the system? ▪Coordination: How do processes agree/synchronize (e.g., lack of global time)? ▪Naming: How do you identify resources? ▪Consistency and replication: How to keep services",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 15,
      "chunk_id": "p15c1",
      "title": "Perspectives on distributed systems ▪Architecture: How do components interact and depend on each oth",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "time)? ▪Naming: How do you identify resources? ▪Consistency and replication: How to keep services available and reliable? ▪Fault tolerance: How to keep a system alive? ▪Security: How to keep a system safe? DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 15,
      "chunk_id": "p15c2",
      "title": "Perspectives on distributed systems ▪Architecture: How do components interact and depend on each oth",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Properties and Challenges of Distributed Systems DSM01Introduction Resource Sharing Distribution Transparency Openness Scalability Dependability Failure Handling Heterogeneity Concurrency Security QoS",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 16,
      "chunk_id": "p16c1",
      "title": "Properties and Challenges of Distributed Systems DSM01Introduction Resource Sharing Distribution Tra",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "1) Resource Sharing ▪Make it easy for users and applications to access and share remote resources (storage, data, files, services, network infrastructure, CPU cycles) ▪Examples: ▪Distributed Computation (Our research: Tasklets) ▪PeertoPeer file sharing systems ▪Every web application and online collaboration tool ▪Cloud services DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 17,
      "chunk_id": "p17c1",
      "title": "1) Resource Sharing ▪Make it easy for users and applications to access and share remote resources (s",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "2) Distribution Transparency Transparency is the phenomenon by which a distributed system attempts to hide the fact that its processes and resources are physically distributed across multiple computers, possibly separated by large distances",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 18,
      "chunk_id": "p18c1",
      "title": "2) Distribution Transparency Transparency is the phenomenon by which a distributed system attempts t",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Distribution transparency is handled through many different techniques in a layer between applications and operating systems: a middleware layer DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 18,
      "chunk_id": "p18c2",
      "title": "2) Distribution Transparency Transparency is the phenomenon by which a distributed system attempts t",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "2) Distribution Transparency DSM01Introduction Transparency Description Access Access local and remote resources using identical operations Location Access resources without knowledge of their actual location Relocation Resources might move within a system without affecting the current operation Migration Hide that a resource may generally move to another location Replication Hide that multiple",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 19,
      "chunk_id": "p19c1",
      "title": "2) Distribution Transparency DSM01Introduction Transparency Description Access Access local and remo",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Hide that a resource may generally move to another location Replication Hide that multiple copies of an resource/object/service exist Concurrency Several processes can operate concurrently using shared resources Failure Complete tasks despite failures of hardware or software components",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 19,
      "chunk_id": "p19c2",
      "title": "2) Distribution Transparency DSM01Introduction Transparency Description Access Access local and remo",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "2) Distribution Transparency DSM01Introduction Transparency Description Access Access local and remote resources using identical operations Location Access resources without knowledge of their actual location Relocation Resources might move within a system without affecting the current operation Migration Hide that a resource may generally move to another location Replication Hide that multiple",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 20,
      "chunk_id": "p20c1",
      "title": "2) Distribution Transparency DSM01Introduction Transparency Description Access Access local and remo",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Hide that a resource may generally move to another location Replication Hide that multiple copies of an resource/object/service exist Concurrency Several processes can operate concurrently using shared resources Failure Complete tasks despite failures of hardware or software components URL NFS DNS GFS/HDFS Email NFS Mobile Phones",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 20,
      "chunk_id": "p20c2",
      "title": "2) Distribution Transparency DSM01Introduction Transparency Description Access Access local and remo",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "2) Distribution Transparency DSM01Introduction Discussion: How much distribution transparency is possible/good? Location Transparency: Minimum Latency: Speed of light (San Francisco – Amsterdam: 35ms) Failure Transparency: Missing network connection cannot be made up for Replication Transparency: Costly to keep all copies uptodate What about locationbased services? And how to distinguish a failing",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 21,
      "chunk_id": "p21c1",
      "title": "2) Distribution Transparency DSM01Introduction Discussion: How much distribution transparency is pos",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "to keep all copies uptodate What about locationbased services? And how to distinguish a failing server from a slow one?",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 21,
      "chunk_id": "p21c2",
      "title": "2) Distribution Transparency DSM01Introduction Discussion: How much distribution transparency is pos",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "3) Openness The openness of a computer system is the characteristic that determines whether the system can be extended and reimplemented in various ways. The system might consist of components from different origins. DSM01Introduction Interoperability: Multiple different implementations of services can coexist. Portability: Services can run on multiple (or all) types of systems",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 22,
      "chunk_id": "p22c1",
      "title": "3) Openness The openness of a computer system is the characteristic that determines whether the syst",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Portability: Services can run on multiple (or all) types of systems. Extensibility: New components can be added, others can be replaced.",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 22,
      "chunk_id": "p22c2",
      "title": "3) Openness The openness of a computer system is the characteristic that determines whether the syst",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "3) Openness How to implement it? ▪Define services through interfaces using an Interface Definition Language (IDL). ▪IDL serves as a languageindependent way to describe the methods, data structures, and interfaces that software components expose for remote interaction. ▪Separation between policies (What needs to be done?) from mechanisms (How is something done?). DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 23,
      "chunk_id": "p23c1",
      "title": "3) Openness How to implement it? ▪Define services through interfaces using an Interface Definition L",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "4) Quality of Service (QoS) Applications have different requirements such as reliability, security and performance",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 24,
      "chunk_id": "p24c1",
      "title": "4) Quality of Service (QoS) Applications have different requirements such as reliability, security a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Web services require responsiveness, i.e., a fast processing of requests ▪Streaming services use timecritical data that needs to be delivered in high volume and low time ▪Online gaming requires low latency and low packet loss Each critical resource must be reserved by the applications that require QoS, and there must be resource managers that provide guarantees. DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 24,
      "chunk_id": "p24c2",
      "title": "4) Quality of Service (QoS) Applications have different requirements such as reliability, security a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "5) Heterogeneity The Internet consists of multiple heterogeneous networks – but provides a homogeneous interface to communicate with all devices: The Internet Protocol (IP)",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 25,
      "chunk_id": "p25c1",
      "title": "5) Heterogeneity The Internet consists of multiple heterogeneous networks – but provides a homogeneo",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". However, there are differences in: DSM01Introduction ▪Hardware ▪Programming languages ▪Data representation ▪Availability ▪Security mechanisms ▪Link bandwidth and speed ▪Regulatory and legal frameworks This is the reason, why middlewares are important!",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 25,
      "chunk_id": "p25c2",
      "title": "5) Heterogeneity The Internet consists of multiple heterogeneous networks – but provides a homogeneo",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "6) Dependability \"A distributed system is one in which the failure of a computer you didn't even know existed can render your own computer unusable.“ (Leslie Lamport) DSM01Introduction Availability: probability that the system is operating correctly at any given moment Safety: when the system temporarily fails to operate correctly, no catastrophic event happens Reliability: the property that a",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 26,
      "chunk_id": "p26c1",
      "title": "6) Dependability \"A distributed system is one in which the failure of a computer you didn't even kno",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "fails to operate correctly, no catastrophic event happens Reliability: the property that a system can run continuously without failure Maintainability: the system can be repaired easily and timely",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 26,
      "chunk_id": "p26c2",
      "title": "6) Dependability \"A distributed system is one in which the failure of a computer you didn't even kno",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "6) Dependability DSM01Introduction An important goal of distributed systems is to mask failures, as well as mask the recovery from those failures. This masking is the essence of being able to tolerate faults, i.e., to be fault tolerant. A fault is a potential defect or deviation within a component or process that may lead to a problem but hasn't yet impacted system functionality",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 27,
      "chunk_id": "p27c1",
      "title": "6) Dependability DSM01Introduction An important goal of distributed systems is to mask failures, as ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". An error occurs when a fault manifests itself and leads to an observable, unintended behavior or state within the system, affecting system operation. A failure is the most severe outcome, resulting from one or more errors that render the system unable to perform its intended functions, often requiring recovery or mitigation measures",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 27,
      "chunk_id": "p27c2",
      "title": "6) Dependability DSM01Introduction An important goal of distributed systems is to mask failures, as ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". An unreliable communication channel A lost message A deadlock caused by waiting for the lost message",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 27,
      "chunk_id": "p27c3",
      "title": "6) Dependability DSM01Introduction An important goal of distributed systems is to mask failures, as ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "6) Dependability DSM01Introduction Transient Faults: ▪Occur briefly and then disappear. ▪May resolve by repeating the operation. ▪For example, a bird crossing a microwave beam – or a bit being flipped in a message. Intermittent Faults: ▪Occur, vanish, and reappear sporadically. ▪In hardware caused by loose contacts. ▪Challenging to diagnose and may work when examined",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 28,
      "chunk_id": "p28c1",
      "title": "6) Dependability DSM01Introduction Transient Faults: ▪Occur briefly and then disappear. ▪May resolve",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪In hardware caused by loose contacts. ▪Challenging to diagnose and may work when examined. Permanent Faults: ▪Persist until the faulty component is replaced. ▪Examples include burntout chips, software bugs, and diskhead crashes.",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 28,
      "chunk_id": "p28c2",
      "title": "6) Dependability DSM01Introduction Transient Faults: ▪Occur briefly and then disappear. ▪May resolve",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "7) Fault Handling Something went wrong. What now? DSM01Introduction Detecting failures: Some failures can be detected. Others cannot. This is not trivial and requires a lot of thoughts. Tolerating failures: Hiding failures does not always make sense. Sometimes they need to be made explicit. Masking failures: Failures in distributed systems are inevitable. However, they can be hidden",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 29,
      "chunk_id": "p29c1",
      "title": "7) Fault Handling Something went wrong. What now? DSM01Introduction Detecting failures: Some failure",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Masking failures: Failures in distributed systems are inevitable. However, they can be hidden. Recovery from failures: Even after a failure the system should be in the correct state. Discussion",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 29,
      "chunk_id": "p29c2",
      "title": "7) Fault Handling Something went wrong. What now? DSM01Introduction Detecting failures: Some failure",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "7) Fault Handling Something went wrong. What now? DSM01Introduction Detecting failures: Some failures can be detected. Others cannot. This is not trivial and requires a lot of thoughts. Tolerating failures: Hiding failures does not always make sense. Sometimes they need to be made explicit. Masking failures: Failures in distributed systems are inevitable. However, they can be hidden",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 30,
      "chunk_id": "p30c1",
      "title": "7) Fault Handling Something went wrong. What now? DSM01Introduction Detecting failures: Some failure",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Masking failures: Failures in distributed systems are inevitable. However, they can be hidden. Recovery from failures: Even after a failure the system should be in the correct state. Discussion A Glimpse into Science Background: In an offloading system, tasks are offloaded to remote enduser devices which might fail at any time. FaultAwareness: The system recognizes faults by missing heartbeats",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 30,
      "chunk_id": "p30c2",
      "title": "7) Fault Handling Something went wrong. What now? DSM01Introduction Detecting failures: Some failure",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". FaultAwareness: The system recognizes faults by missing heartbeats. FaultTolerance: Failures can occur. Task which are abort get reinitiated and executed on another device. FaultAvoidance: Devices are monitored. Their remaining lifetime and success probability gets estimated to select the most reliable devices.",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 30,
      "chunk_id": "p30c3",
      "title": "7) Fault Handling Something went wrong. What now? DSM01Introduction Detecting failures: Some failure",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "8) Scalability Many developers of modern distributed systems easily use the adjective “scalable” without making clear in what form their system actually scales",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 31,
      "chunk_id": "p31c1",
      "title": "8) Scalability Many developers of modern distributed systems easily use the adjective “scalable” wit",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Size: Number of users or processes, nodes, memory, users, … ▪Quite well solved today: Redundant servers, operating in parallel but independently ▪Geography: Distance between nodes ▪Latencies and unreliable communication channels ▪Administration: Number of administrative domains (“players”) ▪Policies (resource usage, payment, management, security) and humans ▪Solution: Make endusers collaborate",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 31,
      "chunk_id": "p31c2",
      "title": "8) Scalability Many developers of modern distributed systems easily use the adjective “scalable” wit",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "(resource usage, payment, management, security) and humans ▪Solution: Make endusers collaborate directly (P2P systems) – not administrative entities DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 31,
      "chunk_id": "p31c3",
      "title": "8) Scalability Many developers of modern distributed systems easily use the adjective “scalable” wit",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "8) Scalability Solutions and Pitfalls: ▪Hiding communication latencies ▪Asynchronous communication: Avoid blocking requestresponse pattern ▪Move logic to the client (e.g., as with JavaScript) DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 32,
      "chunk_id": "p32c1",
      "title": "8) Scalability Solutions and Pitfalls: ▪Hiding communication latencies ▪Asynchronous communication: ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "8) Scalability Solutions and Pitfalls: ▪Partitioning and Distribution ▪Splitting the problem into smaller parts and spread these parts across multiple resources ▪Examples are DNS (see right) or WWW ▪Idea: Looks like a single server but work is handles by millions of individual devices DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 33,
      "chunk_id": "p33c1",
      "title": "8) Scalability Solutions and Pitfalls: ▪Partitioning and Distribution ▪Splitting the problem into sm",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "8) Scalability Solutions and Pitfalls: ▪Replication ▪Contrast to distribution: Same task is performed by multiple devices. ▪Good for load balancing ▪Caching is one form of replication – and comes with multiple questions attached. ▪Replication requires consistency ▪What about (parallel) updates? ▪What about availability and, eventually, scalability? DSM01Introduction Discussion",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 34,
      "chunk_id": "p34c1",
      "title": "8) Scalability Solutions and Pitfalls: ▪Replication ▪Contrast to distribution: Same task is performe",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "9) Concurrency Typically, multiple clients can make use of the same service. ▪Multiple requests can be served at the same time. ▪Shared objects are altered – sometimes even on different devices ▪Distributed synchronization is required DSM01Introduction",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 35,
      "chunk_id": "p35c1",
      "title": "9) Concurrency Typically, multiple clients can make use of the same service. ▪Multiple requests can ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "10) Security A distributed system that is not secure, is not dependable DSM01Introduction Confidentiality: information is disclosed only to authorized parties Integrity: alterations can be made only in an authorized way Authentication: verifying the correctness of a claimed identity Authorization: does an identified entity has proper access rights? Trust: one entity can be assured that another",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 36,
      "chunk_id": "p36c1",
      "title": "10) Security A distributed system that is not secure, is not dependable DSM01Introduction Confidenti",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "does an identified entity has proper access rights? Trust: one entity can be assured that another will perform particular actions according to a specific expectation More about security: Verteilte Systeme und Systemsicherheit (SVS)",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 36,
      "chunk_id": "p36c2",
      "title": "10) Security A distributed system that is not secure, is not dependable DSM01Introduction Confidenti",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Conclusion: Pitfalls There are many false assumptions when developing distributed systems: DSM01Introduction The network is reliable The network is secure The network is homogeneous The topology does not change Latency is zero Bandwidth is infinite Transport cost is zero There is one administrator",
    "metadata": {
      "source": "Lecture_01.pdf",
      "page": 37,
      "chunk_id": "p37c1",
      "title": "Conclusion: Pitfalls There are many false assumptions when developing distributed systems: DSM01Intr",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 02 – Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 1,
      "chunk_id": "p1c1",
      "title": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 02 – Introduction II",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Properties and Challenges of Distributed Systems DSM02Introduction II Resource Sharing Distribution Transparency Openness Scalability Dependability Failure Handling Heterogeneity Concurrency Security QoS",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 2,
      "chunk_id": "p2c1",
      "title": "Properties and Challenges of Distributed Systems DSM02Introduction II Resource Sharing Distribution ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Pitfalls There are many false assumptions when developing distributed systems: DSM02Introduction II The network is reliable The network is secure The network is homogeneous The topology does not change Latency is zero Bandwidth is infinite Transport cost is zero There is one administrator",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 3,
      "chunk_id": "p3c1",
      "title": "Pitfalls There are many false assumptions when developing distributed systems: DSM02Introduction II ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Introduction to Distributed Systems ▪Categorization of Distributed Systems ▪Recap: Layered Architectures ▪PeertoPeer Systems DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 4,
      "chunk_id": "p4c1",
      "title": "Agenda ▪Introduction to Distributed Systems ▪Categorization of Distributed Systems ▪Recap: Layered A",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "A Coarse Categorization 1. Highperformance distributed computing ▪Gathering a lot of computational power from many devices 2. Distributed information systems ▪Business as usual – transactions and databases 3. Pervasive systems ▪Nodes. Nodes everywhere. DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 5,
      "chunk_id": "p5c1",
      "title": "A Coarse Categorization 1. Highperformance distributed computing ▪Gathering a lot of computational p",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "1. Highperformance distributed computing Cluster Computing: Grid Computing: Desktop Grids: DSM02Introduction II ▪Multiple interconnected homogeneous computers working together ▪Enables parallel processing for improved performance ▪Can range from small clusters to thousands of nodes ▪Distributed computing model",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 6,
      "chunk_id": "p6c1",
      "title": "1. Highperformance distributed computing Cluster Computing: Grid Computing: Desktop Grids: DSM02Intr",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Utilizes geographically dispersed and often heterogeneous resources ▪Facilitates resource sharing and collaboration across organizational boundaries ▪Utilizes idle processing power of networked personal computers or workstations ▪Aggregates the computational capabilities of many desktop machines ▪Efficient use of otherwise underutilized resources",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 6,
      "chunk_id": "p6c2",
      "title": "1. Highperformance distributed computing Cluster Computing: Grid Computing: Desktop Grids: DSM02Intr",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "1",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 7,
      "chunk_id": "p7c1",
      "title": "1. Highperformance distributed computing Cloud Computing: Edge Computing: Internet of Things: (IoT) ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Highperformance distributed computing Cloud Computing: Edge Computing: Internet of Things: (IoT) DSM02Introduction II ▪Serviceoriented technology providing ondemand access to computing resources ▪Resources include servers, storage, databases, networking, and software ▪Scalable and costeffective, accessed over the internet ▪Decentralized computing paradigm ▪Data processing occurs near the data",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 7,
      "chunk_id": "p7c2",
      "title": "1. Highperformance distributed computing Cloud Computing: Edge Computing: Internet of Things: (IoT) ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "accessed over the internet ▪Decentralized computing paradigm ▪Data processing occurs near the data source or \"edge\" of the network ▪Reduces latency, enhances realtime processing, and suits IoT and mobile applications ▪Network of interconnected physical devices and objects ▪These devices collect and exchange data over the internet ▪Enables automation, data analysis, and smart applications in",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 7,
      "chunk_id": "p7c3",
      "title": "1. Highperformance distributed computing Cloud Computing: Edge Computing: Internet of Things: (IoT) ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "and exchange data over the internet ▪Enables automation, data analysis, and smart applications in various domains",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 7,
      "chunk_id": "p7c4",
      "title": "1. Highperformance distributed computing Cloud Computing: Edge Computing: Internet of Things: (IoT) ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "The CloudEdge Continuum DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 8,
      "chunk_id": "p8c1",
      "title": "The CloudEdge Continuum DSM02Introduction II",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "2",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 9,
      "chunk_id": "p9c1",
      "title": "2. Distributed Information Systems DSM02Introduction II Situation: ▪Organizations dealing with numer",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Distributed Information Systems DSM02Introduction II Situation: ▪Organizations dealing with numerous networked applications ▪Interoperability among these applications is a challenge Basic Approach: ▪Networked applications run on servers, serving remote clients ▪Simplify integration by having clients combine requests for different applications ▪Clients send combined requests, collect responses,",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 9,
      "chunk_id": "p9c2",
      "title": "2. Distributed Information Systems DSM02Introduction II Situation: ▪Organizations dealing with numer",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "combine requests for different applications ▪Clients send combined requests, collect responses, and present a coherent result to the user Next Step: ▪Enable direct communication between applications ▪This leads to Enterprise Application Integration (EAI), streamlining communication and data exchange between different applications within an organization",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 9,
      "chunk_id": "p9c3",
      "title": "2. Distributed Information Systems DSM02Introduction II Situation: ▪Organizations dealing with numer",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "2. Distributed Information Systems DSM02Introduction II ▪Often, the data involved in a transaction is distributed across several servers. A TP Monitor is responsible for coordinating the execution of a transaction. It performs a distributed commit. • Occurs as a single, indivisible action. • Appears as if it happens all at once. • Maintains system integrity and correctness",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 10,
      "chunk_id": "p10c1",
      "title": "2. Distributed Information Systems DSM02Introduction II ▪Often, the data involved in a transaction i",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". • Appears as if it happens all at once. • Maintains system integrity and correctness. • Preserves the overall coherence of the system. • Operates without mutual interference. • Actions of one process do not disrupt others. • Committing changes ensures their permanence. • Data changes persist and are not lost. Atomic Consistent Isolated Durable",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 10,
      "chunk_id": "p10c2",
      "title": "2. Distributed Information Systems DSM02Introduction II ▪Often, the data involved in a transaction i",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "3. Pervasive Systems DSM02Introduction II “The most profound technologies are those that disappear. They weave themselves into the fabric of everyday life until they are indistinguishable from it.” – Mark Weiser – General idea: Computers become part of our daily lives, with no dedicated interfaces, but they are simply there",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 11,
      "chunk_id": "p11c1",
      "title": "3. Pervasive Systems DSM02Introduction II “The most profound technologies are those that disappear. ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". They use sensors and actuators to understand the context and to react on behalf of the user.",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 11,
      "chunk_id": "p11c2",
      "title": "3. Pervasive Systems DSM02Introduction II “The most profound technologies are those that disappear. ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "3. Pervasive Systems DSM02Introduction II 1) Ubiquitous Computing Systems Definition: Ubiquitous computing, also known as pervasive computing, refers to the concept of seamlessly integrating computation into everyday life. Key Characteristics: ▪Continuous connectivity: Devices are always connected to the internet or a network. ▪Contextawareness: Systems adapt to users' context and needs",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 12,
      "chunk_id": "p12c1",
      "title": "3. Pervasive Systems DSM02Introduction II 1) Ubiquitous Computing Systems Definition: Ubiquitous com",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Contextawareness: Systems adapt to users' context and needs. ▪Seamless interaction: Users can interact with computing resources effortlessly. Examples: ▪Smart homes, IoT devices, wearable technology.",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 12,
      "chunk_id": "p12c2",
      "title": "3. Pervasive Systems DSM02Introduction II 1) Ubiquitous Computing Systems Definition: Ubiquitous com",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "3. Pervasive Systems DSM02Introduction II 2) Mobile Computing Systems Definition: Mobile computing involves the use of portable devices that can be used while in motion, providing connectivity and flexibility. Key Characteristics: ▪Mobility: Devices are designed for use on the go. ▪Wireless communication: Mobile devices typically rely on wireless networks",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 13,
      "chunk_id": "p13c1",
      "title": "3. Pervasive Systems DSM02Introduction II 2) Mobile Computing Systems Definition: Mobile computing i",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Wireless communication: Mobile devices typically rely on wireless networks. ▪Portability: Devices are compact and lightweight. Examples: ▪Smartphones, tablets, laptops, and GPS devices.",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 13,
      "chunk_id": "p13c2",
      "title": "3. Pervasive Systems DSM02Introduction II 2) Mobile Computing Systems Definition: Mobile computing i",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "3. Pervasive Systems DSM02Introduction II 3) Sensor Networks Definition: Sensor networks are collections of spatially distributed sensors that collaborate to monitor and collect data from the environment. Key Characteristics: ▪Distributed sensors: Multiple sensors are deployed across an area. ▪Data collection: Sensors continuously gather information",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 14,
      "chunk_id": "p14c1",
      "title": "3. Pervasive Systems DSM02Introduction II 3) Sensor Networks Definition: Sensor networks are collect",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Data collection: Sensors continuously gather information. ▪Networked communication: Sensors share data through a network. Examples: ▪Environmental monitoring, industrial automation, healthcare applications.",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 14,
      "chunk_id": "p14c2",
      "title": "3. Pervasive Systems DSM02Introduction II 3) Sensor Networks Definition: Sensor networks are collect",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Introduction to Distributed Systems ▪Categorization of Distributed Systems ▪Recap: Layered Architectures ▪PeertoPeer Systems DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 15,
      "chunk_id": "p15c1",
      "title": "Agenda ▪Introduction to Distributed Systems ▪Categorization of Distributed Systems ▪Recap: Layered A",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Software Layers in Distributed Systems Computerand NetworkHardware Operating System Middleware Applications Platform ▪Independent of the respective platform ▪Builds on middleware API ▪Hides platform heterogeneity ▪Provides uniform API ▪Provides an interface to the system resources DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 16,
      "chunk_id": "p16c1",
      "title": "Software Layers in Distributed Systems Computerand NetworkHardware Operating System Middleware Appli",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Layered Architectures Problem: The design of communicating systems is a complex task • Numerous complex functions with different levels of abstraction. • Interaction of these functions is necessary Solution: Layered Architectures • Each layer realizes one abstraction level • The totality of layers is also called protocol stack DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 17,
      "chunk_id": "p17c1",
      "title": "Layered Architectures Problem: The design of communicating systems is a complex task • Numerous comp",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Layered Architectures Layer k1/k Interface Physical Medium Layer 1 Layer 1 Layer k Layer k Layer k+1 Layer k+1 … … Layer k/k+1 Interface Layer k Protocol Layer k+1 Protocol Layer 1 Protocol Layer 1/2 Interface Interfaces: Define which services the lower layer offers to the higher layer Protocols: Communication agreement between two parties of the same layer on different machines DSM02Introduction",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 18,
      "chunk_id": "p18c1",
      "title": "Layered Architectures Layer k1/k Interface Physical Medium Layer 1 Layer 1 Layer k Layer k Layer k+1",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "agreement between two parties of the same layer on different machines DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 18,
      "chunk_id": "p18c2",
      "title": "Layered Architectures Layer k1/k Interface Physical Medium Layer 1 Layer 1 Layer k Layer k Layer k+1",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Two Examples for Layered Architectures OSI Reference Model ▪ Based on a proposal developed by the International Standards Organization (ISO): Standardization of the protocols used in the layers. ▪ OSI = Open Systems Interconnections: connection of open systems ▪ Model with seven layers TCP/IP Reference Model ▪ Architecture of the ARPANET (today Internet)",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 19,
      "chunk_id": "p19c1",
      "title": "Two Examples for Layered Architectures OSI Reference Model ▪ Based on a proposal developed by the In",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪ Originally a model with four layers (actually only an implementation, the model came later...) DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 19,
      "chunk_id": "p19c2",
      "title": "Two Examples for Layered Architectures OSI Reference Model ▪ Based on a proposal developed by the In",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "DSM02Introduction II OSI Reference Model The outer columns represent the two end devices on which an application (e.g. Skype) communicates. The middle two columns represent the routers through which messages are routed on their way from one end device to the other.",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 20,
      "chunk_id": "p20c1",
      "title": "DSM02Introduction II OSI Reference Model The outer columns represent the two end devices on which an",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "DSM02Introduction II Layer Function 1. Physical • connection of two directly connected stations (pointtopoint) • transmission & exchange of physical signals 2. Data link • connection of two stations • exchange of frames between connected computers • allows addressing in local networks with the use of MAC addresses • error handling • flow control 3",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 21,
      "chunk_id": "p21c1",
      "title": "DSM02Introduction II Layer Function 1. Physical • connection of two directly connected stations (poi",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Network • communication between arbitrary stations • unique global addressing of stations • routing, exchange of packets • best effort service Layers in the OSI Model",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 21,
      "chunk_id": "p21c2",
      "title": "DSM02Introduction II Layer Function 1. Physical • connection of two directly connected stations (poi",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "DSM02Introduction II Layer Function 4. Transport • communication of processes (open + maintain connections) • binds applications to a port: addressing of processes (=applications) local to stations • provides reliability, which ensures that packets are received • different service types are available to programmers ‒ UDP: connection less, datagram ‒ TCP: connection oriented, reliable, stream 5",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 22,
      "chunk_id": "p22c1",
      "title": "DSM02Introduction II Layer Function 4. Transport • communication of processes (open + maintain conne",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Session • manages session state across individual connections, e.g., security associations 6. Presentation • transforms application data between different local representations (host, language) 7. Application • manifests the messages and data relevant for the application • provides protocols interacting with user applications Layers in the OSI Model",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 22,
      "chunk_id": "p22c2",
      "title": "DSM02Introduction II Layer Function 4. Transport • communication of processes (open + maintain conne",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "TCP/IP Reference Model DSM02Introduction II OSI TCP/IP Example Application Application SMTP, FTP, HTTP, DHCP Presentation Session Transport Transport TCP, UDP Network Internet IP Data Link HosttoNetwork Ethernet, 802.11 (Wifi) Physical",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 23,
      "chunk_id": "p23c1",
      "title": "TCP/IP Reference Model DSM02Introduction II OSI TCP/IP Example Application Application SMTP, FTP, HT",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "How to use Protocol Stacks? DSM02Introduction II TCP Nutzdaten/Payload Paket Payload Frame Payload TCP Header Paket Header Frame Header",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 24,
      "chunk_id": "p24c1",
      "title": "How to use Protocol Stacks? DSM02Introduction II TCP Nutzdaten/Payload Paket Payload Frame Payload T",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "How to use Protocol Stacks? DSM02Introduction II 00 17 95 9A 55 67 00 60 97 D8 EE 48 08 00 45 00 00 30 3A B2 40 00 80 06 4D E7 86 5D XX XX 86 5D XX XX 04 16 00 16 37 8E 51 7B 00 00 00 00 70 02 40 00 43 BB 00 00 02 04 05 B4 01 01 04 02 0A 00 1B 56 95 AA FF 12 ...",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 25,
      "chunk_id": "p25c1",
      "title": "How to use Protocol Stacks? DSM02Introduction II 00 17 95 9A 55 67 00 60 97 D8 EE 48 08 00 45 00 00 ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "How to use Protocol Stacks? DSM02Introduction II Ethernet Header (Layer 2) IP Header (Layer 3) Payload TCP Header (Layer 4) 00 17 95 9A 55 67 00 60 97 D8 EE 48 08 00 45 00 00 30 3A B2 40 00 80 06 4D E7 86 5D XX XX 86 5D XX XX 04 16 00 16 37 8E 51 7B 00 00 00 00 70 02 40 00 43 BB 00 00 02 04 05 B4 01 01 04 02 0A 00 1B 56 95 AA FF 12 ...",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 26,
      "chunk_id": "p26c1",
      "title": "How to use Protocol Stacks? DSM02Introduction II Ethernet Header (Layer 2) IP Header (Layer 3) Paylo",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Internet Protocol Stack (TCP/IP) DSM02Introduction II Netzzugang Internet Protocol User Datagram Protocol DNS, … Transport Control Protocol HTTP, FTP, … Application Layer HosttoNetwork Layer Transport Layer Network Layer Unreliable Connectionless Reliable Connectionoriented",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 27,
      "chunk_id": "p27c1",
      "title": "Internet Protocol Stack (TCP/IP) DSM02Introduction II Netzzugang Internet Protocol User Datagram Pro",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Internet Protocol Stack (TCP/IP) DSM02Introduction II Netzzugang Internet Protocol User Datagram Protocol DNS, … Transport Control Protocol HTTP, FTP, … Own Protocol Own Protocol Application Layer HosttoNetwork Layer Transport Layer Network Layer Unreliable Connectionless Reliable Connectionoriented",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 28,
      "chunk_id": "p28c1",
      "title": "Internet Protocol Stack (TCP/IP) DSM02Introduction II Netzzugang Internet Protocol User Datagram Pro",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "PeertoPeer Systems peer Etymology: Middle English, from Middle French per, from per, adjective, equal, from Latin par 1 : one that is of equal standing with another : EQUAL; especially : one belonging to the same societal group especially based on age, grade, or status DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 29,
      "chunk_id": "p29c1",
      "title": "PeertoPeer Systems peer Etymology: Middle English, from Middle French per, from per, adjective, equa",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Definitions Various definitions, for example: PeertoPeer is a class of applications that takes advantage of resources [...] available at the edges of the Internet. ... peertopeer nodes must operate outside the DNS and have [...] autonomy from central servers. Clay Shirky DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 30,
      "chunk_id": "p30c1",
      "title": "Definitions Various definitions, for example: PeertoPeer is a class of applications that takes advan",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Definitions Another one: Peertopeer systems are distributed systems consisting of interconnected nodes able to selforganize into network topologies with the purpose of sharing resources […], capable of adapting to failures and accommodating transient populations of nodes while maintaining acceptable connectivity and performance, without requiring the intermediation or support of a global",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 31,
      "chunk_id": "p31c1",
      "title": "Definitions Another one: Peertopeer systems are distributed systems consisting of interconnected nod",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "connectivity and performance, without requiring the intermediation or support of a global centralized server or authority",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 31,
      "chunk_id": "p31c2",
      "title": "Definitions Another one: Peertopeer systems are distributed systems consisting of interconnected nod",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". AndroutsellisTheotokis and Spinellis DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 31,
      "chunk_id": "p31c3",
      "title": "Definitions Another one: Peertopeer systems are distributed systems consisting of interconnected nod",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts • Periodically using socalled newsfeeds • News server are organized in an overlay network • Forwarding of messages to all interested neighbours • Prevention of forwarding loops: messages contain a history of visited news servers • The Usenet is an early (and current) example of a P2P system",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 32,
      "chunk_id": "p32c1",
      "title": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "a history of visited news servers • The Usenet is an early (and current) example of a P2P system DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 32,
      "chunk_id": "p32c2",
      "title": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts • Periodically using socalled newsfeeds • News server are organized in an overlay network • Forwarding of messages to all interested neighbours • Prevention of forwarding loops: messages contain a history of visited news servers • The Usenet is an early (and current) example of a P2P system",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 33,
      "chunk_id": "p33c1",
      "title": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "a history of visited news servers • The Usenet is an early (and current) example of a P2P system DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 33,
      "chunk_id": "p33c2",
      "title": "An Ancient Example: The Usenet • Exchange of messages in newsgroups • Synchronization between hosts ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Application Classes using P2P • Communication and collaboration between users • Goal: Applications that enable direct communication between peers • For example, chat systems based on Jabber, VoIP systems like Skype • Distributed Computing • Goal: Sharing of processing power between peers • Example: Seti@home, genome@home • Internet Service Support • Goal: Support of Internet services based on P2P",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 34,
      "chunk_id": "p34c1",
      "title": "Application Classes using P2P • Communication and collaboration between users • Goal: Applications t",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Seti@home, genome@home • Internet Service Support • Goal: Support of Internet services based on P2P • Example: P2P multicast systems DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 34,
      "chunk_id": "p34c2",
      "title": "Application Classes using P2P • Communication and collaboration between users • Goal: Applications t",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Application Classes using P2P • Database systems • Goal: couple multiple independent databases • Examples: database replication, distributed query processing, e.g., Bayou • Content Distribution • Goal: make content available to users • Examples: file sharing (Gnutella, Kazaa, etc.), distributed content storage and lookup (Chord, CAN, etc.) • Main focus of this chapter DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 35,
      "chunk_id": "p35c1",
      "title": "Application Classes using P2P • Database systems • Goal: couple multiple independent databases • Exa",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Discussion • Why not use servers? • Communication: SMTP, Videoconference Systems • Computation: Elastic Cloud Computing • Databases: pick one out of thousand • Content distribution: iTunes/AppStore sells everything... • Is there a benefit in using P2P technology? DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 36,
      "chunk_id": "p36c1",
      "title": "Discussion • Why not use servers? • Communication: SMTP, Videoconference Systems • Computation: Elas",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Organizing Servers on the Internet • The Internet assume(s|d) computers to • Be 24/7 online • Have a fixed IP address • Thus, they can be managed in registers, such as DNS • However, this is no longer true • Mobility: computers roam through different networks • IPAddress shortage: multiplex IP Adresses (NAT) • Security: block distinct services DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 37,
      "chunk_id": "p37c1",
      "title": "Organizing Servers on the Internet • The Internet assume(s|d) computers to • Be 24/7 online • Have a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Main objective of P2P Systems • Provide an overlay network on top of the Internet • Overlay: nodes are processes that are connected to each other using the underlying network • Overlay addresses and management services are provided • Aim at integration of nodes that join sporadically DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 38,
      "chunk_id": "p38c1",
      "title": "Main objective of P2P Systems • Provide an overlay network on top of the Internet • Overlay: nodes a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Overlay Networks DSM02Introduction II Overlay Underlay",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 39,
      "chunk_id": "p39c1",
      "title": "Overlay Networks DSM02Introduction II Overlay Underlay",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Overlay Networks DSM02Introduction II Overlay Underlay",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 40,
      "chunk_id": "p40c1",
      "title": "Overlay Networks DSM02Introduction II Overlay Underlay",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Overlay Networks DSM02Introduction II Overlay Underlay",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 41,
      "chunk_id": "p41c1",
      "title": "Overlay Networks DSM02Introduction II Overlay Underlay",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Functionality of P2P System • Join the network • Connecting nodes need to know at least one other node of the network • Exchange neighbor information • Often contains an Overlay address and an Underlay address • Route messages to a target / neighbor • Repair for disconnecting nodes • Disconnect gracefully from network DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 42,
      "chunk_id": "p42c1",
      "title": "Functionality of P2P System • Join the network • Connecting nodes need to know at least one other no",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Functionality of P2P Content Distribution Systems DSM02Introduction II Minimal functionality required • Insert new content • Locate (search for) content • Retrieve content Optional functionality (often harder to achieve) • Deletion: remove an object (and its copies!) • Update: apply changes to an existing object • Expiration: remove objects after a specified time • Versioning: • each object is",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 43,
      "chunk_id": "p43c1",
      "title": "Functionality of P2P Content Distribution Systems DSM02Introduction II Minimal functionality require",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "existing object • Expiration: remove objects after a specified time • Versioning: • each object is readonly (new versions) • Replace all existing copies",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 43,
      "chunk_id": "p43c2",
      "title": "Functionality of P2P Content Distribution Systems DSM02Introduction II Minimal functionality require",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Architectural properties: Degree of Centralization • Centralization in this context: →Are there any centralized components necessary to run a given system? • Various degrees of centralization can be found in systems • Purely decentralized architectures • Partially centralized architectures • Hybrid decentralized architectures DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 44,
      "chunk_id": "p44c1",
      "title": "Architectural properties: Degree of Centralization • Centralization in this context: →Are there any ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Purely Decentralized Architectures • All nodes perform the same task • May hinder scalability • All nodes are in the role of SERVer and cliENT (SERVENT) • Example: Gnutella 0.4, Chord DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 45,
      "chunk_id": "p45c1",
      "title": "Purely Decentralized Architectures • All nodes perform the same task • May hinder scalability • All ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Partially Centralized Architectures • Similar to purely decentralized • However, some nodes are more important • Notion of socalled supernodes (or superpeers) • Supernodes: • Often act as local index • Provide information about the content stored at local peers • Are dynamically elected • Do not constitute a single point of failure DSM02Introduction II „normal“ peers supernodes",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 46,
      "chunk_id": "p46c1",
      "title": "Partially Centralized Architectures • Similar to purely decentralized • However, some nodes are more",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Hybrid Decentralized Architectures • Centralized servers exist for some tasks, e.g. • Maintain user data (access control) • Maintain directories of metadata about available files • Exchange of data directly between peers • Sometimes called „peerthroughpeer“ or „broker mediated“ systems • Central components constitute single points of failure! DSM02Introduction II Download of content Server lookup",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 47,
      "chunk_id": "p47c1",
      "title": "Hybrid Decentralized Architectures • Centralized servers exist for some tasks, e.g. • Maintain user ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Network Structure • Overlay network: • network which is built “on top” of another network • Overlay networks may be created and maintained as: • Unstructured overlay networks • Structured overlay networks DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 48,
      "chunk_id": "p48c1",
      "title": "Network Structure • Overlay network: • network which is built “on top” of another network • Overlay ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Unstructured Overlays • Creation of overlay: nondeterministic as nodes and content are added/removed • Search methods (examples): • Brute force: query flooding (breadth/depthfirst) →High message overhead • Random walk →May not find all items that match • Usually cope very well with transient node populations • Insertion and removal of peers is easy • Examples: Gnutella, Kazaa, FreeHaven",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 49,
      "chunk_id": "p49c1",
      "title": "Unstructured Overlays • Creation of overlay: nondeterministic as nodes and content are added/removed",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "node populations • Insertion and removal of peers is easy • Examples: Gnutella, Kazaa, FreeHaven DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 49,
      "chunk_id": "p49c2",
      "title": "Unstructured Overlays • Creation of overlay: nondeterministic as nodes and content are added/removed",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Structured Overlays • Content placed at precisely specified locations • Insertion and removal of peers is more complex • Structure is tightly controlled →must be maintained • Files may have to be migrated on insertion/removal of peers • Search methods depend on used structure (examples): • Binary search along a ring, e.g., Chord • Alphanumeric search over multiple rings, e.g., SkipNet, SkABNet •",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 50,
      "chunk_id": "p50c1",
      "title": "Structured Overlays • Content placed at precisely specified locations • Insertion and removal of pee",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "along a ring, e.g., Chord • Alphanumeric search over multiple rings, e.g., SkipNet, SkABNet • Routing between regions in a Cartesian space, e.g., CAN (Content addressable network) DSM02Introduction II",
    "metadata": {
      "source": "Lecture_02.pdf",
      "page": 50,
      "chunk_id": "p50c2",
      "title": "Structured Overlays • Content placed at precisely specified locations • Insertion and removal of pee",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 08 – Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 1,
      "chunk_id": "p1c1",
      "title": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 08 – Middleware",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Middleware Technologies ▪RPC ▪CORBA ▪Java RMI ▪SOAP ▪REST ▪gRPC ▪Our reasearch in Middleware: Tasklets DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 2,
      "chunk_id": "p2c1",
      "title": "Agenda ▪Middleware Technologies ▪RPC ▪CORBA ▪Java RMI ▪SOAP ▪REST ▪gRPC ▪Our reasearch in Middleware",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Middleware Middleware facilitates and manages the interaction between applications across heterogeneous computing platforms. It is the architectural solution to the problem of integrating a collection of servers and applications under a common service interface",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 3,
      "chunk_id": "p3c1",
      "title": "Middleware Middleware facilitates and manages the interaction between applications across heterogene",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Abstraction is a key concept in making software development easier for software developers Programming abstractions can ▪hide hardware/platform details ▪provide powerful building blocks ▪reduce programming errors ▪offload difficult tasks to other services ▪reduce development and maintenance costs DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 3,
      "chunk_id": "p3c2",
      "title": "Middleware Middleware facilitates and manages the interaction between applications across heterogene",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Middleware “Middleware is a layer of software above the operating system which provides higherlevel building blocks for programmers. In doing so, it helps make them more productive and helps to mask the complexities and heterogenous nature that is inherent in distributed systems.” David E",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 4,
      "chunk_id": "p4c1",
      "title": "Middleware “Middleware is a layer of software above the operating system which provides higherlevel ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Bakken Middleware can be seen as a set of programming abstractions that make it easier to develop complex distributed systems. DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 4,
      "chunk_id": "p4c2",
      "title": "Middleware “Middleware is a layer of software above the operating system which provides higherlevel ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "MessageOriented Middleware (MOM) ▪Provide interoperability via messages: a structured data set typically characterized by a type and a set of attributevalue pairs ▪Components in a MOM will then publish certain messages while subscribing to other messages; components will often be both clients AND servers depending on the messages they understand Aim at highlevel persistent asynchronous",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 5,
      "chunk_id": "p5c1",
      "title": "MessageOriented Middleware (MOM) ▪Provide interoperability via messages: a structured data set typic",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "AND servers depending on the messages they understand Aim at highlevel persistent asynchronous communication: ▪Processes send each other messages, which are queued ▪Sender need not wait for immediate reply, but can do other things ▪Middleware often ensures fault tolerance DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 5,
      "chunk_id": "p5c2",
      "title": "MessageOriented Middleware (MOM) ▪Provide interoperability via messages: a structured data set typic",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "History of Middleware/Inter Process Communication DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 6,
      "chunk_id": "p6c1",
      "title": "History of Middleware/Inter Process Communication DSM08Middleware",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Classification of Inter Process Communication Technologies DSM08Middleware Hamed Dinari (2020). InterProcess Communication (IPC) in Distributed Environments: An Investigation and Performance Analysis of Some Middleware Technologies. International Journal of Modern Education & Computer Science",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 7,
      "chunk_id": "p7c1",
      "title": "Classification of Inter Process Communication Technologies DSM08Middleware Hamed Dinari (2020). Inte",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Remote Procedure Calls ▪Definition: A protocol that allows a program to cause a procedure (subroutine) to execute in another address space (commonly on another machine). ▪Facilitates communication between distributed systems",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 8,
      "chunk_id": "p8c1",
      "title": "Remote Procedure Calls ▪Definition: A protocol that allows a program to cause a procedure (subroutin",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Facilitates communication between distributed systems. ▪Application developers are familiar with simple procedure model ▪Wellengineered procedures operate in isolation (black box) ▪There is no fundamental reason not to execute procedures on separate machine ▪Communication between caller & callee can be hidden by using procedurecall mechanism. DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 8,
      "chunk_id": "p8c2",
      "title": "Remote Procedure Calls ▪Definition: A protocol that allows a program to cause a procedure (subroutin",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Remote Procedure Calls DSM08Middleware ACM Transactions on Computer Systems (TOCS), 1984",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 9,
      "chunk_id": "p9c1",
      "title": "Remote Procedure Calls DSM08Middleware ACM Transactions on Computer Systems (TOCS), 1984",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Remote Procedure Calls DSM08Middleware ACM Transactions on Computer Systems (TOCS), 1984",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 10,
      "chunk_id": "p10c1",
      "title": "Remote Procedure Calls DSM08Middleware ACM Transactions on Computer Systems (TOCS), 1984",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Remote Procedure Calls DSM08Middleware M. van Steen and A.S. Tanenbaum, Distributed Systems, 4th ed., distributedsystems.net, 2023. 1. Client procedure calls client stub. 2. Stub builds message; calls local OS. 3. OS sends message to remote OS. 4. Remote OS gives message to stub. 5. Stub unpacks parameters; calls server. 6. Server does local call; returns result to stub. 7",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 11,
      "chunk_id": "p11c1",
      "title": "Remote Procedure Calls DSM08Middleware M. van Steen and A.S. Tanenbaum, Distributed Systems, 4th ed.",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". 5. Stub unpacks parameters; calls server. 6. Server does local call; returns result to stub. 7. Stub builds message; calls OS. 8. OS sends message to client’s OS. 9. Client’s OS gives message to stub. 10. Client stub unpacks result; returns to client.",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 11,
      "chunk_id": "p11c2",
      "title": "Remote Procedure Calls DSM08Middleware M. van Steen and A.S. Tanenbaum, Distributed Systems, 4th ed.",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Stubs and Skeletons DSM08Middleware A stub for a remote object is the clientside proxy for the remote object. Such a stub implements all the interfaces that are supported by the remote object implementation. A clientside stub is responsible for: ▪ Initiating a call to the remote object ▪ Marshaling arguments to a stream ▪ Informing the remote reference layer that the call should be invoked",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 12,
      "chunk_id": "p12c1",
      "title": "Stubs and Skeletons DSM08Middleware A stub for a remote object is the clientside proxy for the remot",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪ Unmarshaling the return value or exception from a stream. ▪ Informing the remote reference layer that the call is complete. Application Stub RPC Library Transport Application Skeleton RPC Library Transport RPC TCP /IP Client Server",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 12,
      "chunk_id": "p12c2",
      "title": "Stubs and Skeletons DSM08Middleware A stub for a remote object is the clientside proxy for the remot",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Stubs and Skeletons DSM08Middleware A skeleton for a remote object is a serverside entity that contains a method which dispatches calls to the actual remote object implementation. The skeleton is responsible for: ▪ Unmarshaling arguments from the stream. ▪ Making the upcall to the actual remote object implementation",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 13,
      "chunk_id": "p13c1",
      "title": "Stubs and Skeletons DSM08Middleware A skeleton for a remote object is a serverside entity that conta",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪ Making the upcall to the actual remote object implementation. ▪ Marshaling the return value of the call or an exception (if one occurred) onto the stream. Application Stub RPC Library Transport Application Skeleton RPC Library Transport RPC TCP /IP Client Server",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 13,
      "chunk_id": "p13c2",
      "title": "Stubs and Skeletons DSM08Middleware A skeleton for a remote object is a serverside entity that conta",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "IDL – Interface Definition Language DSM08Middleware IDL is a languageagnostic abstraction used to define interfaces between software components. It allows developers to describe the methods and data structures without being tied to a specific programming language.",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 14,
      "chunk_id": "p14c1",
      "title": "IDL – Interface Definition Language DSM08Middleware IDL is a languageagnostic abstraction used to de",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "RPC: Parameter passing ▪There’s more than just wrapping parameters into a message ▪Client and server machines may have different data representations (think of byte ordering) ▪Wrapping a parameter means transforming a value into a sequence of bytes ▪Client and server have to agree on the same encoding: ▪How are basic data values represented (integers, floats, characters) ▪How are complex data",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 15,
      "chunk_id": "p15c1",
      "title": "RPC: Parameter passing ▪There’s more than just wrapping parameters into a message ▪Client and server",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "▪How are basic data values represented (integers, floats, characters) ▪How are complex data values represented (arrays, unions) ▪Conclusion: Client and server need to properly interpret messages, transforming them into machinedependent representations",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 15,
      "chunk_id": "p15c2",
      "title": "RPC: Parameter passing ▪There’s more than just wrapping parameters into a message ▪Client and server",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 15,
      "chunk_id": "p15c3",
      "title": "RPC: Parameter passing ▪There’s more than just wrapping parameters into a message ▪Client and server",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "RPC: Parameter passing ▪Copy in/copy out semantics: while procedure is executed, nothing can be assumed about parameter values. ▪All data that is to be operated on is passed by parameters. Excludes passing references to (global) data. ▪Conclusion: Full access transparency cannot be realized",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 16,
      "chunk_id": "p16c1",
      "title": "RPC: Parameter passing ▪Copy in/copy out semantics: while procedure is executed, nothing can be assu",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Conclusion: Full access transparency cannot be realized. A remote reference mechanism enhances access transparency ▪Remote reference offers unified access to remote data ▪Remote references can be passed as parameter in RPCs DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 16,
      "chunk_id": "p16c2",
      "title": "RPC: Parameter passing ▪Copy in/copy out semantics: while procedure is executed, nothing can be assu",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "CORBA DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 17,
      "chunk_id": "p17c1",
      "title": "CORBA DSM08Middleware",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "OMGObject Management Group ▪Established 1989 (11 members) ▪Specification of middleware (initially) ▪Today ▪Over 800 members ▪Specifications of middleware, modeling languages (UML), Business Process Management Plus (BPM+) and much more ▪Hosts four technical meetings per year for its members and interested nonmembers ▪Technology adoption only after reference implementation ▪But: OMG publishes only",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 18,
      "chunk_id": "p18c1",
      "title": "OMGObject Management Group ▪Established 1989 (11 members) ▪Specification of middleware (initially) ▪",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "nonmembers ▪Technology adoption only after reference implementation ▪But: OMG publishes only specifications, no reference implementation DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 18,
      "chunk_id": "p18c2",
      "title": "OMGObject Management Group ▪Established 1989 (11 members) ▪Specification of middleware (initially) ▪",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "CORBACommon Object Request Broker Architecture ▪Middleware Standard: Enabling communication and collaboration between objects in a distributed computing environment. ▪Language Independence: Allows objects written in different programming languages to seamlessly interact, promoting interoperability and flexibility",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 19,
      "chunk_id": "p19c1",
      "title": "CORBACommon Object Request Broker Architecture ▪Middleware Standard: Enabling communication and coll",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Object Request Broker (ORB): functions as an intermediary, managing communication between distributed objects by handling method invocations and providing a seamless abstraction. DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 19,
      "chunk_id": "p19c2",
      "title": "CORBACommon Object Request Broker Architecture ▪Middleware Standard: Enabling communication and coll",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "CORBA – Object Request Broker (ORB) ▪Facilitates communication between distributed objects. ▪Creates and manages remote object references for clients. ▪Dispatches remote method invocations (RMIs) to the appropriate object implementation. ▪Supports naming services for object lookup. ▪Handles marshalling and unmarshalling of data for network transmission. ▪Implements distributed garbage collection",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 20,
      "chunk_id": "p20c1",
      "title": "CORBA – Object Request Broker (ORB) ▪Facilitates communication between distributed objects. ▪Creates",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Implements distributed garbage collection. ▪Ensures interoperability between objects developed in different programming languages. ▪Manages communication protocols for effective network communication. DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 20,
      "chunk_id": "p20c2",
      "title": "CORBA – Object Request Broker (ORB) ▪Facilitates communication between distributed objects. ▪Creates",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "CORBAObject Adapters ▪Object adapters bridge CORBA objects and servant classes. ▪Tasks include creating remote object references and dispatching RMIs. ▪Manage servant activation and deactivation. ▪Assign unique object names to CORBA objects. ▪Maintain a remote object table mapping object names to servants. ▪Have their own names integrated into remote object references for managed objects",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 21,
      "chunk_id": "p21c1",
      "title": "CORBAObject Adapters ▪Object adapters bridge CORBA objects and servant classes. ▪Tasks include creat",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Have their own names integrated into remote object references for managed objects. DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 21,
      "chunk_id": "p21c2",
      "title": "CORBAObject Adapters ▪Object adapters bridge CORBA objects and servant classes. ▪Tasks include creat",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "IDLCompiler ▪IDLCompiler translates interface description into ▪General templates ▪Clientspecific templates ▪Servicespecific templates ▪Client Implementor ▪Implements functionality under use of the service via stubs ▪Service Implementor ▪Completes the template (skeleton) of the service DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 22,
      "chunk_id": "p22c1",
      "title": "IDLCompiler ▪IDLCompiler translates interface description into ▪General templates ▪Clientspecific te",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "IDL in CORBA module HelloApp { interface Hello { string sayHello(); oneway void shutdown(); }; }; DSM08Middleware IDL compiler",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 23,
      "chunk_id": "p23c1",
      "title": "IDL in CORBA module HelloApp { interface Hello { string sayHello(); oneway void shutdown(); }; }; DS",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Java RMI DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 24,
      "chunk_id": "p24c1",
      "title": "Java RMI DSM08Middleware",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Java RMI ▪Remote Method Invocation (RMI) is Java’s implementation of objecttoobject communication among Java objects to realize a distributed computing model. ▪RMI allows us to distribute our objects on various machines, and invoke methods on the objects located on remote sites. ▪Once the object (or service) is registered, a client can look up that service",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 25,
      "chunk_id": "p25c1",
      "title": "Java RMI ▪Remote Method Invocation (RMI) is Java’s implementation of objecttoobject communication am",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Once the object (or service) is registered, a client can look up that service. ▪A client (application) receives a reference that allows the client to use the service (call the method). ▪Syntax of calling is identical to a call to a method of another object in the same program. DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 25,
      "chunk_id": "p25c2",
      "title": "Java RMI ▪Remote Method Invocation (RMI) is Java’s implementation of objecttoobject communication am",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Java RMI – Specification Goals ▪Support seamless remote invocations on objects in different JVMs. ▪Support callbacks from servers to clients. ▪Integrate the distributed object model into the Java programming language in a natural way while retaining most of the language's object semantics. ▪Make writing distributed applications as simple as possible (certainly simpler than with sockets)",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 26,
      "chunk_id": "p26c1",
      "title": "Java RMI – Specification Goals ▪Support seamless remote invocations on objects in different JVMs. ▪S",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Make writing distributed applications as simple as possible (certainly simpler than with sockets). ▪Preserve the safety provided by the Java runtime environment. ▪Flexibility and extensibility are provided by: ▪Distributed garbage collection ▪Capability to support multiple transports ▪Varying remote invocation mechanisms, such as unicast and multicast DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 26,
      "chunk_id": "p26c2",
      "title": "Java RMI – Specification Goals ▪Support seamless remote invocations on objects in different JVMs. ▪S",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Java RMI – Tasks ▪Locate Remote Objects: Application can obtain references to remote objects when ▪a) objects are registered with the RMI naming facility, the rmiregistry, ▪b) application can pass and return remote object references as part of its normal operation ▪Communicate with remote objects: handled by RMI; looks like standard Java method invocation to the programmer ▪Load class bytecodes",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 27,
      "chunk_id": "p27c1",
      "title": "Java RMI – Tasks ▪Locate Remote Objects: Application can obtain references to remote objects when ▪a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "handled by RMI; looks like standard Java method invocation to the programmer ▪Load class bytecodes for objects that are passed as parameters or return values: Because RMI allows a caller to pass pure Java objects to remote object, RMI provides the necessary mechanisms for loading an object's code as well as transmitting its data DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 27,
      "chunk_id": "p27c2",
      "title": "Java RMI – Tasks ▪Locate Remote Objects: Application can obtain references to remote objects when ▪a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Java RMI – Architecture DSM08Middleware Server Skeleton Client Stub Remote Reference Layer Transport Layer Application Presentation Session Transport OSI Model The layers are independent. Each layer is defined by specific protocol and built using specific interface. Any layer can be replaced by an alternate implementation without affecting the others, e.g",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 28,
      "chunk_id": "p28c1",
      "title": "Java RMI – Architecture DSM08Middleware Server Skeleton Client Stub Remote Reference Layer Transport",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Any layer can be replaced by an alternate implementation without affecting the others, e.g. the standard transport layer in RMI is TCP based, but can be substituted by a UDP based transport layer",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 28,
      "chunk_id": "p28c2",
      "title": "Java RMI – Architecture DSM08Middleware Server Skeleton Client Stub Remote Reference Layer Transport",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Java RMI – Serialization ▪When a client code invokes a remote method on a remote object, it actually calls an ordinary/local Java method encapsulated in the stub. ▪The stub encodes the parameters used in the remote method with a deviceindependent encoding and transforms them in a format suitable for transport",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 29,
      "chunk_id": "p29c1",
      "title": "Java RMI – Serialization ▪When a client code invokes a remote method on a remote object, it actually",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". The process of encoding, writing to a stream and sending an object is referred as parameter marshalling. ▪Thus the stub method on the client side builds an information block that consists of: ▪Identifier of remote object to be used; ▪Name of the method to be called ▪Marshalled parameters. ▪The reverse process of receiving, reading and decoding is called parameter unmarshalling. DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 29,
      "chunk_id": "p29c2",
      "title": "Java RMI – Serialization ▪When a client code invokes a remote method on a remote object, it actually",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Java RMI – Minimal Example DSM08Middleware import java.rmi.Remote; import java.rmi.RemoteException; public interface Hello extends Remote { String sayHello() throws RemoteException; } Hello.java",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 30,
      "chunk_id": "p30c1",
      "title": "Java RMI – Minimal Example DSM08Middleware import java.rmi.Remote; import java.rmi.RemoteException; ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Java RMI – Minimal Example DSM08Middleware public class Client { private Client() {} public static void main(String[] args) { String host = (args.length < 1) ? null : args[0]; try { Registry registry = LocateRegistry.getRegistry(host); Hello stub = (Hello) registry.lookup(\"Hello\"); String response = stub.sayHello(); System.out.println(\"response: \" + response); } catch (Exception e) {",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 31,
      "chunk_id": "p31c1",
      "title": "Java RMI – Minimal Example DSM08Middleware public class Client { private Client() {} public static v",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "response = stub.sayHello(); System.out.println(\"response: \" + response); } catch (Exception e) { System.err.println(\"Client exception: \" + e.toString()); e.printStackTrace(); } } } Client.java",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 31,
      "chunk_id": "p31c2",
      "title": "Java RMI – Minimal Example DSM08Middleware public class Client { private Client() {} public static v",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Java RMI – Minimal Example DSM08Middleware public class Server implements Hello { public Server() {} public String sayHello() { return \"Hello, world!\"; } public static void main(String args[]) { try { Server obj = new Server(); Hello stub = (Hello) UnicastRemoteObject.exportObject(obj, 0); Registry registry = LocateRegistry.createRegistry(1099); registry.bind(\"Hello\", stub);",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 32,
      "chunk_id": "p32c1",
      "title": "Java RMI – Minimal Example DSM08Middleware public class Server implements Hello { public Server() {}",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "0); Registry registry = LocateRegistry.createRegistry(1099); registry.bind(\"Hello\", stub); System.err.println(\"Server ready\"); } catch (Exception e) { ..",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 32,
      "chunk_id": "p32c2",
      "title": "Java RMI – Minimal Example DSM08Middleware public class Server implements Hello { public Server() {}",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". } } } Server.java",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 32,
      "chunk_id": "p32c3",
      "title": "Java RMI – Minimal Example DSM08Middleware public class Server implements Hello { public Server() {}",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "SOAP DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 33,
      "chunk_id": "p33c1",
      "title": "SOAP DSM08Middleware",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "SOAP – Simple Object Access Protocol ▪SOAP is the standard messaging protocol used by Web services. SOAP’s primary application is interapplication communication. SOAP codifies the use of XML as an encoding scheme for request and response parameters using HTTP as a means for transport",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 34,
      "chunk_id": "p34c1",
      "title": "SOAP – Simple Object Access Protocol ▪SOAP is the standard messaging protocol used by Web services. ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". or ▪SOAP is a way for a program running in one operating system to communicate with a program running in either the same or a different operating system, using HTTP (or any other transport protocol) and XML. DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 34,
      "chunk_id": "p34c2",
      "title": "SOAP – Simple Object Access Protocol ▪SOAP is the standard messaging protocol used by Web services. ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "SOAP ▪Protocol Neutrality: Can be used with various transport protocols (e.g., HTTP, SMTP). ▪Platform Independence: Allows communication between different platforms and programming languages",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 35,
      "chunk_id": "p35c1",
      "title": "SOAP ▪Protocol Neutrality: Can be used with various transport protocols (e.g., HTTP, SMTP). ▪Platfor",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Platform Independence: Allows communication between different platforms and programming languages. ▪SOAP ▪can be used over any transport protocol such as TCP, HTTP, SMTP ▪allows for any programming model and is not tied to RPC ▪defines a model for processing individual, oneway messages ▪also allows for any number of message exchange patterns (MEPs) DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 35,
      "chunk_id": "p35c2",
      "title": "SOAP ▪Protocol Neutrality: Can be used with various transport protocols (e.g., HTTP, SMTP). ▪Platfor",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "SOAPMessages ▪SOAP message consists of three parts: ▪SOAP Envelope ▪top element of the XML document representing the message. ▪always the root element of a SOAP message. ▪SOAP Header (optional) ▪SOAP Body DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 36,
      "chunk_id": "p36c1",
      "title": "SOAPMessages ▪SOAP message consists of three parts: ▪SOAP Envelope ▪top element of the XML document ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "SOAP – Example Request POST /StockQuote HTTP/1.1 Host: www.stockquoteserver.com ContentType: text/xml; charset=\"utf8\" ContentLength: nnnn SOAPAction: \"SomeURI\" <SOAPENV:Envelope xmlns:SOAPENV=\"http://schemas.xmlsoap.org/soap/envelope/\" SOAPENV:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"> <SOAPENV:Body> <m:GetLastTradePrice xmlns:m=\"SomeURI\"> <symbol>DIS</symbol>",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 37,
      "chunk_id": "p37c1",
      "title": "SOAP – Example Request POST /StockQuote HTTP/1.1 Host: www.stockquoteserver.com ContentType: text/xm",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "<SOAPENV:Body> <m:GetLastTradePrice xmlns:m=\"SomeURI\"> <symbol>DIS</symbol> </m:GetLastTradePrice> </SOAPENV:Body> </SOAPENV:Envelope> DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 37,
      "chunk_id": "p37c2",
      "title": "SOAP – Example Request POST /StockQuote HTTP/1.1 Host: www.stockquoteserver.com ContentType: text/xm",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "SOAP – Example Response HTTP/1.1 200 OK ContentType: text/xml; charset=\"utf8\" ContentLength: nnnn <SOAPENV:Envelope xmlns:SOAPENV=\"http://schemas.xmlsoap.org/soap/envelope/\" SOAPENV:encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\"/> <SOAPENV:Body> <m:GetLastTradePriceResponse xmlns:m=\"SomeURI\"> <Price>34.5</Price> </m:GetLastTradePriceResponse> </SOAPENV:Body> </SOAPENV:Envelope>",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 38,
      "chunk_id": "p38c1",
      "title": "SOAP – Example Response HTTP/1.1 200 OK ContentType: text/xml; charset=\"utf8\" ContentLength: nnnn <S",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "<Price>34.5</Price> </m:GetLastTradePriceResponse> </SOAPENV:Body> </SOAPENV:Envelope> DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 38,
      "chunk_id": "p38c2",
      "title": "SOAP – Example Response HTTP/1.1 200 OK ContentType: text/xml; charset=\"utf8\" ContentLength: nnnn <S",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "WSDLWeb Services Description Language ▪XMLbased language for describing web service functionalities. ▪serves as a contract defining operations, messages, and communication details. ▪Key elements include types, message, port type, binding, and service. ▪WSDL enables interoperability by standardizing communication details. ▪Supports automated code generation for streamlined development",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 39,
      "chunk_id": "p39c1",
      "title": "WSDLWeb Services Description Language ▪XMLbased language for describing web service functionalities.",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Supports automated code generation for streamlined development. DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 39,
      "chunk_id": "p39c2",
      "title": "WSDLWeb Services Description Language ▪XMLbased language for describing web service functionalities.",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "WSDLWeb Services Description Language <definitions name = \"HelloService\" targetNamespace = \"http://www.examples.com/wsdl/HelloService.wsdl\" xmlns = \"http://schemas.xmlsoap.org/wsdl/\" xmlns:soap = \"http://schemas.xmlsoap.org/wsdl/soap/\" xmlns:tns = \"http://www.examples.com/wsdl/HelloService.wsdl\" xmlns:xsd = \"http://www.w3.org/2001/XMLSchema\"> <message name = \"SayHelloRequest\"> <part name =",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 40,
      "chunk_id": "p40c1",
      "title": "WSDLWeb Services Description Language <definitions name = \"HelloService\" targetNamespace = \"http://w",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "xmlns:xsd = \"http://www.w3.org/2001/XMLSchema\"> <message name = \"SayHelloRequest\"> <part name = \"firstName\" type = \"xsd:string\"/> </message> <message name = \"SayHelloResponse\"> <part name = \"greeting\" type = \"xsd:string\"/> </message> <portType name = \"Hello_PortType\"> <operation name = \"sayHello\"> <input message = \"tns:SayHelloRequest\"/> <output message = \"tns:SayHelloResponse\"/> </operation>",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 40,
      "chunk_id": "p40c2",
      "title": "WSDLWeb Services Description Language <definitions name = \"HelloService\" targetNamespace = \"http://w",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "<input message = \"tns:SayHelloRequest\"/> <output message = \"tns:SayHelloResponse\"/> </operation> </portType> DSM08Middleware <binding name = \"Hello_Binding\" type = \"tns:Hello_PortType\"> <soap:binding style = \"rpc\" transport = \"http://schemas.xmlsoap.org/soap/http\"/> <operation name = \"sayHello\"> <soap:operation soapAction = \"sayHello\"/> <input> <soap:body encodingStyle =",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 40,
      "chunk_id": "p40c3",
      "title": "WSDLWeb Services Description Language <definitions name = \"HelloService\" targetNamespace = \"http://w",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "name = \"sayHello\"> <soap:operation soapAction = \"sayHello\"/> <input> <soap:body encodingStyle = \"http://schemas.xmlsoap.org/soap/encoding/\" namespace = \"urn:examples:helloservice\" use = \"encoded\"/> </input> <output> <soap:body encodingStyle = \"http://schemas.xmlsoap.org/soap/encoding/\" namespace = \"urn:examples:helloservice\" use = \"encoded\"/> </output> </operation> </binding> <service name =",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 40,
      "chunk_id": "p40c4",
      "title": "WSDLWeb Services Description Language <definitions name = \"HelloService\" targetNamespace = \"http://w",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "= \"urn:examples:helloservice\" use = \"encoded\"/> </output> </operation> </binding> <service name = \"Hello_Service\"> <documentation>WSDL File for HelloService</documentation> <port binding = \"tns:Hello_Binding\" name = \"Hello_Port\"> <soap:address location = \"http://www.examples.com/SayHello/\" /> </port> </service> </definitions>",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 40,
      "chunk_id": "p40c5",
      "title": "WSDLWeb Services Description Language <definitions name = \"HelloService\" targetNamespace = \"http://w",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "REST DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 41,
      "chunk_id": "p41c1",
      "title": "REST DSM08Middleware",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "RESTful Applications Statelessness ▪Each client request contains all necessary information. ▪Servers do not store client state, enhancing scalability. ResourceBased ▪Resources are identified by URIs and manipulated using standard HTTP methods. Uniform Interface ▪Consistent constraints for interacting with resources",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 42,
      "chunk_id": "p42c1",
      "title": "RESTful Applications Statelessness ▪Each client request contains all necessary information. ▪Servers",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Uniform Interface ▪Consistent constraints for interacting with resources. ▪Includes resource identification, manipulation through representations, and HATEOAS. Representation ▪Resources have multiple representations (e.g., JSON, XML). ▪Clients interact with resources through exchanged representations. DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 42,
      "chunk_id": "p42c2",
      "title": "RESTful Applications Statelessness ▪Each client request contains all necessary information. ▪Servers",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "RESTful Applications Stateless Communication ▪Each request is independent and selfcontained. Cacheability ▪Responses can be marked as cacheable or noncacheable. Layered System ▪Architecture can have multiple layers for scalability and separation of concerns. Optional: Code on Demand ▪Clients can download and execute code from the server",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 43,
      "chunk_id": "p43c1",
      "title": "RESTful Applications Stateless Communication ▪Each request is independent and selfcontained. Cacheab",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Optional: Code on Demand ▪Clients can download and execute code from the server. SelfDescriptive Messages ▪Messages contain information about their purpose. HATEOAS ▪Clients navigate through hyperlinks dynamically provided in the application’s representation. DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 43,
      "chunk_id": "p43c2",
      "title": "RESTful Applications Stateless Communication ▪Each request is independent and selfcontained. Cacheab",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "REST APIs “Representational State Transfer is intended to evoke an image of how a welldesigned Web application behaves: a network of web pages (a virtual state machine), where the user progresses through an application by selecting links (state transitions), resulting in the next page (representing the next state of the application) being transferred to the user and rendered for their use.”",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 44,
      "chunk_id": "p44c1",
      "title": "REST APIs “Representational State Transfer is intended to evoke an image of how a welldesigned Web a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "the next state of the application) being transferred to the user and rendered for their use.” DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 44,
      "chunk_id": "p44c2",
      "title": "REST APIs “Representational State Transfer is intended to evoke an image of how a welldesigned Web a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "REST APIs ▪Similar purpose like SOAP: allow heterogeneous devices/platforms to talk to each other and access services ▪However, much simpler than SOAP and more lightweight ▪Stateless ▪Use of JSON instead of XML ▪Easy to learn and use DSM08Middleware REST uses common HTTP methods to insert/delete/update/retrieve information: ▪ GET Requests a specific representation of a resource ▪ PUT Creates or",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 45,
      "chunk_id": "p45c1",
      "title": "REST APIs ▪Similar purpose like SOAP: allow heterogeneous devices/platforms to talk to each other an",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "information: ▪ GET Requests a specific representation of a resource ▪ PUT Creates or updates a resource with the supplied representation ▪ DELETE Deletes the specified resource ▪ POST Submits data to be processed by the identified resource Source: mannhowie.com",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 45,
      "chunk_id": "p45c2",
      "title": "REST APIs ▪Similar purpose like SOAP: allow heterogeneous devices/platforms to talk to each other an",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "REST – URL Endpoints ▪A URL endpoint in a RESTful API represents an object, data, or service that the API can access. ▪example.com/surveys represents survey templates, and example.com/surveys/123/responses represents responses for a specific survey",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 46,
      "chunk_id": "p46c1",
      "title": "REST – URL Endpoints ▪A URL endpoint in a RESTful API represents an object, data, or service that th",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪A best practice example: DSM08Middleware URL endpoint resource GET POST PUT DELETE /surveys Retrieve all surveys Create a new survey Bulk update surveys (not advised) Remove all surveys (not advised) /surveys/123 Retrieve the details for survey 123 Error Update the details of survey 123 if it exists Remove survey 123 /surveys/123/responses Retrieve all responses for survey Create a new response",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 46,
      "chunk_id": "p46c2",
      "title": "REST – URL Endpoints ▪A URL endpoint in a RESTful API represents an object, data, or service that th",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Remove survey 123 /surveys/123/responses Retrieve all responses for survey Create a new response for survey 123 Bulk update responses for survey 123 (not advised) Remove all responses for survey 123 (not advised) /responses/42 Retrieve the details for response Error Update the details of response 42 if it exists Remove response 42 mannhowie.com/restapi",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 46,
      "chunk_id": "p46c3",
      "title": "REST – URL Endpoints ▪A URL endpoint in a RESTful API represents an object, data, or service that th",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "gRPC DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 47,
      "chunk_id": "p47c1",
      "title": "gRPC DSM08Middleware",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "gRPCMotivation REST works well but… ▪only provides loosely defined contracts ▪HTTP binding to language needs to be maintained ▪uses inefficient JSON representation Communication should be easy and efficient! →This is what gRPC tries to solve gRPC nowadays is a highperformance, opensource, featurerich RPC framework, originally developed by Google, and now is a part of the cloud native computing",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 48,
      "chunk_id": "p48c1",
      "title": "gRPCMotivation REST works well but… ▪only provides loosely defined contracts ▪HTTP binding to langua",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "RPC framework, originally developed by Google, and now is a part of the cloud native computing foundation (or CNCF)",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 48,
      "chunk_id": "p48c2",
      "title": "gRPCMotivation REST works well but… ▪only provides loosely defined contracts ▪HTTP binding to langua",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". DSM08Middleware",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 48,
      "chunk_id": "p48c3",
      "title": "gRPCMotivation REST works well but… ▪only provides loosely defined contracts ▪HTTP binding to langua",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "gRPC – Code Generation DSM08Middleware ▪gRPC uses protocol buffers (protobuf) as IDL and also message interchange format. ▪Stubs are generated on the client side in gRPC from the protobuf service definition, allowing clients to make remote calls",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 49,
      "chunk_id": "p49c1",
      "title": "gRPC – Code Generation DSM08Middleware ▪gRPC uses protocol buffers (protobuf) as IDL and also messag",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Skeletons are generated on the server side in gRPC from the same protobuf service definition, providing a foundation for implementing server logic to handle incoming remote procedure calls (RPCs)",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 49,
      "chunk_id": "p49c2",
      "title": "gRPC – Code Generation DSM08Middleware ▪gRPC uses protocol buffers (protobuf) as IDL and also messag",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". REST gRPC Crossplatform Yes Yes Message Format Custom but generally JSON Protocol buffers Message Payload Size Medium/Large Small Processing Complexity Higher (text parsing) Lower (welldefined binary structure) Browser Support Yes (native) Yes (via gRPCWeb) REST vs. gRPC",
    "metadata": {
      "source": "Lecture_08.pdf",
      "page": 49,
      "chunk_id": "p49c3",
      "title": "gRPC – Code Generation DSM08Middleware ▪gRPC uses protocol buffers (protobuf) as IDL and also messag",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 04 – Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 1,
      "chunk_id": "p1c1",
      "title": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 04 – Time",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Motivation DSM04Time time: 3267 time: 3269 A B",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 2,
      "chunk_id": "p2c1",
      "title": "Motivation DSM04Time time: 3267 time: 3269 A B",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Motivation DSM04Time time: 3267 time: 3269 A B time: 3268 time: 3270 A B",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 3,
      "chunk_id": "p3c1",
      "title": "Motivation DSM04Time time: 3267 time: 3269 A B time: 3268 time: 3270 A B",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Motivation DSM04Time time: 3267 time: 3269 A B time: 3268 time: 3270 A B time: 3271 time: 3273 A B update(3269)? no update",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 4,
      "chunk_id": "p4c1",
      "title": "Motivation DSM04Time time: 3267 time: 3269 A B time: 3268 time: 3270 A B time: 3271 time: 3273 A B u",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Clock Synchronization ▪Logical Clocks ▪Lamport Clocks ▪Vector Clocks ▪Global State ▪Snapshot Algorithm DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 5,
      "chunk_id": "p5c1",
      "title": "Agenda ▪Clock Synchronization ▪Logical Clocks ▪Lamport Clocks ▪Vector Clocks ▪Global State ▪Snapshot",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Clock Synchronization ▪In a centralized system, time is unambiguous. ▪Crystal oscillators are used to measure time in computers ▪Oscillate at a welldefined frequency ▪Each oscillation decrements a counter by one ▪When counter is 0, →hardware interrupt (clock tick) ▪Each crystal runs at a slightly different frequency ▪No problem with a single system ▪But what about multiple computers? DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 6,
      "chunk_id": "p6c1",
      "title": "Clock Synchronization ▪In a centralized system, time is unambiguous. ▪Crystal oscillators are used t",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Clock Synchronization Two problems 1. How do we synchronize physical clocks with realworld clocks? (Accuracy) 2. How do we synchronize the clocks with each other? (Precision) Accuracy is about correctness and how close a measurement is to the true value, while precision is about consistency and how close repeated measurements are to each other",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 7,
      "chunk_id": "p7c1",
      "title": "Clock Synchronization Two problems 1. How do we synchronize physical clocks with realworld clocks? (",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". You can be accurate, precise, both, or neither depending on the situation. DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 7,
      "chunk_id": "p7c2",
      "title": "Clock Synchronization Two problems 1. How do we synchronize physical clocks with realworld clocks? (",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Clock Synchronization Two problems 1. How do we synchronize physical clocks with realworld clocks? 2. How do we synchronize the clocks with each other? DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 8,
      "chunk_id": "p8c1",
      "title": "Clock Synchronization Two problems 1. How do we synchronize physical clocks with realworld clocks? 2",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Clock Synchronization Two problems 1. How do we synchronize physical clocks with realworld clocks? ▪Basis for global time: Coordinated Universal Time (UTC) ▪~40 shortwave radio stations accross the world broadcast time signal ▪Accuracy ±1ms (in practice ±10ms) 2. How do we synchronize the clocks with each other? DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 9,
      "chunk_id": "p9c1",
      "title": "Clock Synchronization Two problems 1. How do we synchronize physical clocks with realworld clocks? ▪",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Clock Synchronization Algorithms ▪A software clock in a computer is derived from that computer’s hardware clock",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 10,
      "chunk_id": "p10c1",
      "title": "Clock Synchronization Algorithms ▪A software clock in a computer is derived from that computer’s har",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Counting the interrupts ▪All hardware clocks have clock drifts, leading to different values for time in different machines ▪1s30s per year ▪clock drift ratio ρ, precision π, time Δt ▪maximum offset = 2ρ * Δt ▪To guarantee a precision π, resynchronization is required every π/(2ρ) seconds DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 10,
      "chunk_id": "p10c2",
      "title": "Clock Synchronization Algorithms ▪A software clock in a computer is derived from that computer’s har",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Christian’s Algorithm (Network Time Protocol) ▪Client contacts a timeserver (master) ▪Calculate roundtrip time (RTT) of messages ▪RTT = (T1T0) – (T3T2) ▪(T3T2) master’s interrupt handling time ▪Assumption: δ = RTT/2 ▪Pi receives clock Cm from master server ▪Ci(T1) := Cm + δ; Cm read at time T3 ▪If Ci > Cm+ d, slow down Ci ▪Never! set clock back in time DSM04Time t T0 T1 T2 T3 δ Pi Master Cm Time?",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 11,
      "chunk_id": "p11c1",
      "title": "Christian’s Algorithm (Network Time Protocol) ▪Client contacts a timeserver (master) ▪Calculate roun",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "> Cm+ d, slow down Ci ▪Never! set clock back in time DSM04Time t T0 T1 T2 T3 δ Pi Master Cm Time? δ",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 11,
      "chunk_id": "p11c2",
      "title": "Christian’s Algorithm (Network Time Protocol) ▪Client contacts a timeserver (master) ▪Calculate roun",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Clock Synchronization ▪Logical Clocks ▪Lamport Clocks ▪Vector Clocks ▪Global State ▪Snapshot Algorithm DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 12,
      "chunk_id": "p12c1",
      "title": "Agenda ▪Clock Synchronization ▪Logical Clocks ▪Lamport Clocks ▪Vector Clocks ▪Global State ▪Snapshot",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Logical Clocks (HappensbeforeRelationship) ▪Principle of causality: If an event x is in any way the reason for a second event y, we say that x has happened before y. ▪Example: message sending happens before receiving ▪System Model: ▪Set of processes ▪Process communications through messages ▪Processes formed as a series of events DSM04Time P Q R p1 p2 p3 q1 q2 q3 q4 q5 r1 r2 r3 r4 t",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 13,
      "chunk_id": "p13c1",
      "title": "Logical Clocks (HappensbeforeRelationship) ▪Principle of causality: If an event x is in any way the ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Definition: Happenedbefore ▪The “happenedbefore“ (→) relation is defined as follows 1. a, b are events of a process and a happened before b ▪a → b holds 2. If a is send event of a process and b related receive event of a process ▪a →b holds 3",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 14,
      "chunk_id": "p14c1",
      "title": "Definition: Happenedbefore ▪The “happenedbefore“ (→) relation is defined as follows 1. a, b are even",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". If a is send event of a process and b related receive event of a process ▪a →b holds 3. If a, b, c are events in any processes with a →b and b →c ▪a →c holds (transitivity) DSM04Time P Q R p1 p2 p3 q1 q2 q3 q4 q5 r1 r2 r3 r4 t p1 → p2 p2 → r3 p1 → r3",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 14,
      "chunk_id": "p14c2",
      "title": "Definition: Happenedbefore ▪The “happenedbefore“ (→) relation is defined as follows 1. a, b are even",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Definition: Happenedbefore ▪Two events a, b are parallel or causal independent (a || b), if neither a →b nor b →a is true. ▪Example: q1 || r1 DSM04Time P Q R p1 p2 p3 q1 q2 q3 q4 q5 r1 r2 r3 r4 t p1 → p2 p2 → r3 p1 → r3",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 15,
      "chunk_id": "p15c1",
      "title": "Definition: Happenedbefore ▪Two events a, b are parallel or causal independent (a || b), if neither ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Lamport Clocks ▪Logical clock: each process Pi has a clock Ci ▪Ci: e ϵ ℕ0; e event in Pi ▪Clock system: function C assigns to each event e a number C(e), with C(e) = Ci(e) ▪Clock condition: A clock system is correct, if ∀ a,b: a →b ⇒ C(a) < C(b) DSM04Time Reads as: \"For all values of a and b, if a happened before b, then the value of C(a) is less than the value of C(b)",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 16,
      "chunk_id": "p16c1",
      "title": "Lamport Clocks ▪Logical clock: each process Pi has a clock Ci ▪Ci: e ϵ ℕ0; e event in Pi ▪Clock syst",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". P1 P2 P3 t Note: → happened before ⇒ logical implication",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 16,
      "chunk_id": "p16c2",
      "title": "Lamport Clocks ▪Logical clock: each process Pi has a clock Ci ▪Ci: e ϵ ℕ0; e event in Pi ▪Clock syst",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Lamport Clocks – Clock Conditions Clock condition is satisfied if ▪C1: a, b are events in process Pi and a →b ⇒ Ci(a) < Ci(b) ▪C2: a is a send event of message m in process Pi and b the corresponding receive event in process Pk ⇒Ci(a) < Ck(b) DSM04Time P1 P2 P3 t",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 17,
      "chunk_id": "p17c1",
      "title": "Lamport Clocks – Clock Conditions Clock condition is satisfied if ▪C1: a, b are events in process Pi",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Lamport Clocks – Algorithm Each process Pi: ▪initializes Ci = 0; ▪increments Ci before executing an event (Ci++) ▪e.g., local event, sending/receiving a message ▪adds a timestamp ts to message m before sending it ▪ts(m) = Ci ▪computes max{Ci,ts(m)} as the new Ci when receiving a a message from another process DSM04Time Pk max(1,3)+1 = 4 Ci Ck t Pi",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 18,
      "chunk_id": "p18c1",
      "title": "Lamport Clocks – Algorithm Each process Pi: ▪initializes Ci = 0; ▪increments Ci before executing an ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Lamport Clocks – Characteristics ▪Inversion of clock condition does not hold! ▪a →b ⇒ C(a) < C(b) (clock condition) ▪But C(a) < C(b) ⇒ a →b ▪What holds ▪C(a) < C(b) ⇒ (a →b) ∨ (a || b) ▪C(a) < C(b) ⇒ ¬(b → a) “The future does not affect the past“ ▪Desirable ▪(a →b ⇒ C(a) < C(b)) ∧ (C(a) < C(b) ⇒ a →b) (strong clock condition) DSM04Time P1 P2 P3 t",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 19,
      "chunk_id": "p19c1",
      "title": "Lamport Clocks – Characteristics ▪Inversion of clock condition does not hold! ▪a →b ⇒ C(a) < C(b) (c",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks ▪Lamport's clock condition does not allow to derive causal dependencies from logical clocks ▪Vector clocks provide equivalence of timestamp and causal order: VC(a) < VC(b) ⇔ a →b ▪Allow to determine causal dependencies using timestamps DSM04Time P Q R t a b",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 20,
      "chunk_id": "p20c1",
      "title": "Vector Clocks ▪Lamport's clock condition does not allow to derive causal dependencies from logical c",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks ▪Timestamp is ndimensional vector ▪Time is defined by a set of ndimensional vectors ▪Clock is an array C[1:n] ▪Notation: ▪VC (Pi)[k] kth component of vector clock of process Pi ▪VC (a) timestamp of event a ▪VC (a)[k] kth component of the timestamp DSM04Time P Q R t a b",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 21,
      "chunk_id": "p21c1",
      "title": "Vector Clocks ▪Timestamp is ndimensional vector ▪Time is defined by a set of ndimensional vectors ▪C",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Causal History of Events ▪Definition causal history (e) of an event e : ▪ (e) = {e' | e' r→e} ▪(r→is the reflexive version of →) ▪Claim: e' r→e ⇔e' ϵ (e) ▪Claim: e || e' ⇔ ¬ (e ϵ (e' )) ∧¬(e' ϵ (e)) DSM04Time P R S t Q T The cone includes all events that have a causal effect on e e",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 22,
      "chunk_id": "p22c1",
      "title": "Vector Clocks – Causal History of Events ▪Definition causal history (e) of an event e : ▪ (e) = {e' ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Timestamps ▪Timestamp VC(e) of an event e is a vector out of (ℕ0)n (n = #processes) ▪Let Ei be the set of events at process Pi ▪VC (e)[i] = | {e' ϵ Ei | e' r→e } | = number of events of Pi that causally precede event e ▪VC(e) encodes the causal history (e) DSM04Time P R S t Q T e The cone includes all events that have a causal effect on e",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 23,
      "chunk_id": "p23c1",
      "title": "Vector Clocks – Timestamps ▪Timestamp VC(e) of an event e is a vector out of (ℕ0)n (n = #processes) ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Questions: 1) Where to add the cone? 2) What is the timestamp of e? Vector Clocks – Example DSM04Time e",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 24,
      "chunk_id": "p24c1",
      "title": "Questions: 1) Where to add the cone? 2) What is the timestamp of e? Vector Clocks – Example DSM04Tim",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Timestamps ▪Component k points to most recent event of process k (and therefore implicitly on all previous events of process k) ▪Vector represents the complete causal history ▪Encodes \"knowledge\" about all previous events DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 25,
      "chunk_id": "p25c1",
      "title": "Vector Clocks – Timestamps ▪Component k points to most recent event of process k (and therefore impl",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Arithmetics DSM04Time ≤ || More formally: ▪VC1 ≤VC2 ⇔∀i : VC1[i ] ≤VC2[i ] ▪VC1 || VC2 ⇔¬(VC1 ≤VC2) ∧¬(VC2 ≤VC1) ▪VC1 < VC2 ⇔VC1 ≤VC2 ∧VC1 ≠ VC2 comparable concurrent",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 26,
      "chunk_id": "p26c1",
      "title": "Vector Clocks – Arithmetics DSM04Time ≤ || More formally: ▪VC1 ≤VC2 ⇔∀i : VC1[i ] ≤VC2[i ] ▪VC1 || V",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Arithmetics DSM04Time e‘ e ▪Interpretation of VC (e ) < VC (e' ): ▪e belongs to the causal history of e' ▪Cone of e‘ contains cone of e",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 27,
      "chunk_id": "p27c1",
      "title": "Vector Clocks – Arithmetics DSM04Time e‘ e ▪Interpretation of VC (e ) < VC (e' ): ▪e belongs to the ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Algorithm Idea ▪Idea: Analogous to Lamport clock, but using vectors ▪Messages contain the complete causal history of the sender ⇒ time stamp of the send event ▪Reception of a message: merging of the cones = merging the knowledge about history ⇒ supremum of the vectors DSM04Time e e‘",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 28,
      "chunk_id": "p28c1",
      "title": "Vector Clocks – Algorithm Idea ▪Idea: Analogous to Lamport clock, but using vectors ▪Messages contai",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Algorithm Idea ▪Idea: Analogous to Lamport clock, but using vectors ▪Messages contain the complete causal history of the sender ⇒ time stamp of the send event ▪Reception of a message: merging of the cones = merging the knowledge about history ⇒ supremum of the vectors DSM04Time e e‘",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 29,
      "chunk_id": "p29c1",
      "title": "Vector Clocks – Algorithm Idea ▪Idea: Analogous to Lamport clock, but using vectors ▪Messages contai",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Algorithm Idea ▪Idea: Analogous to Lamport clock, but using vectors ▪Messages contain the complete causal history of the sender ⇒ time stamp of the send event ▪Reception of a message: merging of the cones = merging the knowledge about history ⇒ supremum of the vectors DSM04Time e e‘",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 30,
      "chunk_id": "p30c1",
      "title": "Vector Clocks – Algorithm Idea ▪Idea: Analogous to Lamport clock, but using vectors ▪Messages contai",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Algorithm Idea ▪Idea: Analogous to Lamport clock, but using vectors ▪Messages contain the complete causal history of the sender ⇒ time stamp of the send event ▪Reception of a message: merging of the cones = merging the knowledge about history ⇒ supremum of the vectors DSM04Time e e‘",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 31,
      "chunk_id": "p31c1",
      "title": "Vector Clocks – Algorithm Idea ▪Idea: Analogous to Lamport clock, but using vectors ▪Messages contai",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Algorithm (1) ▪Each process has vector clock ▪(encodes causal history) ▪Local Event: ▪increase own component ▪Send Event: ▪increase own component and attach vector to message ▪Receive Event: ▪increase own component and calculate supremum of vectors DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 32,
      "chunk_id": "p32c1",
      "title": "Vector Clocks – Algorithm (1) ▪Each process has vector clock ▪(encodes causal history) ▪Local Event:",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Another Example DSM04Time p1 p2 p3 p4",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 33,
      "chunk_id": "p33c1",
      "title": "Vector Clocks – Another Example DSM04Time p1 p2 p3 p4",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Another Example DSM04Time p1 p2 p3 p4",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 34,
      "chunk_id": "p34c1",
      "title": "Vector Clocks – Another Example DSM04Time p1 p2 p3 p4",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Algorithm (2) ▪Initialization of clock in process pk: ▪VC (pk) := (0, ..., 0); ▪Local event in pk: ▪VC (pk)[k] := VC (pk)[k] + 1; ▪Send event in pk : ▪VC (pk)[k] := VC (pk)[k] + 1; ▪send (m, VC (m)); (where VC (m) = VC (pk)) ▪Receive event in pk: ▪VC (pk)[k] := VC (pk)[k] + 1; receive (m, VC (m)); ▪∀i = 1...n : VC (pk)[i] := max (VC (pk)[i], VC (m)[i]) DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 35,
      "chunk_id": "p35c1",
      "title": "Vector Clocks – Algorithm (2) ▪Initialization of clock in process pk: ▪VC (pk) := (0, ..., 0); ▪Loca",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Interpretation ▪One can show: ▪a →b ⇔VC(a) < VC(b) ▪Concrete interpretation: ▪VC(a) < VC(b) ⇔there is a causal relationship ▪Corollary : ▪e || e' ⇔VC (e ) || VC (e' ) ▪Only concurrent events do not influence each other DSM04Time b a",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 36,
      "chunk_id": "p36c1",
      "title": "Vector Clocks – Interpretation ▪One can show: ▪a →b ⇔VC(a) < VC(b) ▪Concrete interpretation: ▪VC(a) ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Vector Clocks – Summary ▪Foundation of many distributed algorithms ▪Broadcast ▪Termination ▪Deadlock detection ▪Garbage collection ▪And more … ▪In general: Used nearly everywhere, where consistent state information is to be captured in distributed systems! DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 37,
      "chunk_id": "p37c1",
      "title": "Vector Clocks – Summary ▪Foundation of many distributed algorithms ▪Broadcast ▪Termination ▪Deadlock",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Exercise – Lamport Clocks DSM04Time t P Q R S",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 38,
      "chunk_id": "p38c1",
      "title": "Exercise – Lamport Clocks DSM04Time t P Q R S",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Exercise – Vector Clocks DSM04Time P Q R p1 p2 p3 p4 q1 q2 q3 p5 r1 r2 r3 r4",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 39,
      "chunk_id": "p39c1",
      "title": "Exercise – Vector Clocks DSM04Time P Q R p1 p2 p3 p4 q1 q2 q3 p5 r1 r2 r3 r4",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Clock Synchronization ▪Logical Clocks ▪Lamport Clocks ▪Vector Clocks ▪Global State ▪Snapshot Algorithm DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 40,
      "chunk_id": "p40c1",
      "title": "Agenda ▪Clock Synchronization ▪Logical Clocks ▪Lamport Clocks ▪Vector Clocks ▪Global State ▪Snapshot",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Global StateMotivation DSM04Time Distributed garbage collection: Find unreferenced objects Distributed deadlocks: Multiple processes wait for each other Distributed termination: Check whether a distributed algorithm has terminated Distributed debugging: Check whether assertions hold",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 41,
      "chunk_id": "p41c1",
      "title": "Global StateMotivation DSM04Time Distributed garbage collection: Find unreferenced objects Distribut",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Global StateMotivation DSM04Time ▪Given a global time: Just record state at one agreed time ▪However, there is no perfect clock synchronization ▪Goal: Assemble a meaningful global state from the local states recorded at different real times ▪Definitions: ▪ϕ is a system of N processes with pi (i = 1, 2, … N) ▪e is an event in this process (an internal action (updating a local variable) or sending",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 42,
      "chunk_id": "p42c1",
      "title": "Global StateMotivation DSM04Time ▪Given a global time: Just record state at one agreed time ▪However",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "2, … N) ▪e is an event in this process (an internal action (updating a local variable) or sending or receipt of a message to/from another process) ▪history(pi) = hi = <𝑒𝑖 0, 𝑒𝑖 1, 𝑒𝑖 2, …> ▪history at a certain point in time k: 𝑒𝑖 𝑘= < 𝑒𝑖 0, 𝑒𝑖 1,…, 𝑒𝑖 𝑘 >",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 42,
      "chunk_id": "p42c2",
      "title": "Global StateMotivation DSM04Time ▪Given a global time: Just record state at one agreed time ▪However",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Global State – Cuts DSM04Time ▪history at a certain point in time k: ℎ𝑖 𝑘= < 𝑒𝑖 0, 𝑒𝑖 1,…, 𝑒𝑖 𝑘> ▪state 𝑠𝑖 𝑘the state of process pi just before the kth event occurs ▪global history of ϕ: H = h1 ⋃ h2 ⋃ … ⋃ hN (history of p1 and p2 and …) ▪global state S = (s1, s2, …, sN) ▪Cut: The union of histories of all processes where pi is cut: C = < ℎ1 𝐶1, ℎ2 𝐶2,…, 𝑒𝑖 𝑁> ▪Each process might be cut at a",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 43,
      "chunk_id": "p43c1",
      "title": "Global State – Cuts DSM04Time ▪history at a certain point in time k: ℎ𝑖 𝑘= < 𝑒𝑖 0, 𝑒𝑖 1,…, 𝑒𝑖 𝑘> ▪st",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "of all processes where pi is cut: C = < ℎ1 𝐶1, ℎ2 𝐶2,…, 𝑒𝑖 𝑁> ▪Each process might be cut at a different event (ek) ▪𝑒1 𝐶1 is the event in process 1 that was just processed after the cut at process 1 ▪The set of events { 𝑒𝑖 𝐶𝑖: i = 1, 2, …, N} is called the frontier of the cut",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 43,
      "chunk_id": "p43c2",
      "title": "Global State – Cuts DSM04Time ▪history at a certain point in time k: ℎ𝑖 𝑘= < 𝑒𝑖 0, 𝑒𝑖 1,…, 𝑒𝑖 𝑘> ▪st",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Global State – Cuts Examples DSM04Time ▪First cut <𝑒1 0, 𝑒2 0> ▪Inconsistent cut ▪Why? p2 includes the receipt of message m1 which is sent after the cut in p1. “Message from the future” ▪Second cut <𝑒1 2, 𝑒2 2> ▪Consistent cut ▪Includes the sending and receipt of m1 as well as the sending of message m2",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 44,
      "chunk_id": "p44c1",
      "title": "Global State – Cuts Examples DSM04Time ▪First cut <𝑒1 0, 𝑒2 0> ▪Inconsistent cut ▪Why? p2 includes t",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Note: A cut C is consistent if, for each event it contains, it also contains all the events that happenedbefore that event: For all events 𝑒∈𝐶, 𝑓→𝑒⇒𝑓∈𝐶 This is also called a consistent global state.",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 44,
      "chunk_id": "p44c2",
      "title": "Global State – Cuts Examples DSM04Time ▪First cut <𝑒1 0, 𝑒2 0> ▪Inconsistent cut ▪Why? p2 includes t",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Clock Synchronization ▪Logical Clocks ▪Lamport Clocks ▪Vector Clocks ▪Global State ▪Snapshot Algorithm DSM04Time",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 45,
      "chunk_id": "p45c1",
      "title": "Agenda ▪Clock Synchronization ▪Logical Clocks ▪Lamport Clocks ▪Vector Clocks ▪Global State ▪Snapshot",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot Algorithm of Chandy and Lamport DSM04Time ▪First snapshot algorithm, published in 1985 ▪Goal: record a set of process and channel states for a set of processes pi (i = 1, 2, ..., N), such that ▪the recorded global state is consistent, even though the recorded (local) states have never appeared at the same time in the execution",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 46,
      "chunk_id": "p46c1",
      "title": "Snapshot Algorithm of Chandy and Lamport DSM04Time ▪First snapshot algorithm, published in 1985 ▪Goa",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Algorithm: ▪records (process and channel) state locally at processes ▪does not give method for gathering global state at one site ▪obvious method: processes send recorded state to collector process",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 46,
      "chunk_id": "p46c2",
      "title": "Snapshot Algorithm of Chandy and Lamport DSM04Time ▪First snapshot algorithm, published in 1985 ▪Goa",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot AlgorithmAssumptions DSM04Time ▪Neither channels nor processes fail ▪Communication is reliable, i.e., each message is eventually received exactly once ▪Channels are unidirectional and provide FIFOordered message delivery ▪incoming: channels over which process receives messages ▪outgoing: channels over which process sends messages ▪The graph of processes and channels is strongly connected",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 47,
      "chunk_id": "p47c1",
      "title": "Snapshot AlgorithmAssumptions DSM04Time ▪Neither channels nor processes fail ▪Communication is relia",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "over which process sends messages ▪The graph of processes and channels is strongly connected ▪i.e., there is a path between any two processes ▪Any process may initiate a global snapshot any time ▪Processes may continue their execution and send and receive normal messages while the snapshot takes place p1 p2 p3 p4",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 47,
      "chunk_id": "p47c2",
      "title": "Snapshot AlgorithmAssumptions DSM04Time ▪Neither channels nor processes fail ▪Communication is relia",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot AlgorithmGoal DSM04Time ▪Consistent cut: prevents “messages from future“ (m1) ▪Messages in transit (m2 was send in grey and arrives in blue epoch) ▪not captured in recorded process states of the receivers ▪are to be recorded in channel state m1 m2",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 48,
      "chunk_id": "p48c1",
      "title": "Snapshot AlgorithmGoal DSM04Time ▪Consistent cut: prevents “messages from future“ (m1) ▪Messages in ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot Algorithm – Basic Idea DSM04Time ▪Each process records ▪process state, and ▪set of messages sent to it ▪Which messages are recorded by a process p? ▪for each of p‘s incoming channels, any message ▪that arrived after p recorded its state, and ▪that was sent before sender recorded its own state p1 p2 m1 m2 s1 s2 <m1,m2> c m3 M M‘ m0",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 49,
      "chunk_id": "p49c1",
      "title": "Snapshot Algorithm – Basic Idea DSM04Time ▪Each process records ▪process state, and ▪set of messages",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot Algorithm – Markers DSM04Time ▪The algorithm uses special marker messages ▪These markers serve a dual purpose ▪As a prompt to for the receiver to record its state ▪if it has not already done so ▪As a means of determining which messages to include in the channel state ▪The algorithm is defined by two rules ▪The marker receiving rule ▪The marker sending rule p1 p2 m1 m2 s1 s2 <m1,m2> c m3 M",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 50,
      "chunk_id": "p50c1",
      "title": "Snapshot Algorithm – Markers DSM04Time ▪The algorithm uses special marker messages ▪These markers se",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "by two rules ▪The marker receiving rule ▪The marker sending rule p1 p2 m1 m2 s1 s2 <m1,m2> c m3 M M‘ m0",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 50,
      "chunk_id": "p50c2",
      "title": "Snapshot Algorithm – Markers DSM04Time ▪The algorithm uses special marker messages ▪These markers se",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot Algorithm – Marker Rules DSM04Time Marker receiving rule for process pi: When pi receives a marker message over channel c: if (pi has not yet recorded its state) it records its process state now; records the state of c as the empty set; turns on recording of messages arriving over other incoming channels; else pi records the state of c as the set of messages it has received over..",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 51,
      "chunk_id": "p51c1",
      "title": "Snapshot Algorithm – Marker Rules DSM04Time Marker receiving rule for process pi: When pi receives a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". channel c since it saved its state. end if",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 51,
      "chunk_id": "p51c2",
      "title": "Snapshot Algorithm – Marker Rules DSM04Time Marker receiving rule for process pi: When pi receives a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot Algorithm – Marker Rules DSM04Time Marker sending rule for process pi: After pi has recorded its state, for each outgoing channel c: pi sends one marker message over c (before it sends any other message over c)",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 52,
      "chunk_id": "p52c1",
      "title": "Snapshot Algorithm – Marker Rules DSM04Time Marker sending rule for process pi: After pi has recorde",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot Algorithm – Remarks DSM04Time Marker sending rule obligates process to ▪send marker after having recorded the state but before sending any other message Marker receiving rule obligates process to ▪record state and note incoming messages if this is the first marker ▪record noted messages (i.e., channel state), otherwise",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 53,
      "chunk_id": "p53c1",
      "title": "Snapshot Algorithm – Remarks DSM04Time Marker sending rule obligates process to ▪send marker after h",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Each process may begin algorithm at any time ▪acts as if it received marker and follows marker receiving rule Several processes may start the algorithm ▪as long as markers they use can be distinguished",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 53,
      "chunk_id": "p53c2",
      "title": "Snapshot Algorithm – Remarks DSM04Time Marker sending rule obligates process to ▪send marker after h",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot Algorithm – Example 1 DSM04Time ▪M sent over a FIFOchannel after s1 was recorded, and before any other message is sent by p1 ▪No “messages from future“ => consistent cut ▪M‘ sent over FIFOchannel after s2 was recorded, before any other message is sent by p2 ▪all messages sent before s2 is recorded arrive before M‘ at p1 ▪no message sent after s2 is recorded arrive before M‘ at p1 ▪i.e.,",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 54,
      "chunk_id": "p54c1",
      "title": "Snapshot Algorithm – Example 1 DSM04Time ▪M sent over a FIFOchannel after s1 was recorded, and befor",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "recorded arrive before M‘ at p1 ▪no message sent after s2 is recorded arrive before M‘ at p1 ▪i.e., no “messages from future” <m1, m2> p1 p2 M' M m1 m2 s1 c s2",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 54,
      "chunk_id": "p54c2",
      "title": "Snapshot Algorithm – Example 1 DSM04Time ▪M sent over a FIFOchannel after s1 was recorded, and befor",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot Algorithm – Example 2 DSM04Time p1 p2 M m1 m2 m3 m4 m p3 p1 p2 p3",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 55,
      "chunk_id": "p55c1",
      "title": "Snapshot Algorithm – Example 2 DSM04Time p1 p2 M m1 m2 m3 m4 m p3 p1 p2 p3",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot Algorithm – Example 2 DSM04Time M m1 m2 m3 m4 m M M‘ p1 p2 p3 p1 p2 p3",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 56,
      "chunk_id": "p56c1",
      "title": "Snapshot Algorithm – Example 2 DSM04Time M m1 m2 m3 m4 m M M‘ p1 p2 p3 p1 p2 p3",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot Algorithm – Example 2 DSM04Time M m1 m2 m3 m4 m M M‘ M‘ p1 p2 p3 p1 p2 p3",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 57,
      "chunk_id": "p57c1",
      "title": "Snapshot Algorithm – Example 2 DSM04Time M m1 m2 m3 m4 m M M‘ M‘ p1 p2 p3 p1 p2 p3",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot Algorithm – Example 2 DSM04Time M m1 m2 m3 m4 m M M‘ M‘ <m5> <m1, m2> p1 p2 p3 p1 p2 p3",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 58,
      "chunk_id": "p58c1",
      "title": "Snapshot Algorithm – Example 2 DSM04Time M m1 m2 m3 m4 m M M‘ M‘ <m5> <m1, m2> p1 p2 p3 p1 p2 p3",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Snapshot AlgorithmSummary DSM04Time ▪The ability to calculate global snapshots in a distributed system is very important. ▪But don’t want to interrupt running distributed application. ▪ChandyLamport algorithm calculates global snapshot. ▪Obeys causality (creates a consistent cut). ▪Can be used to detect global properties.",
    "metadata": {
      "source": "Lecture_04.pdf",
      "page": 59,
      "chunk_id": "p59c1",
      "title": "Snapshot AlgorithmSummary DSM04Time ▪The ability to calculate global snapshots in a distributed syst",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 05 – Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 1,
      "chunk_id": "p1c1",
      "title": "Prof. Dr. Janick Edinger Distributed Systems and Middleware 05 – Coordination",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Mutual Exclusion ▪Election DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 2,
      "chunk_id": "p2c1",
      "title": "Agenda ▪Mutual Exclusion ▪Election DSM05Coordination",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual ExclusionMotivation ▪Very much related to mutual exclusion in local systems (operating systems) ▪How is it done there? ▪In distributed systems: No central variables or signals available ▪Solutions must solely be based on message passing ▪Basic solutions ▪Permissionbased: A process wanting to enter its critical region, or access a resource, needs permission from other processes",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 3,
      "chunk_id": "p3c1",
      "title": "Mutual ExclusionMotivation ▪Very much related to mutual exclusion in local systems (operating system",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Tokenbased: A token is passed between processes. The one who has the token may proceed in its critical region, or pass it on when not interested. DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 3,
      "chunk_id": "p3c2",
      "title": "Mutual ExclusionMotivation ▪Very much related to mutual exclusion in local systems (operating system",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Centralized Solution ▪Do it as in oneprocessor systems: Use a central controller. ▪One process is selected as the coordinator. a) Process P1 asks the coordinator for permission to access a shared resource. Permission is granted. b) Process P2 then asks permission to access the same resource. The coordinator does not reply",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 4,
      "chunk_id": "p4c1",
      "title": "Centralized Solution ▪Do it as in oneprocessor systems: Use a central controller. ▪One process is se",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". b) Process P2 then asks permission to access the same resource. The coordinator does not reply. c) When P1 releases the resource, it tells the coordinator, which then replies to P2. ▪Simple, but SPOF and bottleneck. Plus, how to distinguish a dead coordinator from a “request denied”? However, powerful! DSM05Coordination a) b) c)",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 4,
      "chunk_id": "p4c2",
      "title": "Centralized Solution ▪Do it as in oneprocessor systems: Use a central controller. ▪One process is se",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion using Lamport‘s Algorithm ▪Used to order critical section requests and to resolve any conflict between requests ▪A request with smaller timestamp will be given permission to execute critical section first than a request with larger timestamp, and so on. ▪Messages ▪A process sends a REQUEST message to all other processes to get their permission to enter critical section",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 5,
      "chunk_id": "p5c1",
      "title": "Mutual Exclusion using Lamport‘s Algorithm ▪Used to order critical section requests and to resolve a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪A process sends a REPLY message to requesting process to give its permission to enter the critical section. ▪A process sends a RELEASE message to all other processes upon exiting the critical section. ▪Every process pi, keeps a queue to store critical section requests ordered by their timestamps",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 5,
      "chunk_id": "p5c2",
      "title": "Mutual Exclusion using Lamport‘s Algorithm ▪Used to order critical section requests and to resolve a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪Every process pi, keeps a queue to store critical section requests ordered by their timestamps. ▪request_queuei denotes the queue of process pi ▪A timestamp is given to each critical section request using Lamport’s logical clock. DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 5,
      "chunk_id": "p5c3",
      "title": "Mutual Exclusion using Lamport‘s Algorithm ▪Used to order critical section requests and to resolve a",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion using Lamport‘s Algorithm To enter critical section: ▪When a process pi wants to enter the critical section ▪sends a request message Request(tsi,i) to all other processes ▪places the request on request_queuei",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 6,
      "chunk_id": "p6c1",
      "title": "Mutual Exclusion using Lamport‘s Algorithm To enter critical section: ▪When a process pi wants to en",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪When a process pj receives the request message Request(tsi,i) from process pi ▪return a timestamped REPLY message to process pi ▪place the request of process pi on request_queuej DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 6,
      "chunk_id": "p6c2",
      "title": "Mutual Exclusion using Lamport‘s Algorithm To enter critical section: ▪When a process pi wants to en",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion using Lamport‘s Algorithm To execute the critical section: ▪A process pi can enter the critical section ▪if it has received the message with timestamp larger than (tsi, i) from all other sites ▪and its own request is at the top of request_queuei DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 7,
      "chunk_id": "p7c1",
      "title": "Mutual Exclusion using Lamport‘s Algorithm To execute the critical section: ▪A process pi can enter ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion using Lamport‘s Algorithm To release the critical section: ▪When a process pi exits the critical section ▪it removes its own request from the top of its request queue ▪And sends a timestamped RELEASE message to all other processes ▪When a process pj receives the timestamped RELEASE message from process pi ▪it removes the request of pi from its request queue DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 8,
      "chunk_id": "p8c1",
      "title": "Mutual Exclusion using Lamport‘s Algorithm To release the critical section: ▪When a process pi exits",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 9,
      "chunk_id": "p9c1",
      "title": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 10,
      "chunk_id": "p10c1",
      "title": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 11,
      "chunk_id": "p11c1",
      "title": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2 p2,",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 12,
      "chunk_id": "p12c1",
      "title": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2 p2,",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 13,
      "chunk_id": "p13c1",
      "title": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2 p2,",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 14,
      "chunk_id": "p14c1",
      "title": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2 p2,",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2 p1, 2 p1, 2 p1, 2 p2, 1 p2, 1 p1, 2",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 15,
      "chunk_id": "p15c1",
      "title": "Mutual Exclusion using Lamport‘s Algorithm DSM05Coordination p1, 2 p2, 1 p1, 2 p2, 1 p2, 1 p1, 2 p1,",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Optimization: Ricart & Agrawala ▪Interested process sends a request to all other processes ▪The receiving processes return a response to a request only when: ▪they have no interest in the shared resource; or ▪they are waiting for the resource, but have lower priority (known through comparison of timestamps). ▪In all other cases, reply is deferred, implying some more local administration",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 16,
      "chunk_id": "p16c1",
      "title": "Optimization: Ricart & Agrawala ▪Interested process sends a request to all other processes ▪The rece",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪In all other cases, reply is deferred, implying some more local administration. ▪Problem: Really prone to failures (#nodes points of failure) DSM05Coordination a) b) c)",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 16,
      "chunk_id": "p16c2",
      "title": "Optimization: Ricart & Agrawala ▪Interested process sends a request to all other processes ▪The rece",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion – Tokenbased ▪Organize processes in a logical ring, and let a token be passed between them. The one that holds the token is allowed to enter the critical region (if it wants to). ▪Simple, but: ▪when token gets lost, a new token needs to be created. Plus, it needs to be ensured, that it is the only token in the system. Otherwise …? DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 17,
      "chunk_id": "p17c1",
      "title": "Mutual Exclusion – Tokenbased ▪Organize processes in a logical ring, and let a token be passed betwe",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion – A Fully Decentralized Solution ▪Each resource has N coordinators, ‘randomly’ selected from a group of peers ▪A hash function is used to compute the N keys of the coordinators ▪Every node in the network can compute these keys ▪To access a resource, a process needs a majority vote from m > N/2 coordinators ▪if vote is <m, process backs of for a random amount of time ▪m can be",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 18,
      "chunk_id": "p18c1",
      "title": "Mutual Exclusion – A Fully Decentralized Solution ▪Each resource has N coordinators, ‘randomly’ sele",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "from m > N/2 coordinators ▪if vote is <m, process backs of for a random amount of time ▪m can be configured",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 18,
      "chunk_id": "p18c2",
      "title": "Mutual Exclusion – A Fully Decentralized Solution ▪Each resource has N coordinators, ‘randomly’ sele",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Why not N/2 + 1? DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 18,
      "chunk_id": "p18c3",
      "title": "Mutual Exclusion – A Fully Decentralized Solution ▪Each resource has N coordinators, ‘randomly’ sele",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion – A Fully Decentralized Solution ▪Coordinators can crash and restart any time ▪Recovery: Start over and forget everything that has happened ▪Problem: Might already have given access to resource ▪If f ≥ 2m – N, mutual exclusion not given (f = #restarted coordinators) ▪In practice: Violations can be neglected when m is set conservatively ▪What happens when multiple processes request",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 19,
      "chunk_id": "p19c1",
      "title": "Mutual Exclusion – A Fully Decentralized Solution ▪Coordinators can crash and restart any time ▪Reco",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "can be neglected when m is set conservatively ▪What happens when multiple processes request access at (almost) the same time? ▪No process gets >m votes, resource keeps underutilized/unused ▪Solution: Clients can give back their votes and coordinators can vote again ▪After a while, a client typically receives sufficient votes DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 19,
      "chunk_id": "p19c2",
      "title": "Mutual Exclusion – A Fully Decentralized Solution ▪Coordinators can crash and restart any time ▪Reco",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Mutual Exclusion – Summary ▪The centralized algorithm is simplest and also most efficient ▪Least messages required (request, grant to enter, release) ▪Shortest delay before a process can enter the critical section ▪All algorithms suffer from failures ▪Complex recovery mechanism necessary for distributed algorithms →Better go for a centralized solution But what if this central devices fails…?",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 20,
      "chunk_id": "p20c1",
      "title": "Mutual Exclusion – Summary ▪The centralized algorithm is simplest and also most efficient ▪Least mes",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "algorithms →Better go for a centralized solution But what if this central devices fails…? DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 20,
      "chunk_id": "p20c2",
      "title": "Mutual Exclusion – Summary ▪The centralized algorithm is simplest and also most efficient ▪Least mes",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Agenda ▪Mutual Exclusion ▪Election DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 21,
      "chunk_id": "p21c1",
      "title": "Agenda ▪Mutual Exclusion ▪Election DSM05Coordination",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms ▪Many distributed algorithms require one process to act as coordinator ▪As all processes are equal, each could take over",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 22,
      "chunk_id": "p22c1",
      "title": "Election Algorithms ▪Many distributed algorithms require one process to act as coordinator ▪As all p",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪But who actually does? Election required! ▪Assumptions: ▪All processes have unique id’s ▪All processes know id’s of all processes in the system (but not if they are up or down) ▪Election means identifying the process with the highest id that is up ▪Election algorithms differ in how they identify this process DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 22,
      "chunk_id": "p22c2",
      "title": "Election Algorithms ▪Many distributed algorithms require one process to act as coordinator ▪As all p",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms ▪When do elections take place? ▪When leader is not responding anymore ▪When system recovers from crash Conditions: ▪Liveness: Every node will eventually enter an elected state or a nonelected state. ▪Safety: Only a single node can enter the elected state and eventually, become the leader of the distributed system DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 23,
      "chunk_id": "p23c1",
      "title": "Election Algorithms ▪When do elections take place? ▪When leader is not responding anymore ▪When syst",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Bully Algorithm ▪Consider N processes {P0 , . . . , PN−1} and let id(Pk ) = k . When a process Pk notices that the coordinator is no longer responding to requests, it initiates an election: 1. Pk sends an ELECTION message to all processes with higher identifiers: Pk+1, Pk+2 , . . . , PN−1. 2. If no one responds, Pk wins the election and becomes coordinator. 3",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 24,
      "chunk_id": "p24c1",
      "title": "Election Algorithms – Bully Algorithm ▪Consider N processes {P0 , . . . , PN−1} and let id(Pk ) = k ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". . . , PN−1. 2. If no one responds, Pk wins the election and becomes coordinator. 3. If one of the higherups answers, it takes over and Pk’s job is done. DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 24,
      "chunk_id": "p24c2",
      "title": "Election Algorithms – Bully Algorithm ▪Consider N processes {P0 , . . . , PN−1} and let id(Pk ) = k ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Bully Algorithm What happens when process 7 wakes up? DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 25,
      "chunk_id": "p25c1",
      "title": "Election Algorithms – Bully Algorithm What happens when process 7 wakes up? DSM05Coordination",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Ring Algorithm ▪Process priority is obtained by organizing processes into a (logical) ring. The process with the highest priority should be elected as coordinator. ▪Any process can start an election by sending an election message to its successor. If a successor is down, the message is passed on to the next successor",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 26,
      "chunk_id": "p26c1",
      "title": "Election Algorithms – Ring Algorithm ▪Process priority is obtained by organizing processes into a (l",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". If a successor is down, the message is passed on to the next successor. ▪If a message is passed on, the sender adds itself to the list. When it gets back to the initiator, everyone had a chance to make its presence known. ▪The initiator sends a coordinator message around the ring containing a list of all living processes. The one with the highest priority is elected as coordinator",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 26,
      "chunk_id": "p26c2",
      "title": "Election Algorithms – Ring Algorithm ▪Process priority is obtained by organizing processes into a (l",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". The one with the highest priority is elected as coordinator. DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 26,
      "chunk_id": "p26c3",
      "title": "Election Algorithms – Ring Algorithm ▪Process priority is obtained by organizing processes into a (l",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Ring Algorithm ▪The solid line shows the election messages initiated by P6 ▪The dashed one, the messages by P3 ▪P6 and P3 eventually receive their own election messages and send out coordinator messages next DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 27,
      "chunk_id": "p27c1",
      "title": "Election Algorithms – Ring Algorithm ▪The solid line shows the election messages initiated by P6 ▪Th",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Example: RAFT Basics ▪We have a (relatively small) group of servers ▪A server is in one of three states: follower , candidate, or leader ▪The protocol works in terms, starting with term 0 ▪Each server starts in the follower state",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 28,
      "chunk_id": "p28c1",
      "title": "Election Algorithms – Example: RAFT Basics ▪We have a (relatively small) group of servers ▪A server ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". ▪A leader is to regularly broadcast messages (perhaps just a simple heartbeat) ▪When a follower does not receive heartbeats anymore, it starts an election DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 28,
      "chunk_id": "p28c2",
      "title": "Election Algorithms – Example: RAFT Basics ▪We have a (relatively small) group of servers ▪A server ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Example: RAFT Election ▪When server s1 timed out (has not received a heartbeat for a while), it ▪increments current term ▪changes to Candidate state ▪Votes for itself ▪sends RequestVote RPCs to all other servers ▪Leader still alive? ▪Responds with RPC and s1 returns to follower state ▪Otherwise: Continue election DSM05Coordination The message primitives in RAFT are called",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 29,
      "chunk_id": "p29c1",
      "title": "Election Algorithms – Example: RAFT Election ▪When server s1 timed out (has not received a heartbeat",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "state ▪Otherwise: Continue election DSM05Coordination The message primitives in RAFT are called remote procedure calls (RPCs) If leader s receives the message, it responds by acknowledging that it is still the leader",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 29,
      "chunk_id": "p29c2",
      "title": "Election Algorithms – Example: RAFT Election ▪When server s1 timed out (has not received a heartbeat",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". s1 returns to the follower state.",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 29,
      "chunk_id": "p29c3",
      "title": "Election Algorithms – Example: RAFT Election ▪When server s1 timed out (has not received a heartbeat",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Example: RAFT Election (continued) ▪Each server will vote for at most one candidate on a FIFO basis ▪Majority rule: At most one candidate can win the election for each term ▪On RequestVote: ▪Check term in RPC vs. own current term ▪Own term higher? →ignore request ▪Own term lower? →update current term, vote for requester ▪Similar →Further checks necessary DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 30,
      "chunk_id": "p30c1",
      "title": "Election Algorithms – Example: RAFT Election (continued) ▪Each server will vote for at most one cand",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Example: RAFT Election (continued) ▪There are three possible results of an election 1) s1 wins the election →send heartbeats to other servers to show dominance 2) another server s2 establishes itself as leader (and term(s2) ≥ term(s1)) →go back to follower state 3) a period of time goes by with no winner (split votes) →reinitiate the election →How can we prevent this from",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 31,
      "chunk_id": "p31c1",
      "title": "Election Algorithms – Example: RAFT Election (continued) ▪There are three possible results of an ele",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "of time goes by with no winner (split votes) →reinitiate the election →How can we prevent this from happening again and again? DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 31,
      "chunk_id": "p31c2",
      "title": "Election Algorithms – Example: RAFT Election (continued) ▪There are three possible results of an ele",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Example: RAFT Election (continued) ▪There are three possible results of an election 1) s1 wins the election →send heartbeats to other servers to show dominance 2) another server s2 establishes itself as leader (and term(s2) ≥ term(s1)) →go back to follower state 3) a period of time goes by with no winner (split votes) →reinitiate the election →How can we prevent this from",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 32,
      "chunk_id": "p32c1",
      "title": "Election Algorithms – Example: RAFT Election (continued) ▪There are three possible results of an ele",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "of time goes by with no winner (split votes) →reinitiate the election →How can we prevent this from happening again and again? →Solution: choose random timeout between T and 2T (typically 150300ms) DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 32,
      "chunk_id": "p32c2",
      "title": "Election Algorithms – Example: RAFT Election (continued) ▪There are three possible results of an ele",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Example: RAFT DSM05Coordination Follower Candidate Leader starts up times out, starts election times out, new election receives votes from majority of servers discovers server with higher term discovers current leader or new term",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 33,
      "chunk_id": "p33c1",
      "title": "Election Algorithms – Example: RAFT DSM05Coordination Follower Candidate Leader starts up times out,",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – In LargeScale Systems Two approaches ▪Proof of work ▪Proof of stake DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 34,
      "chunk_id": "p34c1",
      "title": "Election Algorithms – In LargeScale Systems Two approaches ▪Proof of work ▪Proof of stake DSM05Coord",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Proof of work Basics ▪Consider a potentially large group of processes ▪Each process is required to solve a computational puzzle ▪When a process solves the puzzle, it broadcasts its victory to the group Solving a computational puzzle ▪Make use of a secure hashing function H(m): ▪m is some data; H(m) returns a fixedlength bit string ▪computing h = H(m) is computationally",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 35,
      "chunk_id": "p35c1",
      "title": "Election Algorithms – Proof of work Basics ▪Consider a potentially large group of processes ▪Each pr",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "H(m): ▪m is some data; H(m) returns a fixedlength bit string ▪computing h = H(m) is computationally efficient ▪finding a function H−1 such that m = H−1(H(m)) is computationally extremely difficult ▪Practice: finding H−1 boils down to an extensive trialanderror procedure DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 35,
      "chunk_id": "p35c2",
      "title": "Election Algorithms – Proof of work Basics ▪Consider a potentially large group of processes ▪Each pr",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Proof of work Controlled race ▪Given a globally known secure hash function H* ▪Task: given a bit string h = H*(m), find a bit string h˜ such that ▪h* = H*(h˜ ⊙ h) where: ▪h∗ is a bit string with K leading zeroes ▪h˜ ⊙ h denotes some predetermined bitwise operation on h˜ and h ▪By controlling K , we control the difficulty of finding h˜",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 36,
      "chunk_id": "p36c1",
      "title": "Election Algorithms – Proof of work Controlled race ▪Given a globally known secure hash function H* ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". Success probability p = ( )K ▪Current practice in many PoWbased blockchain systems, K = 64 ▪With K = 64, it takes about 10 minutes on a supercomputer to find h˜ ▪With K = 64, it takes about 100 years on a laptop to find h˜ DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 36,
      "chunk_id": "p36c2",
      "title": "Election Algorithms – Proof of work Controlled race ▪Given a globally known secure hash function H* ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Proof of work Discussion ▪Large K leads to? ▪Long time between two successful guesses ▪Few transactions can be processed per time unit ▪Huge amounts of computational power (energy) is used. Wasted? ▪Small K leads to? ▪Less energy consumption ▪More transactions per time unit ▪Possible forking of the blockchain ▪Can we do better? DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 37,
      "chunk_id": "p37c1",
      "title": "Election Algorithms – Proof of work Discussion ▪Large K leads to? ▪Long time between two successful ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Proof of work Discussion ▪Large K leads to? ▪Long time between two successful guesses ▪Few transactions can be processed per time unit ▪Huge amounts of computational power (energy) is used. Wasted? ▪Small K leads to? ▪Less energy consumption ▪More transactions per time unit ▪Possible forking of the blockchain ▪Can we do better? DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 38,
      "chunk_id": "p38c1",
      "title": "Election Algorithms – Proof of work Discussion ▪Large K leads to? ▪Long time between two successful ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": "Election Algorithms – Proof of stake Basics ▪We assume a blockchain system in which N secure tokens are used: ▪Each token has a unique owner ▪Each token has a uniquely associated index 1 ≤ k ≤ N ▪A token cannot be modified or copied without this going unnoticed Principle ▪Draw a random number k ∈ {1,..., N} ▪Look up the process P that owns the token with index k . P is the next leader",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 39,
      "chunk_id": "p39c1",
      "title": "Election Algorithms – Proof of stake Basics ▪We assume a blockchain system in which N secure tokens ",
      "ocr_used": false,
      "course": "DOS"
    }
  },
  {
    "page_content": ". P is the next leader. ▪The more tokens a process owns, the higher the probability it will be selected as leader. DSM05Coordination",
    "metadata": {
      "source": "Lecture_05.pdf",
      "page": 39,
      "chunk_id": "p39c2",
      "title": "Election Algorithms – Proof of stake Basics ▪We assume a blockchain system in which N secure tokens ",
      "ocr_used": false,
      "course": "DOS"
    }
  }
]